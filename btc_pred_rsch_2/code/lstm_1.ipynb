{"cells":[{"cell_type":"markdown","metadata":{"id":"0vawE1k-gCea"},"source":["- recent update: 24.10.29\n","- update content:\n","    1. mid-price 생성\n","    2. significant or insignificant 예측 모델 생성\n","    3. significant 예측되는 경우에만 significant increase or decrease인지 예측\n","- target var: mid price return significant change (0 or 1)\n","- Model: XGBoost(significant or insignificant 예측) + LSTM(significant increase or decrease 예측)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2654,"status":"ok","timestamp":1732598266300,"user":{"displayName":"Hohyun Kim","userId":"09062334856697746087"},"user_tz":-540},"id":"dcxEwsS5gED-","outputId":"85bccaa7-3e0c-4761-ce46-adcbee275fe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2914,"status":"ok","timestamp":1732598269212,"user":{"displayName":"Hohyun Kim","userId":"09062334856697746087"},"user_tz":-540},"id":"qbRESA8GgCen"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n","from imblearn.over_sampling import SMOTE\n","import seaborn as sns\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from sklearn.metrics import precision_score\n","#from optuna.integration import XGBoostPruningCallback\n","#import optuna"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lnSsbzVFgCeo","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1732600503441,"user_tz":-540,"elapsed":1634181,"user":{"displayName":"Hohyun Kim","userId":"09062334856697746087"}},"outputId":"5269c9d5-b216-4c16-fb1a-d208c3d614f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['train_sequences', 'train_labels', 'valid_sequences', 'valid_labels', 'test_sequences', 'test_labels'])\n","Train batches: 8379\n","Validation batches: 4451\n","Test batches: 4451\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-79962281411f>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(self.sequences[idx], dtype=torch.float32),\n","<ipython-input-7-79962281411f>:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(self.labels[idx], dtype=torch.long),\n"]},{"output_type":"stream","name":"stdout","text":["DAE Epoch [1/10], Loss: 0.4434\n","DAE Epoch [2/10], Loss: 0.4241\n","DAE Epoch [3/10], Loss: 0.4240\n","DAE Epoch [4/10], Loss: 0.4240\n","DAE Epoch [5/10], Loss: 0.4240\n","DAE Epoch [6/10], Loss: 0.4240\n","DAE Epoch [7/10], Loss: 0.4240\n","DAE Epoch [8/10], Loss: 0.4240\n","DAE Epoch [9/10], Loss: 0.4240\n","DAE Epoch [10/10], Loss: 0.4240\n","Epoch [1/50], Train Loss: 0.5398, Valid Loss: 2.4070\n","Epoch [2/50], Train Loss: 0.3537, Valid Loss: 3.0696\n","Epoch [3/50], Train Loss: 0.3190, Valid Loss: 3.1454\n","Epoch [4/50], Train Loss: 0.3007, Valid Loss: 3.8145\n","Epoch [5/50], Train Loss: 0.2873, Valid Loss: 3.9757\n","Epoch [6/50], Train Loss: 0.2764, Valid Loss: 3.6648\n","Epoch [7/50], Train Loss: 0.2661, Valid Loss: 3.8773\n","Epoch [8/50], Train Loss: 0.2569, Valid Loss: 4.3089\n","Epoch [9/50], Train Loss: 0.2465, Valid Loss: 4.3198\n","Epoch [10/50], Train Loss: 0.2372, Valid Loss: 4.5880\n","Epoch [11/50], Train Loss: 0.2279, Valid Loss: 4.3636\n","Epoch [12/50], Train Loss: 0.2189, Valid Loss: 4.0619\n","Epoch [13/50], Train Loss: 0.2097, Valid Loss: 4.1686\n","Epoch [14/50], Train Loss: 0.2014, Valid Loss: 4.9419\n","Epoch [15/50], Train Loss: 0.1928, Valid Loss: 4.6259\n","Epoch [16/50], Train Loss: 0.1851, Valid Loss: 4.9584\n","Epoch [17/50], Train Loss: 0.1781, Valid Loss: 4.6932\n","Epoch [18/50], Train Loss: 0.1712, Valid Loss: 5.1018\n","Epoch [19/50], Train Loss: 0.1644, Valid Loss: 4.8740\n","Epoch [20/50], Train Loss: 0.1595, Valid Loss: 4.9839\n","Epoch [21/50], Train Loss: 0.1541, Valid Loss: 4.9022\n","Epoch [22/50], Train Loss: 0.1479, Valid Loss: 5.1158\n","Epoch [23/50], Train Loss: 0.1436, Valid Loss: 5.0321\n","Epoch [24/50], Train Loss: 0.1397, Valid Loss: 5.0964\n","Epoch [25/50], Train Loss: 0.1357, Valid Loss: 5.4871\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-79962281411f>\u001b[0m in \u001b[0;36m<cell line: 206>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;31m# Train LSTM with DAE features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;31m# Plotting training and validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-79962281411f>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(dae, lstm, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-79962281411f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m         return (\n\u001b[1;32m     59\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","\n","# .pkl 파일 경로\n","pkl_file_path = '/content/drive/MyDrive/eunsung/data/sequence_data.pkl'\n","\n","# 저장된 파일 불러오기\n","with open(pkl_file_path, 'rb') as file:\n","    sequence_data = pickle.load(file)\n","\n","# 로드된 데이터 확인\n","print(sequence_data.keys())  # ['train_sequences', 'train_labels', 'valid_sequences', 'valid_labels', 'test_sequences', 'test_labels']\n","\n","# Tensor 데이터 준비\n","train_sequences = sequence_data['train_sequences']\n","train_labels = sequence_data['train_labels']\n","valid_sequences = sequence_data['valid_sequences']\n","valid_labels = sequence_data['valid_labels']\n","test_sequences = sequence_data['test_sequences']\n","test_labels = sequence_data['test_labels']\n","\n","# Hyperparameters\n","hyperparams = {\n","    \"input_dim\": train_sequences.shape[2],  # Feature size\n","    \"hidden_dim\": 128,                      # Hidden size for LSTM\n","    \"num_layers\": 2,                        # Number of LSTM layers\n","    \"num_classes\": len(np.unique(train_labels)),  # Number of output classes\n","    \"dropout_rate\": 0.3,                    # Dropout rate\n","    \"batch_size\": 64,                       # Batch size for training\n","    \"epochs\": 50,                           # Number of training epochs\n","    \"learning_rate\": 5e-4,                  # Initial learning rate\n","    \"weight_decay\": 1e-6,                   # Weight decay for regularization\n","    \"gradient_clipping\": 1.0,               # Max norm for gradient clipping\n","    \"model_save_path\": \"./model_lstm_dae\",  # Directory to save the model\n","}\n","\n","# Create model save directory\n","os.makedirs(hyperparams[\"model_save_path\"], exist_ok=True)\n","\n","# Custom Dataset 정의\n","class TimeSeriesDataset(Dataset):\n","    def __init__(self, sequences, labels):\n","        self.sequences = sequences\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        return (\n","            torch.tensor(self.sequences[idx], dtype=torch.float32),\n","            torch.tensor(self.labels[idx], dtype=torch.long),\n","        )\n","\n","# Dataset 생성\n","train_dataset = TimeSeriesDataset(train_sequences, train_labels)\n","valid_dataset = TimeSeriesDataset(valid_sequences, valid_labels)\n","test_dataset = TimeSeriesDataset(test_sequences, test_labels)\n","\n","# DataLoader 생성\n","train_loader = DataLoader(train_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=True, drop_last=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=False, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=False, drop_last=True)\n","\n","print(f\"Train batches: {len(train_loader)}\")\n","print(f\"Validation batches: {len(valid_loader)}\")\n","print(f\"Test batches: {len(test_loader)}\")\n","\n","# Denoising Autoencoder\n","class DenoisingAutoencoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim):\n","        super(DenoisingAutoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU()\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(hidden_dim, input_dim),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded\n","\n","# LSTM Classifier\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout_rate):\n","        super(LSTMClassifier, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, x):\n","        _, (hidden, _) = self.lstm(x)\n","        return self.fc(hidden[-1])  # Use the output from the last LSTM layer\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize models\n","dae = DenoisingAutoencoder(input_dim=hyperparams[\"input_dim\"], hidden_dim=64).to(device)\n","lstm = LSTMClassifier(\n","    input_dim=64,  # Encoded dimension from DAE\n","    hidden_dim=hyperparams[\"hidden_dim\"],\n","    num_layers=hyperparams[\"num_layers\"],\n","    num_classes=hyperparams[\"num_classes\"],\n","    dropout_rate=hyperparams[\"dropout_rate\"]\n",").to(device)\n","\n","# Loss and optimizer\n","dae_optimizer = optim.Adam(dae.parameters(), lr=hyperparams[\"learning_rate\"])\n","lstm_optimizer = optim.Adam(lstm.parameters(), lr=hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"weight_decay\"])\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training Denoising Autoencoder\n","def train_dae(dae, train_loader, epochs=10):\n","    dae.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for inputs, _ in train_loader:\n","            noisy_inputs = inputs + torch.randn_like(inputs) * 0.1\n","            noisy_inputs, inputs = noisy_inputs.to(device), inputs.to(device)\n","\n","            _, decoded = dae(noisy_inputs)\n","            loss = nn.MSELoss()(decoded, inputs)\n","\n","            dae_optimizer.zero_grad()\n","            loss.backward()\n","            dae_optimizer.step()\n","\n","            total_loss += loss.item()\n","        print(f\"DAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n","\n","# Training and Validation Loop for LSTM\n","def train_lstm(dae, lstm, train_loader, valid_loader):\n","    best_valid_loss = float('inf')\n","    train_losses, valid_losses = [], []\n","\n","    for epoch in range(hyperparams[\"epochs\"]):\n","        # Training Phase\n","        lstm.train()\n","        epoch_train_loss = 0.0\n","\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            with torch.no_grad():\n","                encoded, _ = dae(inputs)  # DAE encoding output (batch_size, feature_size)\n","\n","            if encoded.dim() == 2:  # Check if the output is 2D\n","                encoded = encoded.unsqueeze(1)  # Add sequence_length dimension\n","\n","            lstm_optimizer.zero_grad()\n","            outputs = lstm(encoded)  # Forward pass through LSTM\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(lstm.parameters(), max_norm=hyperparams[\"gradient_clipping\"])\n","            lstm_optimizer.step()\n","\n","            epoch_train_loss += loss.item()\n","\n","        train_loss = epoch_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation Phase\n","        lstm.eval()\n","        epoch_valid_loss = 0.0\n","\n","        with torch.no_grad():\n","            for inputs, targets in valid_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                encoded, _ = dae(inputs)\n","\n","                if encoded.dim() == 2:\n","                    encoded = encoded.unsqueeze(1)\n","\n","                outputs = lstm(encoded)\n","                loss = criterion(outputs, targets)\n","                epoch_valid_loss += loss.item()\n","\n","        valid_loss = epoch_valid_loss / len(valid_loader)\n","        valid_losses.append(valid_loss)\n","\n","        # Save the best model\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(lstm.state_dict(), os.path.join(hyperparams[\"model_save_path\"], 'best_lstm_model.pth'))\n","\n","        print(f\"Epoch [{epoch+1}/{hyperparams['epochs']}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n","\n","    return train_losses, valid_losses\n","\n","# Train DAE\n","train_dae(dae, train_loader)\n","\n","# Train LSTM with DAE features\n","train_losses, valid_losses = train_lstm(dae, lstm, train_loader, valid_loader)\n","\n","# Plotting training and validation loss\n","plt.figure(figsize=(8, 6))\n","plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n","plt.plot(range(1, len(valid_losses) + 1), valid_losses, label='Valid Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Train and Validation Loss')\n","plt.legend()\n","plt.grid()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"676g3RZPOeia","executionInfo":{"status":"aborted","timestamp":1732598277334,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hohyun Kim","userId":"09062334856697746087"}}},"outputs":[],"source":["# Evaluation on Test Set\n","lstm.load_state_dict(torch.load(os.path.join(hyperparams[\"model_save_path\"], 'best_lstm_model.pth')))\n","lstm.eval()\n","\n","all_preds, all_targets = [], []\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = lstm(inputs)\n","        preds = torch.argmax(outputs, dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_targets.extend(targets.cpu().numpy())\n","\n","# Classification Report and Confusion Matrix\n","print(classification_report(all_targets, all_preds, target_names=[\"Significant Increase\", \"Insignificant Increase\", \"Insignificant Decrease\"]))\n","\n","cm = confusion_matrix(all_targets, all_preds)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Significant Increase\", \"Insignificant Increase\", \"Insignificant Decrease\"], yticklabels=[\"Significant Increase\", \"Insignificant Increase\", \"Insignificant Decrease\"])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"EgfvRT2dgCev"},"source":["### 실제 데이터에 적용\n","- insignificant increase, decrease도 적용"]},{"cell_type":"markdown","metadata":{"id":"3XrxhGoNgCe4"},"source":["- Precision (정밀도):\n","\n","정밀도는 모델이 해당 클래스로 예측한 값 중 실제로 맞은 비율입니다.\n","예를 들어, \"Significant increase\" 클래스에 대해 모델이 98%의 정밀도를 보였다는 것은, 모델이 이 클래스로 예측한 값 중 98%가 실제로 맞았다는 의미입니다.\n","하지만 \"Significant decrease\" 클래스는 데이터에 등장하지 않아서 정밀도가 0.00으로 표시되었습니다.\n","\n","- Recall (재현율):\n","\n","재현율은 실제로 해당 클래스에 속한 데이터 중에서 모델이 올바르게 예측한 비율입니다.\n","예를 들어, \"Insignificant increase\" 클래스에 대한 재현율이 0.92라는 것은, 실제로 \"Insignificant increase\"에 속한 데이터 중 92%를 모델이 정확히 맞췄다는 의미입니다.\n","\"Significant increase\" 클래스의 재현율이 0.01이라는 것은, 이 클래스에 속한 실제 데이터 중 1%만 모델이 맞췄다는 의미입니다.\n","\n","- F1-score:\n","\n","F1 스코어는 정밀도와 재현율의 조화평균으로, 두 지표를 종합적으로 평가하는 지표입니다. 정밀도와 재현율 사이의 균형을 중요시할 때 유용합니다.\n","예를 들어, \"Insignificant increase\" 클래스의 F1 스코어가 0.84라는 것은, 정밀도와 재현율이 적절히 균형을 이뤘음을 의미합니다.\n","\n","- Support:\n","\n","Support는 각 클래스에 실제로 속한 데이터의 개수입니다.\n","예를 들어, \"Insignificant increase\" 클래스는 241,234개의 데이터 포인트를 가지고 있다는 것을 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"sIUs_8TOgCe4"},"source":["- Micro avg (마이크로 평균):\n","\n","마이크로 평균은 전체 데이터에서의 정밀도, 재현율, F1 스코어를 계산합니다. 이는 각 클래스의 데이터 개수를 고려하지 않고, 전체 데이터를 한 번에 평가하는 방식입니다.\n","마이크로 평균 77%는 모든 클래스의 데이터를 합쳐서 모델이 77%의 정확도를 보였음을 의미합니다.\n","\n","- Macro avg (매크로 평균):\n","\n","매크로 평균은 각 클래스의 정밀도, 재현율, F1 스코어의 평균을 단순히 계산한 것입니다. 이는 클래스별 데이터 비율을 고려하지 않기 때문에, 클래스 간 불균형이 있는 경우 잘못된 평가가 나올 수 있습니다.\n","예를 들어, \"Significant decrease\" 클래스처럼 데이터가 없는 클래스는 성능이 0으로 평가되며, 이러한 클래스들도 평균에 포함되기 때문에 성능이 낮아집니다.\n","\n","- Weighted avg (가중 평균):\n","\n","가중 평균은 각 클래스의 정밀도, 재현율, F1 스코어를 해당 클래스의 데이터 개수에 비례하여 평균을 계산한 것입니다. 즉, 클래스의 데이터가 많을수록 해당 클래스의 성능이 평균에 더 큰 영향을 줍니다.\n","Weighted 평균 77%는 실제 데이터 비율에 따라 가중치를 부여하여 계산한 성능입니다. 이 값은 전체적으로 모델이 77%의 정확도를 가지고 있음을 보여줍니다."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
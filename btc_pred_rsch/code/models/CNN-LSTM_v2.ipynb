{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM v2\n",
    "- 모델 성능이 안좋아서 모델 복잡도 증가시킴\n",
    "- Conv1d를 하나 더 추가\n",
    "- ref: https://medium.com/@mijanr/different-ways-to-combine-cnn-and-lstm-networks-for-time-series-classification-tasks-b03fc37e91b6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library 불러오기, SEED 설정, CUDA 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps 사용 가능 여부: True\n",
      "mps 지원 환경 여부: True\n",
      "mps is available\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 import\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 관련\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sequence as sq\n",
    "\n",
    "# 성능 평가 관련\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Visualization 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "'''\n",
    "딥러닝 학습을 진행할 때, 가중치를 임의의 값으로 초기화하여 학습을 수행하는 데, \n",
    "실험을 동일하게 진행하기 위해서는 난수를 동일하게 생성해야 한다.\n",
    "Pytorch에서 random seed를 고정하기 위해 manual_seed를 사용한다.\n",
    "'''\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# 맥북 용\n",
    "# GPU 사용 가능 환경인지 확인 -> mac의 경우 GPU가 아는 MPS를 사용\n",
    "print(f\"mps 사용 가능 여부: {torch.backends.mps.is_available()}\")\n",
    "print(f\"mps 지원 환경 여부: {torch.backends.mps.is_built()}\")\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# 윈도우 용(Colab)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 전처리 (Binary, Scale, Tensor, train&valid&test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([914, 40, 77]) torch.Size([914, 1])\n",
      "Train Size: torch.Size([548, 40, 77]) torch.Size([548, 1])\n",
      "Valid Size: torch.Size([183, 40, 77]) torch.Size([183, 1])\n",
      "Test Size: torch.Size([183, 40, 77]) torch.Size([183, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "file_path = '../../data/' # for mac\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "df = df.iloc[-1000:]\n",
    "df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 40 # 20, 40, 80, 160, 320\n",
    "X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (60% / 20% / 20%)\n",
    "train_split = int((X.size(0)) * 0.6)\n",
    "valid_split = int((X.size(0)) * 0.8)\n",
    "\n",
    "X_train_seq = X[:train_split]\n",
    "X_val_seq = X[train_split:valid_split]\n",
    "X_test_seq = X[valid_split:]\n",
    "y_train_seq = y[:train_split]\n",
    "y_val_seq = y[train_split:valid_split]\n",
    "y_test_seq = y[valid_split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Valid Size:', X_val_seq.size(), y_val_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset과 DataLoader를 이용해 배치 데이터로 만든다.\n",
    "train = torch.utils.data.TensorDataset(X_train_seq, y_train_seq)\n",
    "valid = torch.utils.data.TensorDataset(X_val_seq, y_val_seq)\n",
    "test = torch.utils.data.TensorDataset(X_test_seq, y_test_seq)\n",
    "batch_size = 64 # 32, 64, 128\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False, drop_last=True) # 시계열 데이터기에 shuffle X, 마지막 batch 버림\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 주식 시계열 데이터의 형태: [배치 크기, 시퀀스 길이, 특성 수]\n",
    "# # 여기서 특성 수는 주가, 거래량, 기술적 지표 등 다양한 특성을 포함합니다.\n",
    "\n",
    "# class CNNLSTMModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers):\n",
    "#         super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "#         # CNN 레이어\n",
    "#         self.cnn = nn.Conv1d(in_channels=input_size[-1], out_channels=64, kernel_size=3)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "#         # LSTM 레이어\n",
    "#         self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "#         # Fully Connected 레이어\n",
    "#         self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # CNN 레이어 적용\n",
    "#         x = self.cnn(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "        \n",
    "#         # LSTM 레이어 적용\n",
    "#         lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "#         # Fully Connected 레이어에 입력\n",
    "#         out = self.fc(lstm_out[:, -1, :])\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# num_features = X.size(2)\n",
    "\n",
    "# # 모델 인스턴스화\n",
    "# input_size = [batch_size, seq_len, num_features]  # 예: [32, 20, 5]\n",
    "# hidden_size = 64\n",
    "# num_layers = 2\n",
    "\n",
    "# model = CNNLSTMModel(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN 레이어\n",
    "        # in_channels=input_size[-1]이면 안됨. 즉 feature_dims면 안되고 sequence_length(=20, 40, 80...) 여야 함.\n",
    "        '''\n",
    "        in_channels = 일반적인 이미지와 같은 2D 데이터를 다룰 때는 특성 맵(channel)을 채널로 인식함.\n",
    "        그러나 주식 시계열 데이터와 같은 1D 데이터의 경우 시퀀스 길이에 해당하는 차원이 채널로 간주됨.\n",
    "        이에 따라 'in_channels'에는 시퀀스 길이를 입력해야 함.\n",
    "        즉, 주식 시게열 데이터에서는 'in_channels'에는 시퀀스의 길이가 들어가야 올바르게 수행됨.\n",
    "        '''\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Fully Connected 레이어\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 레이어 적용 (cnn takes input of shape (batch_size, channels, seq_len))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn(x)\n",
    "        \n",
    "        # LSTM 레이어 적용\n",
    "        '''\n",
    "        LSTM 레이어에 입력을 전달하고, LSTM의 출력과 은닉 상태를 받는 부분\n",
    "        x.permute(0, 2, 1): 입력텐서 x의 차원을 변경. 일반적으로 LSTM 레이어는 시간 단계(seq_len)를 두 번쨰 차원으로 받지만,\n",
    "        Conv1d 레이어의 출력은 시간 단계가 세번째 차원에 위치함. 따라서 permute를 통해 차원을 변경하여 LSTM 레이어에 올바른 형태의 입력을 제공\n",
    "        여기서 0번째 차원은 배치 크기(batch_size)를 나타내며, 1번째 차원은 특성 수(num_features)를 나타냄. 마지막(2번째) 차원은 시간 단계(seq_len)를 나타냄\n",
    "        self.lstm(x.permute(0, 2, 1)): 변경된 입력을 LSTM 레이어에 전달함. LSTM 입력으로 3D 텐서를 받으며,\n",
    "        이 텐서는 배치 크기(batch_size), 시간 단계(seq_len),. 특성 수(num_features)의 형태를 가짐\n",
    "        lstm_out, _: LSTM 레이어의 출력과 은닉 상태를 받음. 여기서 은닉 상태는 사용하지 않기 때문에 '_'로 무시. lstm_out은 LSTM 레이어의 출력으로, 각 시간 단계에\n",
    "        해당하는 출력을 포함하는 3D 텐서임.\n",
    "        '''\n",
    "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(out)\n",
    "        \n",
    "        # Fully Connected 레이어에 입력\n",
    "        '''\n",
    "        lstm_out[:, -1, :]: LSTM 레이어의 출력에서 마지막 시간 단계의 출력만 선택. 이는 시퀀스 예측을 위해 마지막 시간 단계의 정보만을 사용하고자 하는 것\n",
    "        따라서 [:, -1, :]는 모든 배치와 모든 특성을 유지하면서 마지막 시간 단계의 출력을 선택함\n",
    "        self.fc(lstm_out[:, -1, :]): 선택된 마지막 시간 단계의 출력을 Fully Connected(FC) 레이어에 입력함. FC 레이어는 입력된 LSTM 출력을 받아서 최종\n",
    "        예측을 수행하는 역할을 함. 출력 크기는 1이며, 이는 주어진 입력에 대한 예측된 결과를 나타냄.\n",
    "        '''\n",
    "        out = self.fc(out[:, -1, :])        \n",
    "        return out\n",
    "\n",
    "model = CNNLSTMModel(input_size=X.size(-1), hidden_size=64, num_layers=2, num_classes=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델학습1: train 데이터만 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습1: train data만 가지고 학습 -> 과적합 이빠이~\n",
    "\n",
    "# # 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# #criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # GPU 사용 가능 여부 확인\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# num_epochs = 100\n",
    "\n",
    "# # 학습 루프\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch_features, batch_targets in train_loader:\n",
    "#         # 배치를 GPU로 전송\n",
    "#         batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "#         # 모델에 대한 순전파 및 손실 계산\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "#         # 역전파 및 최적화\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     # 에폭마다 손실 출력\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델학습2: train, valid를 이용한 과적합 방지되는 epoch 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.010015937642459451, Valid Loss: 0.011511032047167502\n",
      "Epoch 2/100, Train Loss: 0.009978433160016136, Valid Loss: 0.011538039465419581\n",
      "Epoch 3/100, Train Loss: 0.009964859616147341, Valid Loss: 0.011568736508895791\n",
      "Epoch 4/100, Train Loss: 0.009955893250277443, Valid Loss: 0.011599712684506276\n",
      "Epoch 5/100, Train Loss: 0.009950143903711416, Valid Loss: 0.011629004621766303\n",
      "Epoch 6/100, Train Loss: 0.009946808218955994, Valid Loss: 0.011655070416914309\n",
      "Epoch 7/100, Train Loss: 0.009945155712809876, Valid Loss: 0.01167682220375603\n",
      "Epoch 8/100, Train Loss: 0.009944508110519744, Valid Loss: 0.011693858058074784\n",
      "Epoch 9/100, Train Loss: 0.009944320160107021, Valid Loss: 0.011706489682848988\n",
      "Epoch 10/100, Train Loss: 0.009944260881765045, Valid Loss: 0.011715479235831506\n",
      "Epoch 11/100, Train Loss: 0.00994417723948068, Valid Loss: 0.011721722740944617\n",
      "Epoch 12/100, Train Loss: 0.009944026922657542, Valid Loss: 0.011726039354918434\n",
      "Epoch 13/100, Train Loss: 0.009943819502844427, Valid Loss: 0.011729073003341592\n",
      "Epoch 14/100, Train Loss: 0.009943579235216127, Valid Loss: 0.011731273163863219\n",
      "Epoch 15/100, Train Loss: 0.00994332732945463, Valid Loss: 0.011732938511124074\n",
      "Epoch 16/100, Train Loss: 0.009943077272742334, Valid Loss: 0.011734260561687698\n",
      "Epoch 17/100, Train Loss: 0.009942837875254833, Valid Loss: 0.011735352662091698\n",
      "Epoch 18/100, Train Loss: 0.009942613052625726, Valid Loss: 0.011736286468193179\n",
      "Epoch 19/100, Train Loss: 0.009942403239925412, Valid Loss: 0.011737099436462903\n",
      "Epoch 20/100, Train Loss: 0.009942208219618692, Valid Loss: 0.011737822509202802\n",
      "Epoch 21/100, Train Loss: 0.009942026142656367, Valid Loss: 0.011738470017584296\n",
      "Epoch 22/100, Train Loss: 0.009941855159989238, Valid Loss: 0.011739054012819718\n",
      "Epoch 23/100, Train Loss: 0.009941696032990504, Valid Loss: 0.011739586220412958\n",
      "Epoch 24/100, Train Loss: 0.009941546151237766, Valid Loss: 0.01174006989744843\n",
      "Epoch 25/100, Train Loss: 0.009941403556914225, Valid Loss: 0.011740512860928727\n",
      "Epoch 26/100, Train Loss: 0.00994126999030148, Valid Loss: 0.011740919019355148\n",
      "Epoch 27/100, Train Loss: 0.009941141426998333, Valid Loss: 0.011741295538313401\n",
      "Epoch 28/100, Train Loss: 0.009941020042356783, Valid Loss: 0.011741643394928813\n",
      "Epoch 29/100, Train Loss: 0.009940903769792432, Valid Loss: 0.01174196714911956\n",
      "Epoch 30/100, Train Loss: 0.009940792718072878, Valid Loss: 0.011742268103719408\n",
      "Epoch 31/100, Train Loss: 0.009940686234592521, Valid Loss: 0.011742549841521217\n",
      "Epoch 32/100, Train Loss: 0.009940583993048563, Valid Loss: 0.011742813665358747\n",
      "Epoch 33/100, Train Loss: 0.009940485449603005, Valid Loss: 0.011743064460858621\n",
      "Epoch 34/100, Train Loss: 0.009940391039326243, Valid Loss: 0.011743297342394219\n",
      "Epoch 35/100, Train Loss: 0.00994030032714788, Valid Loss: 0.011743517521300602\n",
      "Epoch 36/100, Train Loss: 0.009940212334159516, Valid Loss: 0.011743728254662186\n",
      "Epoch 37/100, Train Loss: 0.009940127386663953, Valid Loss: 0.011743926611102995\n",
      "Epoch 38/100, Train Loss: 0.009940046028499185, Valid Loss: 0.011744117150541212\n",
      "Epoch 39/100, Train Loss: 0.009939966410616018, Valid Loss: 0.011744296941600863\n",
      "Epoch 40/100, Train Loss: 0.00993988994699325, Valid Loss: 0.011744470544200126\n",
      "Epoch 41/100, Train Loss: 0.00993981565872248, Valid Loss: 0.01174463502696303\n",
      "Epoch 42/100, Train Loss: 0.00993974311073331, Valid Loss: 0.011744793972682431\n",
      "Epoch 43/100, Train Loss: 0.009939673934539739, Valid Loss: 0.011744945752816122\n",
      "Epoch 44/100, Train Loss: 0.009939605193416568, Valid Loss: 0.011745090367364102\n",
      "Epoch 45/100, Train Loss: 0.009939539171483394, Valid Loss: 0.011745230747702343\n",
      "Epoch 46/100, Train Loss: 0.009939474998599422, Valid Loss: 0.011745364613871757\n",
      "Epoch 47/100, Train Loss: 0.009939412239694247, Valid Loss: 0.011745494897248314\n",
      "Epoch 48/100, Train Loss: 0.009939351656141073, Valid Loss: 0.011745618992164487\n",
      "Epoch 49/100, Train Loss: 0.009939292595334296, Valid Loss: 0.011745740155704686\n",
      "Epoch 50/100, Train Loss: 0.009939234404668321, Valid Loss: 0.011745858387868912\n",
      "Epoch 51/100, Train Loss: 0.009939178063051545, Valid Loss: 0.011745971082989635\n",
      "Epoch 52/100, Train Loss: 0.009939123135413567, Valid Loss: 0.011746078892483738\n",
      "Epoch 53/100, Train Loss: 0.009939069295451589, Valid Loss: 0.011746186050560957\n",
      "Epoch 54/100, Train Loss: 0.00993901708700361, Valid Loss: 0.011746288648719997\n",
      "Epoch 55/100, Train Loss: 0.009938965531161232, Valid Loss: 0.01174638994404527\n",
      "Epoch 56/100, Train Loss: 0.009938916912044052, Valid Loss: 0.011746491239370544\n",
      "Epoch 57/100, Train Loss: 0.00993887253486327, Valid Loss: 0.01174660458590815\n",
      "Epoch 58/100, Train Loss: 0.009938842732540882, Valid Loss: 0.011746717281028872\n",
      "Epoch 59/100, Train Loss: 0.009938816410781693, Valid Loss: 0.011746769068671054\n",
      "Epoch 60/100, Train Loss: 0.009938745276771323, Valid Loss: 0.011746853752865818\n",
      "Epoch 61/100, Train Loss: 0.00993870296617494, Valid Loss: 0.011746936157101491\n",
      "Epoch 62/100, Train Loss: 0.009938660655578557, Valid Loss: 0.011746993481787177\n",
      "Epoch 63/100, Train Loss: 0.009938601159701382, Valid Loss: 0.011747065137644282\n",
      "Epoch 64/100, Train Loss: 0.009938550473999804, Valid Loss: 0.01174714363337866\n",
      "Epoch 65/100, Train Loss: 0.00993850881600902, Valid Loss: 0.0117472234319468\n",
      "Epoch 66/100, Train Loss: 0.009938467375553437, Valid Loss: 0.011747301276264294\n",
      "Epoch 67/100, Train Loss: 0.009938426696471055, Valid Loss: 0.011747378143456465\n",
      "Epoch 68/100, Train Loss: 0.00993838797520547, Valid Loss: 0.011747452404981103\n",
      "Epoch 69/100, Train Loss: 0.009938349362707486, Valid Loss: 0.011747525363671974\n",
      "Epoch 70/100, Train Loss: 0.009938311729117901, Valid Loss: 0.011747595065278433\n",
      "Epoch 71/100, Train Loss: 0.009938275183204316, Valid Loss: 0.011747664766884892\n",
      "Epoch 72/100, Train Loss: 0.009938238854825933, Valid Loss: 0.011747729908573172\n",
      "Epoch 73/100, Train Loss: 0.009938203179053147, Valid Loss: 0.011747795375969892\n",
      "Epoch 74/100, Train Loss: 0.00993816761204796, Valid Loss: 0.011747859540532847\n",
      "Epoch 75/100, Train Loss: 0.009938133241486376, Valid Loss: 0.01174792077371983\n",
      "Epoch 76/100, Train Loss: 0.009938099197227589, Valid Loss: 0.011747982332615254\n",
      "Epoch 77/100, Train Loss: 0.009938065914342003, Valid Loss: 0.011748041937260029\n",
      "Epoch 78/100, Train Loss: 0.009938032848991616, Valid Loss: 0.011748099261945715\n",
      "Epoch 79/100, Train Loss: 0.00993800098008483, Valid Loss: 0.011748155609506076\n",
      "Epoch 80/100, Train Loss: 0.009937969111178044, Valid Loss: 0.011748213259900202\n",
      "Epoch 81/100, Train Loss: 0.009937937786109257, Valid Loss: 0.011748266676084591\n",
      "Epoch 82/100, Train Loss: 0.00993790711364607, Valid Loss: 0.011748320743685862\n",
      "Epoch 83/100, Train Loss: 0.009937877311323682, Valid Loss: 0.01174837350845337\n",
      "Epoch 84/100, Train Loss: 0.009937847617768893, Valid Loss: 0.01174842529609555\n",
      "Epoch 85/100, Train Loss: 0.009937818141749306, Valid Loss: 0.011748476106612409\n",
      "Epoch 86/100, Train Loss: 0.009937789644638118, Valid Loss: 0.011748526917129267\n",
      "Epoch 87/100, Train Loss: 0.00993776114752693, Valid Loss: 0.01174857447056171\n",
      "Epoch 88/100, Train Loss: 0.00993773406439454, Valid Loss: 0.011748623652536361\n",
      "Epoch 89/100, Train Loss: 0.009937707960170551, Valid Loss: 0.011748676091595425\n",
      "Epoch 90/100, Train Loss: 0.009937685336509761, Valid Loss: 0.011748730159196698\n",
      "Epoch 91/100, Train Loss: 0.009937666628482568, Valid Loss: 0.011748778689754465\n",
      "Epoch 92/100, Train Loss: 0.009937647050314576, Valid Loss: 0.011748815820516784\n",
      "Epoch 93/100, Train Loss: 0.009937617356759788, Valid Loss: 0.011748843505734304\n",
      "Epoch 94/100, Train Loss: 0.009937580158240604, Valid Loss: 0.011748877705120649\n",
      "Epoch 95/100, Train Loss: 0.009937548506869016, Valid Loss: 0.011748920698634913\n",
      "Epoch 96/100, Train Loss: 0.009937523381553428, Valid Loss: 0.011748964994982944\n",
      "Epoch 97/100, Train Loss: 0.009937498908843437, Valid Loss: 0.011749007662788767\n",
      "Epoch 98/100, Train Loss: 0.009937473892295448, Valid Loss: 0.011749050330594589\n",
      "Epoch 99/100, Train Loss: 0.009937449963423458, Valid Loss: 0.011749089741315997\n",
      "Epoch 100/100, Train Loss: 0.009937426360854268, Valid Loss: 0.011749133060538704\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습2: valid를 이용한 과적합 방지 epoch 찾기\n",
    "\n",
    "# 학습과 검증 손실을 저장할 리스트 초기화\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# # 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "#criterion = nn.BCELoss() # 모델 출력이 시그모이드 활성화 함수를 거쳐 확률로 변환된 후의 값을 입력으로 받음. 입력 값은 0과 1사이의 확률 값.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# 검증 데이터에 대한 모델 성능 평가 함수 정의\n",
    "def evaluate(model, criterion, dataloader):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in dataloader:\n",
    "            # 배치를 GPU로 전송\n",
    "            batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            \n",
    "            # 모델에 대한 순전파 및 손실 계산\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)  # 평균 손실 반환\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_features, batch_targets in train_loader:\n",
    "        # 배치를 GPU로 전송\n",
    "        batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "        # 모델에 대한 순전파 및 손실 계산\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # 에폭마다 학습 손실 기록\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # 검증 데이터에 대한 손실 계산 및 기록\n",
    "    valid_loss = evaluate(model, criterion, valid_loader)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # 에폭마다 손실 출력\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "\n",
    "# 손실 함수 시각화\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Valid Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Imbalance: Counter({1.0: 94, 0.0: 89})\n",
      "Accuracy: 0.4863\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        # 이진 분류를 가정하여 결과를 반올림하고, 스칼라 값으로 변환하여 리스트에 추가\n",
    "        preds = torch.round(outputs).squeeze().cpu().numpy()  # squeeze()를 사용하여 차원 축소\n",
    "        y_true.extend(labels.squeeze().cpu().numpy())  # labels도 동일하게 처리\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data Imbalance: {Counter(y_true)}')\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델학습3: Optuna + CV 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# sequence length를 기준으로 sequence 데이터 생성\u001b[39;00m\n\u001b[1;32m      9\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m# 20, 40, 80, 160, 320\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43msq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Tensor화\u001b[39;00m\n\u001b[1;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/논문/code/models/sequence.py:36\u001b[0m, in \u001b[0;36mcreate_sequence\u001b[0;34m(df, seq_len)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 시퀀스 내에 del_idx가 1인 행이 있다면, 해당 시퀀스를 제외\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sequence[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdel_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# 예측하고자 하는 마지막 피처의 값을 제외하고 스케일링\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     scaled_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdel_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_var\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# 스케일링된 시퀀스에 예측하고자 하는 마지막 피처의 값을 추가\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     scaled_sequence_with_target \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(scaled_sequence), sequence[target_var]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:435\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:473\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m     )\n\u001b[1;32m    472\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 473\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    481\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/utils/validation.py:790\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mapply(is_sparse)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    785\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    786\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame with sparse columns found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt will be converted to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m         )\n\u001b[0;32m--> 790\u001b[0m dtypes_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m)\n\u001b[1;32m    791\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    792\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    793\u001b[0m )\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/pandas/core/generic.py:6159\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;124;03mReturn the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   6134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6156\u001b[0m \u001b[38;5;124;03mdtype: object\u001b[39;00m\n\u001b[1;32m   6157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6158\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mget_dtypes()\n\u001b[0;32m-> 6159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_sliced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/pandas/core/series.py:499\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    497\u001b[0m         data \u001b[38;5;241m=\u001b[39m [data]\n\u001b[1;32m    498\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    500\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(data, index)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 / Optuna 용 -> valid 제거\n",
    "file_path = '../../data/' # for mac\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "df = df.iloc[-1000]\n",
    "df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (70% / 30%)\n",
    "split = int((X.size(0)) * 0.7)\n",
    "\n",
    "X_train_seq = X[:split]\n",
    "X_test_seq = X[split:]\n",
    "y_train_seq = y[:split]\n",
    "y_test_seq = y[split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 15:28:59,176] A new study created in memory with name: no-name-d6822665-db7f-4e2f-9eb1-f49e92bf51f4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 15:29:46,390] Trial 0 finished with value: 0.7014174699783325 and parameters: {'hidden_size': 10, 'num_layers': 2, 'lr': 0.1}. Best is trial 0 with value: 0.7014174699783325.\n",
      "[I 2024-02-28 15:30:57,182] Trial 1 finished with value: 0.7083777785301208 and parameters: {'hidden_size': 100, 'num_layers': 4, 'lr': 0.1}. Best is trial 0 with value: 0.7014174699783325.\n",
      "[I 2024-02-28 15:31:54,308] Trial 2 finished with value: 0.7014065384864807 and parameters: {'hidden_size': 25, 'num_layers': 3, 'lr': 0.1}. Best is trial 2 with value: 0.7014065384864807.\n",
      "[I 2024-02-28 15:33:07,379] Trial 3 finished with value: 0.7007116734981537 and parameters: {'hidden_size': 95, 'num_layers': 4, 'lr': 0.01}. Best is trial 3 with value: 0.7007116734981537.\n",
      "[I 2024-02-28 15:34:08,575] Trial 4 finished with value: 0.7073028862476349 and parameters: {'hidden_size': 50, 'num_layers': 3, 'lr': 0.1}. Best is trial 3 with value: 0.7007116734981537.\n",
      "[I 2024-02-28 15:35:36,268] Trial 5 finished with value: 0.8319100975990296 and parameters: {'hidden_size': 95, 'num_layers': 5, 'lr': 0.001}. Best is trial 3 with value: 0.7007116734981537.\n",
      "[I 2024-02-28 15:36:31,126] Trial 6 finished with value: 0.6982091009616852 and parameters: {'hidden_size': 95, 'num_layers': 2, 'lr': 0.0001}. Best is trial 6 with value: 0.6982091009616852.\n",
      "[I 2024-02-28 15:37:25,542] Trial 7 finished with value: 0.7056076526641846 and parameters: {'hidden_size': 85, 'num_layers': 2, 'lr': 0.01}. Best is trial 6 with value: 0.6982091009616852.\n",
      "[I 2024-02-28 15:38:55,724] Trial 8 finished with value: 0.7596176505088806 and parameters: {'hidden_size': 85, 'num_layers': 5, 'lr': 0.001}. Best is trial 6 with value: 0.6982091009616852.\n",
      "[I 2024-02-28 15:39:56,962] Trial 9 finished with value: 0.7099454998970032 and parameters: {'hidden_size': 100, 'num_layers': 2, 'lr': 0.1}. Best is trial 6 with value: 0.6982091009616852.\n",
      "[I 2024-02-28 15:41:03,436] Trial 10 finished with value: 0.6977709770202637 and parameters: {'hidden_size': 60, 'num_layers': 3, 'lr': 0.0001}. Best is trial 10 with value: 0.6977709770202637.\n",
      "[I 2024-02-28 15:42:14,503] Trial 11 finished with value: 0.699049311876297 and parameters: {'hidden_size': 65, 'num_layers': 3, 'lr': 0.0001}. Best is trial 10 with value: 0.6977709770202637.\n",
      "[I 2024-02-28 15:43:25,045] Trial 12 finished with value: 0.6980584979057312 and parameters: {'hidden_size': 50, 'num_layers': 2, 'lr': 0.0001}. Best is trial 10 with value: 0.6977709770202637.\n",
      "[I 2024-02-28 15:44:40,692] Trial 13 finished with value: 0.6969872713088989 and parameters: {'hidden_size': 50, 'num_layers': 3, 'lr': 0.0001}. Best is trial 13 with value: 0.6969872713088989.\n",
      "[I 2024-02-28 15:46:15,717] Trial 14 finished with value: 0.6972411453723908 and parameters: {'hidden_size': 65, 'num_layers': 4, 'lr': 0.0001}. Best is trial 13 with value: 0.6969872713088989.\n",
      "[I 2024-02-28 15:47:42,136] Trial 15 finished with value: 0.6982307016849518 and parameters: {'hidden_size': 35, 'num_layers': 4, 'lr': 0.0001}. Best is trial 13 with value: 0.6969872713088989.\n",
      "[I 2024-02-28 15:48:49,379] Trial 16 finished with value: 0.6980492770671844 and parameters: {'hidden_size': 70, 'num_layers': 4, 'lr': 0.0001}. Best is trial 13 with value: 0.6969872713088989.\n",
      "[I 2024-02-28 15:49:54,326] Trial 17 finished with value: 0.696724820137024 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:50:58,129] Trial 18 finished with value: 0.69744313955307 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:52:02,011] Trial 19 finished with value: 0.9157582461833954 and parameters: {'hidden_size': 20, 'num_layers': 5, 'lr': 0.001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:52:51,718] Trial 20 finished with value: 0.7588746547698975 and parameters: {'hidden_size': 40, 'num_layers': 3, 'lr': 0.01}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:53:49,845] Trial 21 finished with value: 0.6967857778072357 and parameters: {'hidden_size': 75, 'num_layers': 4, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:54:57,520] Trial 22 finished with value: 0.6989129304885864 and parameters: {'hidden_size': 75, 'num_layers': 5, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:55:55,700] Trial 23 finished with value: 0.6980346381664276 and parameters: {'hidden_size': 50, 'num_layers': 4, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:56:44,987] Trial 24 finished with value: 0.6970070362091064 and parameters: {'hidden_size': 30, 'num_layers': 3, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:57:50,634] Trial 25 finished with value: 0.6973746359348297 and parameters: {'hidden_size': 55, 'num_layers': 5, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:58:51,645] Trial 26 finished with value: 0.6990817427635193 and parameters: {'hidden_size': 80, 'num_layers': 4, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 15:59:41,826] Trial 27 finished with value: 0.6984017729759217 and parameters: {'hidden_size': 40, 'num_layers': 3, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 16:00:37,904] Trial 28 finished with value: 0.7303711712360382 and parameters: {'hidden_size': 15, 'num_layers': 4, 'lr': 0.001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 16:01:38,410] Trial 29 finished with value: 0.7251190185546875 and parameters: {'hidden_size': 10, 'num_layers': 5, 'lr': 0.01}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 16:02:32,534] Trial 30 finished with value: 0.6973938941955566 and parameters: {'hidden_size': 45, 'num_layers': 4, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 16:03:19,746] Trial 31 finished with value: 0.6995476722717285 and parameters: {'hidden_size': 30, 'num_layers': 3, 'lr': 0.0001}. Best is trial 17 with value: 0.696724820137024.\n",
      "[I 2024-02-28 16:04:10,372] Trial 32 finished with value: 0.687905079126358 and parameters: {'hidden_size': 5, 'num_layers': 3, 'lr': 0.0001}. Best is trial 32 with value: 0.687905079126358.\n",
      "[I 2024-02-28 16:05:02,231] Trial 33 finished with value: 0.7219882071018219 and parameters: {'hidden_size': 5, 'num_layers': 3, 'lr': 0.0001}. Best is trial 32 with value: 0.687905079126358.\n",
      "[I 2024-02-28 16:05:56,004] Trial 34 finished with value: 0.70503551363945 and parameters: {'hidden_size': 25, 'num_layers': 3, 'lr': 0.1}. Best is trial 32 with value: 0.687905079126358.\n",
      "[I 2024-02-28 16:06:49,951] Trial 35 finished with value: 0.6965234041213989 and parameters: {'hidden_size': 60, 'num_layers': 3, 'lr': 0.0001}. Best is trial 32 with value: 0.687905079126358.\n",
      "[W 2024-02-28 16:07:49,299] Trial 36 failed with parameters: {'hidden_size': 60, 'num_layers': 4, 'lr': 0.1} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_27359/1271495075.py\", line 47, in objective\n",
      "    optimizer.step()\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 373, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py\", line 163, in step\n",
      "    adam(\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py\", line 311, in adam\n",
      "    func(params,\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py\", line 385, in _single_tensor_adam\n",
      "    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n",
      "KeyboardInterrupt\n",
      "[W 2024-02-28 16:07:49,310] Trial 36 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Optuna 최적화 실행\u001b[39;00m\n\u001b[1;32m     67\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 시도 횟수는 10으로 설정\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     45\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     46\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 47\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 검증 손실 계산\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # 학습 3: Optuna + CV 추가\n",
    "# import optuna\n",
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# def objective(trial):\n",
    "#     # K-Fold 교차 검증 설정\n",
    "#     # k = 5  # 분할 수\n",
    "#     # kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "#     # TimeSeriesSplit 설정\n",
    "#     tscv = TimeSeriesSplit(n_splits=5, gap=0) # gap: valid 전 train 데이터의 마지막 몇개 데이터 포인트를 제거하느냐\n",
    "\n",
    "#     # 하이퍼파라미터 탐색 공간 정의\n",
    "#     input_size = X.size(-1) # LSTM: X.shape[2](n_features), CNN-LSTM: X.size() -> CNN내에서 X.size(1)(seq_len)으로 input 실행\n",
    "#     hidden_size = trial.suggest_int('hidden_size', 5, 100, step=5)\n",
    "#     num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "#     lr = trial.suggest_categorical('lr', [0.1, 0.01, 0.001, 0.0001])\n",
    "#     num_epochs = 100  # 에폭 수는 고정값으로 설정\n",
    "\n",
    "#     # 교차 검증을 위한 전체 손실 초기화\n",
    "#     total_loss = 0.0\n",
    "\n",
    "#     for train_idx, val_idx in tscv.split(X):\n",
    "#         # 훈련 데이터와 검증 데이터로 분할\n",
    "#         X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "#         y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "#         # DataLoader 설정\n",
    "#         train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "#         val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "#         val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "#         # 모델, 손실 함수, 옵티마이저 정의\n",
    "#         model = CNNLSTMModel(input_size, hidden_size, num_layers, num_classes=1).to(device)\n",
    "#         criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#         # 모델 훈련\n",
    "#         model.train()\n",
    "#         for epoch in range(num_epochs):\n",
    "#             for x_batch, y_batch in train_loader:\n",
    "#                 x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = model(x_batch)\n",
    "#                 loss = criterion(outputs, y_batch)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#         # 검증 손실 계산\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_loss = 0.0\n",
    "#             for x_batch, y_batch in val_loader:\n",
    "#                 x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "#                 outputs = model(x_batch)\n",
    "#                 loss = criterion(outputs, y_batch)\n",
    "#                 val_loss += loss.item()\n",
    "#             val_loss /= len(val_loader)\n",
    "\n",
    "#         total_loss += val_loss\n",
    "\n",
    "#     # 평균 검증 손실을 반환\n",
    "#     avg_loss = total_loss / 5\n",
    "#     return avg_loss\n",
    "\n",
    "# # Optuna 최적화 실행\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=50)  # 시도 횟수는 10으로 설정\n",
    "\n",
    "# print('Best trial:', study.best_trial.params)\n",
    "# print(\"Best trial's value:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Optuna(with. Pruner) + CV 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-02-28 16:16:41,673] A new study created in memory with name: no-name-73bf86af-931e-4d4c-a8a2-fd7a611f6576\n",
      "/opt/homebrew/lib/python3.8/site-packages/optuna/trial/_trial.py:499: UserWarning: The reported value is ignored because this `step` 99 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2024-02-28 16:17:30,765] Trial 0 finished with value: 0.7022524535655975 and parameters: {'hidden_size': 15, 'num_layers': 3, 'lr': 0.0001}. Best is trial 0 with value: 0.7022524535655975.\n",
      "[I 2024-02-28 16:18:14,471] Trial 1 finished with value: 0.6951237678527832 and parameters: {'hidden_size': 85, 'num_layers': 2, 'lr': 0.0001}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:18:59,529] Trial 2 finished with value: 0.6980426192283631 and parameters: {'hidden_size': 100, 'num_layers': 2, 'lr': 0.0001}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:19:49,678] Trial 3 finished with value: 0.7011891424655914 and parameters: {'hidden_size': 25, 'num_layers': 3, 'lr': 0.01}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:20:32,068] Trial 4 finished with value: 0.699713921546936 and parameters: {'hidden_size': 15, 'num_layers': 2, 'lr': 0.001}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:20:35,039] Trial 5 pruned. \n",
      "[I 2024-02-28 16:21:27,685] Trial 6 finished with value: 0.6978628933429718 and parameters: {'hidden_size': 75, 'num_layers': 3, 'lr': 0.0001}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:21:31,531] Trial 7 pruned. \n",
      "[I 2024-02-28 16:21:35,282] Trial 8 pruned. \n",
      "[I 2024-02-28 16:21:39,361] Trial 9 pruned. \n",
      "[I 2024-02-28 16:21:43,684] Trial 10 pruned. \n",
      "[I 2024-02-28 16:21:46,598] Trial 11 pruned. \n",
      "[I 2024-02-28 16:22:39,048] Trial 12 finished with value: 0.6969136714935302 and parameters: {'hidden_size': 75, 'num_layers': 3, 'lr': 0.0001}. Best is trial 1 with value: 0.6951237678527832.\n",
      "[I 2024-02-28 16:22:43,332] Trial 13 pruned. \n",
      "[I 2024-02-28 16:22:46,512] Trial 14 pruned. \n",
      "[I 2024-02-28 16:22:49,912] Trial 15 pruned. \n",
      "[I 2024-02-28 16:23:54,103] Trial 16 finished with value: 0.6929434239864349 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:24:59,802] Trial 17 finished with value: 0.697215735912323 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:26:10,322] Trial 18 finished with value: 0.696452796459198 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:26:14,445] Trial 19 pruned. \n",
      "[I 2024-02-28 16:26:19,116] Trial 20 pruned. \n",
      "[I 2024-02-28 16:27:22,262] Trial 21 finished with value: 0.6953979313373566 and parameters: {'hidden_size': 35, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:28:24,787] Trial 22 finished with value: 0.6976889610290528 and parameters: {'hidden_size': 30, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:29:20,415] Trial 23 finished with value: 0.7046750068664551 and parameters: {'hidden_size': 30, 'num_layers': 4, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:29:24,652] Trial 24 pruned. \n",
      "[I 2024-02-28 16:30:31,093] Trial 25 finished with value: 0.6971872985363007 and parameters: {'hidden_size': 45, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:30:37,063] Trial 26 pruned. \n",
      "[I 2024-02-28 16:30:42,164] Trial 27 pruned. \n",
      "[I 2024-02-28 16:30:46,178] Trial 28 pruned. \n",
      "[I 2024-02-28 16:31:50,847] Trial 29 finished with value: 0.6952159404754639 and parameters: {'hidden_size': 35, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:31:54,401] Trial 30 pruned. \n",
      "[I 2024-02-28 16:32:57,944] Trial 31 finished with value: 0.6968687117099762 and parameters: {'hidden_size': 35, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:34:01,363] Trial 32 finished with value: 0.6979646503925323 and parameters: {'hidden_size': 25, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:35:04,593] Trial 33 finished with value: 0.6986250638961792 and parameters: {'hidden_size': 35, 'num_layers': 5, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:36:02,522] Trial 34 finished with value: 0.6965474545955658 and parameters: {'hidden_size': 20, 'num_layers': 4, 'lr': 0.0001}. Best is trial 16 with value: 0.6929434239864349.\n",
      "[I 2024-02-28 16:36:48,992] Trial 35 finished with value: 0.6924559473991394 and parameters: {'hidden_size': 50, 'num_layers': 2, 'lr': 0.0001}. Best is trial 35 with value: 0.6924559473991394.\n",
      "[I 2024-02-28 16:36:52,160] Trial 36 pruned. \n",
      "[I 2024-02-28 16:36:55,265] Trial 37 pruned. \n",
      "[I 2024-02-28 16:36:58,221] Trial 38 pruned. \n",
      "[I 2024-02-28 16:37:01,852] Trial 39 pruned. \n",
      "[I 2024-02-28 16:37:04,966] Trial 40 pruned. \n",
      "[I 2024-02-28 16:37:08,366] Trial 41 pruned. \n",
      "[I 2024-02-28 16:38:13,440] Trial 42 finished with value: 0.6979423105716706 and parameters: {'hidden_size': 40, 'num_layers': 5, 'lr': 0.0001}. Best is trial 35 with value: 0.6924559473991394.\n",
      "[I 2024-02-28 16:38:17,253] Trial 43 pruned. \n",
      "[I 2024-02-28 16:38:20,684] Trial 44 pruned. \n",
      "[I 2024-02-28 16:39:26,507] Trial 45 finished with value: 0.6964085638523102 and parameters: {'hidden_size': 50, 'num_layers': 5, 'lr': 0.0001}. Best is trial 35 with value: 0.6924559473991394.\n",
      "[I 2024-02-28 16:40:23,882] Trial 46 finished with value: 0.7019116997718811 and parameters: {'hidden_size': 5, 'num_layers': 4, 'lr': 0.0001}. Best is trial 35 with value: 0.6924559473991394.\n",
      "[I 2024-02-28 16:40:26,945] Trial 47 pruned. \n",
      "[I 2024-02-28 16:40:30,577] Trial 48 pruned. \n",
      "[I 2024-02-28 16:40:34,856] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: {'hidden_size': 50, 'num_layers': 2, 'lr': 0.0001}\n",
      "Best trial's value: 0.6924559473991394\n"
     ]
    }
   ],
   "source": [
    "# 학습 4: Optuna(with. Pruner) + CV 추가\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "def objective(trial):\n",
    "    tscv = TimeSeriesSplit(n_splits=5, gap=0)\n",
    "\n",
    "    input_size = X.size(-1)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    lr = trial.suggest_categorical('lr', [0.01, 0.001, 0.0001])\n",
    "    num_epochs = 100\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        model = CNNLSTMModel(input_size, hidden_size, num_layers, num_classes=1).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        total_loss += val_loss\n",
    "\n",
    "        # Pruner를 위한 조기 중단 로직\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    avg_loss = total_loss / 5\n",
    "    return avg_loss\n",
    "\n",
    "# MedianPruner 초기화 및 Optuna 최적화 실행\n",
    "pruner = MedianPruner()\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(\"Best trial's value:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1180583119.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    best_model = CNNLSTMModel(input_size=input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 평가\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "input_size = X_test_seq.size(-1)\n",
    "\n",
    "# 모델을 최적의 하이퍼파라미터로 초기화\n",
    "best_model = CNNLSTMModel(input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "best_model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# 검증 데이터로 평가\n",
    "with torch.no_grad(): # 기울기 계산X -> 메모리 사용량, 속도 줄어듬\n",
    "    val_loss = 0.0\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "        outputs = best_model(x_batch)\n",
    "        preds = torch.round(outputs).cpu().numpy()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 성능 지표 계산\u001b[39;00m\n\u001b[1;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[0;32m---> 15\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_true, y_pred)\n\u001b[1;32m     17\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2131\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1974\u001b[0m     {\n\u001b[1;32m   1975\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2001\u001b[0m ):\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \n\u001b[1;32m   2004\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2131\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1724\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \n\u001b[1;32m   1568\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1724\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1518\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1517\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1519\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1520\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1523\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1529\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        preds = torch.round(outputs).cpu().numpy()  # 이진 분류를 가정\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

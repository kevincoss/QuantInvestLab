{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps 사용 가능 여부: True\n",
      "mps 지원 환경 여부: True\n",
      "mps is available\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 import\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 관련\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "# 성능 평가 관련\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 최적화\n",
    "import optuna\n",
    "\n",
    "# Visualization 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "'''\n",
    "딥러닝 학습을 진행할 때, 가중치를 임의의 값으로 초기화하여 학습을 수행하는 데,\n",
    "실험을 동일하게 진행하기 위해서는 난수를 동일하게 생성해야 한다.\n",
    "Pytorch에서 random seed를 고정하기 위해 manual_seed를 사용한다.\n",
    "'''\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 맥북 용\n",
    "# GPU 사용 가능 환경인지 확인 -> mac의 경우 GPU가 아는 MPS를 사용\n",
    "print(f\"mps 사용 가능 여부: {torch.backends.mps.is_available()}\")\n",
    "print(f\"mps 지원 환경 여부: {torch.backends.mps.is_built()}\")\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# 윈도우 용(Colab)\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (1000, 84)\n",
      "after:  (984, 81)\n",
      "          window_start           window_end  num_rows  lowest_return  \\\n",
      "0  2022-12-16 21:05:30  2022-12-16 21:06:00        14       0.000000   \n",
      "1  2022-12-16 21:06:00  2022-12-16 21:06:30        10       0.000000   \n",
      "2  2022-12-16 21:06:30  2022-12-16 21:07:00        24      -0.000576   \n",
      "3  2022-12-16 21:07:00  2022-12-16 21:07:30        22      -0.000044   \n",
      "4  2022-12-16 21:07:30  2022-12-16 21:08:00        24      -0.000443   \n",
      "\n",
      "   highest_return  high_low_gap  trade_vol  volume_power  beginning_price  \\\n",
      "0        0.000089      0.000089   1.468656      0.747351       22568000.0   \n",
      "1        0.000089      0.000089   0.567585      0.027857       22568000.0   \n",
      "2        0.000044      0.000620   1.677093      0.146635       22570000.0   \n",
      "3        0.000443      0.000488   2.439677      0.751995       22557000.0   \n",
      "4        0.000000      0.000443   2.345821     -0.915608       22565000.0   \n",
      "\n",
      "   ending_price  ...  ob_end_bp_14  ob_end_bs_14 ob_end_bias_0  ob_end_bias_1  \\\n",
      "0    22570000.0  ...    22545000.0      1.467714      5.470422      10.649683   \n",
      "1    22570000.0  ...    22544000.0      0.143039      4.224361      14.918538   \n",
      "2    22570000.0  ...    22541000.0      0.271898     17.677511       9.697905   \n",
      "3    22567000.0  ...    22541000.0      0.640898     95.630870       3.371113   \n",
      "4    22555000.0  ...    22539000.0      0.081040      0.114815       0.828364   \n",
      "\n",
      "   ob_end_bias_4  ob_end_bidask_spread  ob_end_liq_0  ob_end_liq_1  \\\n",
      "0       3.235541                   2.0      0.001693      0.002198   \n",
      "1       3.856600                   2.0      0.000531      0.001064   \n",
      "2       1.106227                  14.0      0.000449      0.000536   \n",
      "3       1.367349                   2.0      0.000416      0.000480   \n",
      "4       0.068175                  10.0      0.000311      0.000560   \n",
      "\n",
      "   ob_end_liq_4  highest_possible_return  \n",
      "0      0.002412                 1.000000  \n",
      "1      0.001471                 1.000000  \n",
      "2      0.001821                 0.999778  \n",
      "3      0.001422                 0.999911  \n",
      "4      0.003454                 0.999911  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_74105/3477799353.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_var['returns_next10m'] = target_var['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 0보다 작으면 0, 0보다 크면 1\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 셋 생성 함수\n",
    "# Sequence data를 만들어서 numpy array로 반환\n",
    "def build_dataset(data, seq_len):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(len(data)-seq_len):\n",
    "        x = data[i:i+seq_len, :]\n",
    "        y = data[i+seq_len, [-1]]\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_path = '../../data/' # for mac\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_9.csv')\n",
    "df = df.iloc[:1000]\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "print(\"before: \", df.shape)\n",
    "\n",
    "# 무한대에 해당하는 값 제거\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Data Preprocessing\n",
    "# 필요한 Feature만 추출한 데이터\n",
    "target_var = df[['returns', 'returns_next10m', 'realized_vol_next10m']] # 종속변수\n",
    "df.drop(columns=['returns', 'returns_next10m', 'realized_vol_next10m'], inplace=True) # 독립변수\n",
    "print(\"after: \", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# 독립변수 카테고리화\n",
    "target_var['returns_next10m'] = target_var['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 0보다 작으면 0, 0보다 크면 1\n",
    "\n",
    "# 독립변수 중 사용할 변수만 가져오기(+정규화)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df.drop(columns=['window_start', 'window_end', 'num_rows', 'time_id'])) # 위 변수를 제외한 모든 변수\n",
    "y = target_var['returns_next10m'].values # 종속변수\n",
    "\n",
    "# 성능을 기록할 데이터프레임\n",
    "#result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([688, 8, 77]) torch.Size([688, 1])\n",
      "torch.Size([288, 8, 77]) torch.Size([288, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_74105/1122436012.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  return torch.FloatTensor(x_seq).to(device), torch.FloatTensor(y_seq).to(device).view(-1,1)\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스 데이터 생성\n",
    "def seq_data(x, y, sequence_length):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x)-sequence_length):\n",
    "        x_seq.append(x[i:i+sequence_length]) # a[2:6] -> 2,3,4,5\n",
    "        y_seq.append(y[i+sequence_length])\n",
    "\n",
    "    # view를 사용하여 2차원으로 바꿈(MSE Loss가 기본적으로 2차원 타깃 데이터를 받음)\n",
    "    return torch.FloatTensor(x_seq).to(device), torch.FloatTensor(y_seq).to(device).view(-1,1)\n",
    "\n",
    "split = int(len(df)*0.7) # 70%를 학습 데이터로\n",
    "sequence_length = 8 # 30s * 5 = 2m 30s를 시퀀스 길이로\n",
    "x_seq, y_seq = seq_data(X, y, sequence_length)\n",
    "x_train_seq = x_seq[:split]\n",
    "y_train_seq = y_seq[:split]\n",
    "x_test_seq = x_seq[split:]\n",
    "y_test_seq = y_seq[split:]\n",
    "print(x_train_seq.size(), y_train_seq.size())\n",
    "print(x_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset과 DataLoader를 이용해 배치 데이터로 만든다.\n",
    "train = torch.utils.data.TensorDataset(x_train_seq, y_train_seq)\n",
    "test = torch.utils.data.TensorDataset(x_test_seq, y_test_seq)\n",
    "batch_size = 64\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False, drop_last=True) # 시계열 데이터기에 shuffle X, 마지막 batch 버림\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRUModel 클래스 정의\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, sequence_length, output_size, num_layers, device):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # 출력 크기를 1로 설정\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)  # self.hidden_dim -> self.hidden_size\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = torch.sigmoid(out)  # 시그모이드 활성화 함수 적용\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "input_size = x_train_seq.size(2) # feature 개수\n",
    "num_layers = 2 # 은닉층의 개수\n",
    "hidden_size = 10 # 은닉 상태를 저장하는 벡터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(input_size=77, \n",
    "                 hidden_size=12, \n",
    "                 sequence_length=sequence_length, \n",
    "                 output_size=1, \n",
    "                 num_layers=2,\n",
    "                 device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.7002\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.BCELoss()  # 손실 함수를 BCELoss로 변경\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # 입력 차원 추가\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.88%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # 모델을 평가 모드로 설정\n",
    "with torch.no_grad(): # 기울기 계산을 비활성화하여 메모리 사용량 줄이고 계산 속도 향상\n",
    "    correct = 0\n",
    "    total = 0 \n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float() # 출력이 0.5보다 크면 1, 아니면 0으로 예측\n",
    "        total += labels.size(0) # 테스트 데이터셋의 전체 샘플 수가 저장(labels.sze(0): 배치에서 레이블(정답)의 총 개수로 배치 크기와 동일)\n",
    "        correct += (predicted == labels).sum().item() # .item(): 스칼라 값(텐서)을 파이썬의 숫자 타입으로 변환\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 13:38:32,774] A new study created in memory with name: no-name-14a2e0e0-26bd-42f5-a80b-4c6fa5ad3f7b\n",
      "[I 2024-02-20 13:38:48,538] Trial 0 finished with value: 100.0 and parameters: {'sequence_length': 20}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 13:38:59,320] Trial 1 finished with value: 100.0 and parameters: {'sequence_length': 14}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 13:39:11,217] Trial 2 finished with value: 100.0 and parameters: {'sequence_length': 16}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 13:39:19,367] Trial 3 finished with value: 100.00000762939453 and parameters: {'sequence_length': 9}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 13:39:24,873] Trial 4 finished with value: 0.7356594204902649 and parameters: {'sequence_length': 6}. Best is trial 4 with value: 0.7356594204902649.\n",
      "[I 2024-02-20 13:39:38,668] Trial 5 finished with value: 100.0 and parameters: {'sequence_length': 18}. Best is trial 4 with value: 0.7356594204902649.\n",
      "[I 2024-02-20 13:39:39,498] Trial 6 pruned. \n",
      "[I 2024-02-20 13:39:46,353] Trial 7 finished with value: 0.5528890490531921 and parameters: {'sequence_length': 8}. Best is trial 7 with value: 0.5528890490531921.\n",
      "[I 2024-02-20 13:39:58,920] Trial 8 finished with value: 100.00000762939453 and parameters: {'sequence_length': 17}. Best is trial 7 with value: 0.5528890490531921.\n",
      "[I 2024-02-20 13:40:03,578] Trial 9 finished with value: 0.7552491426467896 and parameters: {'sequence_length': 5}. Best is trial 7 with value: 0.5528890490531921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.5528890490531921\n",
      "Params: \n",
      "    sequence_length: 8\n"
     ]
    }
   ],
   "source": [
    "def build_sequences(X, y, sequence_length):\n",
    "    \"\"\"입력 데이터와 타깃 데이터를 받아 sequence_length에 맞게 데이터를 재조정하는 함수\"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:(i + sequence_length)])\n",
    "        y_seq.append(y[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    sequence_length = trial.suggest_int('sequence_length', 5, 20)\n",
    "\n",
    "    # 데이터를 sequence_length에 맞게 재조정\n",
    "    X_seq, y_seq = build_sequences(X, y, sequence_length)\n",
    "    X_seq, y_seq = torch.FloatTensor(X_seq).to(device), torch.FloatTensor(y_seq).to(device).view(-1, 1)\n",
    "    \n",
    "    # 데이터셋과 데이터로더 준비\n",
    "    dataset = TensorDataset(X_seq, y_seq)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # 모델, 옵티마이저, 손실 함수 설정\n",
    "    model = GRUModel(input_size=X_seq.size(2), hidden_size=hidden_size, sequence_length=sequence_length,\n",
    "                     output_size=1, num_layers=num_layers, device=device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # 훈련 과정\n",
    "    for epoch in range(num_epochs):\n",
    "        for x_batch, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 조기 종료 조건 검사\n",
    "        trial.report(loss.item(), epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# MedianPruner 추가\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "\n",
    "# Optuna 최적화 실행, pruner 인자 추가\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'Value: {trial.value}')\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 13:40:48,944] A new study created in memory with name: no-name-f1803199-bd75-413f-ad75-384bfa5a6224\n",
      "[I 2024-02-20 13:54:29,763] Trial 0 finished with value: 100.0 and parameters: {'num_layers': 9, 'hidden_size': 3, 'num_epochs': 516, 'lr': 0.01}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 14:02:10,625] Trial 1 finished with value: 100.0 and parameters: {'num_layers': 6, 'hidden_size': 5, 'num_epochs': 404, 'lr': 0.01}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 14:11:36,488] Trial 2 finished with value: 100.0 and parameters: {'num_layers': 4, 'hidden_size': 6, 'num_epochs': 721, 'lr': 0.0001}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 14:34:55,417] Trial 3 finished with value: 100.0 and parameters: {'num_layers': 6, 'hidden_size': 7, 'num_epochs': 916, 'lr': 0.0001}. Best is trial 0 with value: 100.0.\n",
      "[I 2024-02-20 14:44:55,128] Trial 4 finished with value: 0.6383315920829773 and parameters: {'num_layers': 2, 'hidden_size': 9, 'num_epochs': 926, 'lr': 0.0001}. Best is trial 4 with value: 0.6383315920829773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.6383315920829773\n",
      "Params: \n",
      "    num_layers: 2\n",
      "    hidden_size: 9\n",
      "    num_epochs: 926\n",
      "    lr: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tunning\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    input_size = x_train_seq.size(2) # feature 개수\n",
    "    output_size = 1\n",
    "    sequence_length = 8\n",
    "    #sequence_length = trial.suggest_int('sequence_length', 5, 20)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 10)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 2, 10)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 200, 1000)\n",
    "    #dropout = trial.suggest_categorical('dropout', [0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    lr = trial.suggest_categorical('lr', [1e-4, 1e-3, 1e-2])\n",
    "\n",
    "    model = GRUModel(input_size=input_size, hidden_size=hidden_size, sequence_length=sequence_length,\n",
    "                     output_size=output_size, num_layers=num_layers, device=device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # 훈련\n",
    "    for epoch in range(num_epochs):\n",
    "        for x_batch, labels in train_loader:\n",
    "            x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "         # 조기 종료 검사\n",
    "        trial.report(loss.item(), epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# MedianPruner 추가\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "\n",
    "# Optuna 최적화 실행\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'Value: {trial.value}')\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/926], Loss: 0.6947\n",
      "Epoch [20/926], Loss: 0.6928\n",
      "Epoch [30/926], Loss: 0.6908\n",
      "Epoch [40/926], Loss: 0.6888\n",
      "Epoch [50/926], Loss: 0.6869\n",
      "Epoch [60/926], Loss: 0.6850\n",
      "Epoch [70/926], Loss: 0.6831\n",
      "Epoch [80/926], Loss: 0.6812\n",
      "Epoch [90/926], Loss: 0.6794\n",
      "Epoch [100/926], Loss: 0.6778\n",
      "Epoch [110/926], Loss: 0.6763\n",
      "Epoch [120/926], Loss: 0.6749\n",
      "Epoch [130/926], Loss: 0.6737\n",
      "Epoch [140/926], Loss: 0.6725\n",
      "Epoch [150/926], Loss: 0.6715\n",
      "Epoch [160/926], Loss: 0.6705\n",
      "Epoch [170/926], Loss: 0.6696\n",
      "Epoch [180/926], Loss: 0.6687\n",
      "Epoch [190/926], Loss: 0.6679\n",
      "Epoch [200/926], Loss: 0.6672\n",
      "Epoch [210/926], Loss: 0.6664\n",
      "Epoch [220/926], Loss: 0.6656\n",
      "Epoch [230/926], Loss: 0.6649\n",
      "Epoch [240/926], Loss: 0.6641\n",
      "Epoch [250/926], Loss: 0.6632\n",
      "Epoch [260/926], Loss: 0.6623\n",
      "Epoch [270/926], Loss: 0.6613\n",
      "Epoch [280/926], Loss: 0.6602\n",
      "Epoch [290/926], Loss: 0.6589\n",
      "Epoch [300/926], Loss: 0.6577\n",
      "Epoch [310/926], Loss: 0.6569\n",
      "Epoch [320/926], Loss: 0.6560\n",
      "Epoch [330/926], Loss: 0.6544\n",
      "Epoch [340/926], Loss: 0.6528\n",
      "Epoch [350/926], Loss: 0.6501\n",
      "Epoch [360/926], Loss: 0.6535\n",
      "Epoch [370/926], Loss: 0.6578\n",
      "Epoch [380/926], Loss: 0.6522\n",
      "Epoch [390/926], Loss: 0.6518\n",
      "Epoch [400/926], Loss: 0.6477\n",
      "Epoch [410/926], Loss: 0.6439\n",
      "Epoch [420/926], Loss: 0.6458\n",
      "Epoch [430/926], Loss: 0.6452\n",
      "Epoch [440/926], Loss: 0.6447\n",
      "Epoch [450/926], Loss: 0.6443\n",
      "Epoch [460/926], Loss: 0.6438\n",
      "Epoch [470/926], Loss: 0.6434\n",
      "Epoch [480/926], Loss: 0.6428\n",
      "Epoch [490/926], Loss: 0.6422\n",
      "Epoch [500/926], Loss: 0.6415\n",
      "Epoch [510/926], Loss: 0.6409\n",
      "Epoch [520/926], Loss: 0.6402\n",
      "Epoch [530/926], Loss: 0.6395\n",
      "Epoch [540/926], Loss: 0.6388\n",
      "Epoch [550/926], Loss: 0.6381\n",
      "Epoch [560/926], Loss: 0.6374\n",
      "Epoch [570/926], Loss: 0.6366\n",
      "Epoch [580/926], Loss: 0.6359\n",
      "Epoch [590/926], Loss: 0.6351\n",
      "Epoch [600/926], Loss: 0.6343\n",
      "Epoch [610/926], Loss: 0.6335\n",
      "Epoch [620/926], Loss: 0.6326\n",
      "Epoch [630/926], Loss: 0.6315\n",
      "Epoch [640/926], Loss: 0.6302\n",
      "Epoch [650/926], Loss: 0.6289\n",
      "Epoch [660/926], Loss: 0.6275\n",
      "Epoch [670/926], Loss: 0.6260\n",
      "Epoch [680/926], Loss: 0.6229\n",
      "Epoch [690/926], Loss: 0.6228\n",
      "Epoch [700/926], Loss: 0.6259\n",
      "Epoch [710/926], Loss: 0.6246\n",
      "Epoch [720/926], Loss: 0.6242\n",
      "Epoch [730/926], Loss: 0.6255\n",
      "Epoch [740/926], Loss: 0.6231\n",
      "Epoch [750/926], Loss: 0.6202\n",
      "Epoch [760/926], Loss: 0.6172\n",
      "Epoch [770/926], Loss: 0.6147\n",
      "Epoch [780/926], Loss: 0.6121\n",
      "Epoch [790/926], Loss: 0.6083\n",
      "Epoch [800/926], Loss: 0.6080\n",
      "Epoch [810/926], Loss: 0.6069\n",
      "Epoch [820/926], Loss: 0.6065\n",
      "Epoch [830/926], Loss: 0.6057\n",
      "Epoch [840/926], Loss: 0.6048\n",
      "Epoch [850/926], Loss: 0.6009\n",
      "Epoch [860/926], Loss: 0.5984\n",
      "Epoch [870/926], Loss: 0.5968\n",
      "Epoch [880/926], Loss: 0.5951\n",
      "Epoch [890/926], Loss: 0.5942\n",
      "Epoch [900/926], Loss: 0.5933\n",
      "Epoch [910/926], Loss: 0.5923\n",
      "Epoch [920/926], Loss: 0.5918\n",
      "Accuracy: 0.3715\n",
      "Precision: 0.3715\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5418\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 최적 하이퍼파라미터 사용하여 모델 초기화\n",
    "best_trial = study.best_trial\n",
    "model = GRUModel(\n",
    "    input_size=x_train_seq.size(2),\n",
    "    hidden_size=best_trial.params['hidden_size'],\n",
    "    sequence_length=8,\n",
    "    output_size=1,\n",
    "    num_layers=best_trial.params['num_layers'],\n",
    "    device=device).to(device)\n",
    "\n",
    "# 모델 훈련을 위한 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_trial.params['lr'])  # 최적화 알고리즘 설정\n",
    "criterion = nn.BCELoss()  # 손실 함수 설정 (이진 분류를 가정)\n",
    "\n",
    "# 훈련 과정 설정\n",
    "num_epochs = best_trial.params['num_epochs']  # 에폭 수\n",
    "\n",
    "# 훈련 시작\n",
    "model.train()  # 모델을 훈련 모드로 설정\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, labels in train_loader:\n",
    "        x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "        \n",
    "        # 순전파: 모델에 데이터를 입력하여 예측값을 계산\n",
    "        outputs = model(x_batch)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 역전파: 손실에 대한 모델의 매개변수들의 미분값을 계산\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        loss.backward()  # 역전파 실행\n",
    "        \n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에폭마다 진행 상황 출력\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        preds = torch.round(outputs).cpu().numpy()  # 이진 분류를 가정\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 메트릭 초기화\n",
    "accuracy = torchmetrics.Accuracy().to(device)\n",
    "precision = torchmetrics.Precision().to(device)\n",
    "recall = torchmetrics.Recall().to(device)\n",
    "f1 = torchmetrics.F1().to(device)\n",
    "\n",
    "# 예측값과 실제값을 저장할 리스트 초기화\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        \n",
    "        # 클래스 예측값을 계산합니다 (이진 분류의 경우)\n",
    "        preds = torch.round(outputs)\n",
    "        \n",
    "        # 메트릭 업데이트\n",
    "        accuracy(preds, labels.int())\n",
    "        precision(preds, labels.int())\n",
    "        recall(preds, labels.int())\n",
    "        f1(preds, labels.int())\n",
    "        \n",
    "        # 혼동 행렬을 위해 예측값과 실제값 저장\n",
    "        y_pred_list.extend(preds.view(-1).cpu().numpy())\n",
    "        y_true_list.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "# 메트릭 출력\n",
    "print(f'Accuracy: {accuracy.compute()}')\n",
    "print(f'Precision: {precision.compute()}')\n",
    "print(f'Recall: {recall.compute()}')\n",
    "print(f'F1 Score: {f1.compute()}')\n",
    "\n",
    "# 혼동 행렬 계산 및 출력\n",
    "conf_mat = confusion_matrix(y_true_list, y_pred_list)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

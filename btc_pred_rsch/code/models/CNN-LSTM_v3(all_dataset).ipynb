{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM_v3\n",
    "\n",
    "- 파이썬 버전: 3.8.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library 불러오기, SEED 설정, CUDA 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 PC는 맥(OS X) 운영 체제입니다: mps is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 import\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 관련\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sequence as sq # 사용자 정의 함수 불러오기\n",
    "\n",
    "# 성능 평가 관련\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 운영체제 관련\n",
    "import platform\n",
    "\n",
    "'''\n",
    "딥러닝 학습을 진행할 때, 가중치를 임의의 값으로 초기화하여 학습을 수행하는 데, \n",
    "실험을 동일하게 진행하기 위해서는 난수를 동일하게 생성해야 한다.\n",
    "Pytorch에서 random seed를 고정하기 위해 manual_seed를 사용한다.\n",
    "'''\n",
    "\n",
    "# set seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)  # 멀티 GPU 사용 시\n",
    "# GPU에서 실행할 때, CUDNN 자동 튜너의 비결정적 행동을 방지하기 위해 이를 설정\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 운영체제별 device 설정\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"이 PC는 윈도우 운영 체제입니다: {device} is available\")\n",
    "elif os_name == 'Darwin':\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")\n",
    "    print(f\"이 PC는 맥(OS X) 운영 체제입니다: {device} is available\")\n",
    "else:\n",
    "    print(f\"이 PC는 다른 운영 체제입니다: {os_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 전처리 (Binary, Scale, Tensor, train&valid&test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (151838, 84)\n",
      "after:  (151838, 81)\n",
      "          window_start           window_end  num_rows  lowest_return  \\\n",
      "0  2022-12-16 21:05:30  2022-12-16 21:06:00        14       0.000000   \n",
      "1  2022-12-16 21:06:00  2022-12-16 21:06:30        10       0.000000   \n",
      "2  2022-12-16 21:06:30  2022-12-16 21:07:00        24      -0.000576   \n",
      "3  2022-12-16 21:07:00  2022-12-16 21:07:30        22      -0.000044   \n",
      "4  2022-12-16 21:07:30  2022-12-16 21:08:00        24      -0.000443   \n",
      "\n",
      "   highest_return  high_low_gap  trade_vol  volume_power  beginning_price  \\\n",
      "0        0.000089      0.000089   1.468656      0.747351       22568000.0   \n",
      "1        0.000089      0.000089   0.567585      0.027857       22568000.0   \n",
      "2        0.000044      0.000620   1.677093      0.146635       22570000.0   \n",
      "3        0.000443      0.000488   2.439677      0.751995       22557000.0   \n",
      "4        0.000000      0.000443   2.345821     -0.915608       22565000.0   \n",
      "\n",
      "   ending_price  ...  ob_end_bp_14  ob_end_bs_14 ob_end_bias_0  ob_end_bias_1  \\\n",
      "0    22570000.0  ...    22545000.0      1.467714      5.470422      10.649683   \n",
      "1    22570000.0  ...    22544000.0      0.143039      4.224361      14.918538   \n",
      "2    22570000.0  ...    22541000.0      0.271898     17.677511       9.697905   \n",
      "3    22567000.0  ...    22541000.0      0.640898     95.630870       3.371113   \n",
      "4    22555000.0  ...    22539000.0      0.081040      0.114815       0.828364   \n",
      "\n",
      "   ob_end_bias_4  ob_end_bidask_spread  ob_end_liq_0  ob_end_liq_1  \\\n",
      "0       3.235541                   2.0      0.001693      0.002198   \n",
      "1       3.856600                   2.0      0.000531      0.001064   \n",
      "2       1.106227                  14.0      0.000449      0.000536   \n",
      "3       1.367349                   2.0      0.000416      0.000480   \n",
      "4       0.068175                  10.0      0.000311      0.000560   \n",
      "\n",
      "   ob_end_liq_4  highest_possible_return  \n",
      "0      0.002412                 1.000000  \n",
      "1      0.001471                 1.000000  \n",
      "2      0.001821                 0.999778  \n",
      "3      0.001422                 0.999911  \n",
      "4      0.003454                 0.999911  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_29266/2088436790.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_var['returns_next10m'] = target_var['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 0보다 작으면 0, 0보다 크면 1\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "file_path = '../../data/'\n",
    "df = pd.read_csv(file_path + 'BTC_sum_both_30s_202303271051_v1.csv')\n",
    "#df = df.iloc[:10000]\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "print(\"before: \", df.shape)\n",
    "\n",
    "# Data Preprocessing\n",
    "# 필요한 Feature만 추출한 데이터\n",
    "target_var = df[['returns', 'returns_next10m', 'realized_vol_next10m']] # 종속변수\n",
    "df.drop(columns=['returns', 'returns_next10m', 'realized_vol_next10m'], inplace=True) # 독립변수\n",
    "print(\"after: \", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# 무한대에 해당하는 값 제거\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 독립변수 카테고리화\n",
    "target_var['returns_next10m'] = target_var['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 0보다 작으면 0, 0보다 크면 1\n",
    "\n",
    "# 독립변수 중 사용할 변수만 가져오기(+정규화)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df.drop(columns=['window_start', 'window_end', 'num_rows', 'time_id'])) # 위 변수를 제외한 모든 변수\n",
    "y = target_var['returns_next10m'].values # 종속변수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_29266/523404300.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  return torch.FloatTensor(x_seq).to(device), torch.FloatTensor(y_seq).to(device).view(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89735, 20, 77]) torch.Size([89735, 1])\n",
      "torch.Size([29912, 20, 77]) torch.Size([29912, 1])\n",
      "torch.Size([29892, 20, 77]) torch.Size([29892, 1])\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스 데이터 생성\n",
    "def seq_data(x, y, sequence_length):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x)-sequence_length):\n",
    "        x_seq.append(x[i:i+sequence_length]) # a[2:6] -> 2,3,4,5\n",
    "        y_seq.append(y[i+sequence_length])\n",
    "    \n",
    "    # view를 사용하여 2차원으로 바꿈(MSE Loss가 기본적으로 2차원 타깃 데이터를 받음)\n",
    "    return torch.FloatTensor(x_seq).to(device), torch.FloatTensor(y_seq).to(device).view(-1,1) \n",
    "\n",
    "\n",
    "sequence_length = 20 # 30s * 5 = 2m 30s를 시퀀스 길이로\n",
    "x_seq, y_seq = seq_data(X, y, sequence_length)\n",
    "\n",
    "train_split = int(len(df)*0.6) # 70%를 학습 데이터로\n",
    "valid_split = int(len(df)*0.8) # 70%를 학습 데이터로\n",
    "\n",
    "x_train_seq = x_seq[:train_split]\n",
    "y_train_seq = y_seq[:train_split]\n",
    "x_valid_seq = x_seq[train_split:valid_split]\n",
    "y_valid_seq = y_seq[train_split:valid_split]\n",
    "x_test_seq = x_seq[valid_split:]\n",
    "y_test_seq = y_seq[valid_split:]\n",
    "print(x_train_seq.size(), y_train_seq.size())\n",
    "print(x_valid_seq.size(), y_valid_seq.size())\n",
    "print(x_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 불러오기\n",
    "# file_path = '../../data/' # 경로 설정\n",
    "# df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "# #df = df.iloc[:10000]\n",
    "# #df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "# df['returns_next10m_binary'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "# df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# # sequence length를 기준으로 sequence 데이터 생성\n",
    "# seq_len = 20 # 20, 40, 80, 160, 320\n",
    "# #X, y = sq.create_sequence(df, seq_len=seq_len) # 사용자 정의 함수\n",
    "# X, y, y_for_backtest = sq.createSeqForBacktest(df, seq_len=seq_len)\n",
    "\n",
    "# # Tensor화\n",
    "# X = torch.FloatTensor(X).to(device)\n",
    "# y = torch.FloatTensor(y).to(device)\n",
    "# print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# # split (60% / 20% / 20%)\n",
    "# train_split = int((X.size(0)) * 0.6)\n",
    "# valid_split = int((X.size(0)) * 0.8)\n",
    "\n",
    "# X_train_seq = X[:train_split]\n",
    "# X_val_seq = X[train_split:valid_split]\n",
    "# X_test_seq = X[valid_split:]\n",
    "# y_train_seq = y[:train_split]\n",
    "# y_val_seq = y[train_split:valid_split]\n",
    "# y_test_seq = y[valid_split:]\n",
    "# y_test_bt = y_for_backtest[valid_split:] # for backtest\n",
    "\n",
    "# print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "# print('Valid Size:', X_val_seq.size(), y_val_seq.size())\n",
    "# print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset과 DataLoader를 이용해 배치 데이터로 만든다.\n",
    "train = torch.utils.data.TensorDataset(x_train_seq, y_train_seq)\n",
    "valid = torch.utils.data.TensorDataset(x_valid_seq, y_valid_seq)\n",
    "test = torch.utils.data.TensorDataset(x_test_seq, y_test_seq)\n",
    "batch_size = 128 # 32, 64, 128\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False, drop_last=True) # 시계열 데이터기에 shuffle X, 마지막 batch 버림\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(77, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN 레이어\n",
    "        '''\n",
    "        in_channels = 일반적인 이미지와 같은 2D 데이터를 다룰 때는 특성 맵(channel)을 채널로 인식함.\n",
    "        그러나 주식 시계열 데이터와 같은 1D 데이터의 경우 시퀀스 길이에 해당하는 차원이 채널로 간주됨.\n",
    "        이에 따라 'in_channels'에는 시퀀스 길이를 입력해야 함.\n",
    "        즉, 주식 시게열 데이터에서는 'in_channels'에는 시퀀스의 길이가 들어가야 올바르게 수행됨.\n",
    "        '''\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Fully Connected 레이어\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 레이어 적용 (cnn takes input of shape (batch_size, channels, seq_len))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn(x)\n",
    "        \n",
    "        # LSTM 레이어 적용\n",
    "        '''\n",
    "        LSTM 레이어에 입력을 전달하고, LSTM의 출력과 은닉 상태를 받는 부분\n",
    "        x.permute(0, 2, 1): 입력텐서 x의 차원을 변경. 일반적으로 LSTM 레이어는 시간 단계(seq_len)를 두 번쨰 차원으로 받지만,\n",
    "        Conv1d 레이어의 출력은 시간 단계가 세번째 차원에 위치함. 따라서 permute를 통해 차원을 변경하여 LSTM 레이어에 올바른 형태의 입력을 제공\n",
    "        여기서 0번째 차원은 배치 크기(batch_size)를 나타내며, 1번째 차원은 특성 수(num_features)를 나타냄. 마지막(2번째) 차원은 시간 단계(seq_len)를 나타냄\n",
    "        self.lstm(x.permute(0, 2, 1)): 변경된 입력을 LSTM 레이어에 전달함. LSTM 입력으로 3D 텐서를 받으며,\n",
    "        이 텐서는 배치 크기(batch_size), 시간 단계(seq_len),. 특성 수(num_features)의 형태를 가짐\n",
    "        lstm_out, _: LSTM 레이어의 출력과 은닉 상태를 받음. 여기서 은닉 상태는 사용하지 않기 때문에 '_'로 무시. lstm_out은 LSTM 레이어의 출력으로, 각 시간 단계에\n",
    "        해당하는 출력을 포함하는 3D 텐서임.\n",
    "        '''\n",
    "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(out)\n",
    "        \n",
    "        # Fully Connected 레이어에 입력\n",
    "        '''\n",
    "        lstm_out[:, -1, :]: LSTM 레이어의 출력에서 마지막 시간 단계의 출력만 선택. 이는 시퀀스 예측을 위해 마지막 시간 단계의 정보만을 사용하고자 하는 것\n",
    "        따라서 [:, -1, :]는 모든 배치와 모든 특성을 유지하면서 마지막 시간 단계의 출력을 선택함\n",
    "        self.fc(lstm_out[:, -1, :]): 선택된 마지막 시간 단계의 출력을 Fully Connected(FC) 레이어에 입력함. FC 레이어는 입력된 LSTM 출력을 받아서 최종\n",
    "        예측을 수행하는 역할을 함. 출력 크기는 1이며, 이는 주어진 입력에 대한 예측된 결과를 나타냄.\n",
    "        '''\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "#model = CNNLSTMModel(input_size=77, hidden_size=64, num_layers=2, num_classes=1)\n",
    "model = CNNLSTMModel(input_size=77, hidden_size=64, num_layers=2, num_classes=1)\n",
    "model.to(device) # GPU 사용 시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델학습1: train, valid를 이용한 과적합 방지되는 epochs 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습1: valid를 이용한 과적합 방지 epochs 찾기\n",
    "\n",
    "# # 학습과 검증 손실을 저장할 리스트 초기화\n",
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "\n",
    "# # # 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "# #criterion = nn.BCELoss() # 모델 출력이 시그모이드 활성화 함수를 거쳐 확률로 변환된 후의 값을 입력으로 받음. 입력 값은 0과 1사이의 확률 값.\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 100\n",
    "\n",
    "# # 검증 데이터에 대한 모델 성능 평가 함수 정의\n",
    "# def evaluate(model, criterion, dataloader):\n",
    "#     model.eval()  # 모델을 평가 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_features, batch_targets in dataloader:\n",
    "#             # 배치를 GPU로 전송\n",
    "#             batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            \n",
    "#             # 모델에 대한 순전파 및 손실 계산\n",
    "#             outputs = model(batch_features)\n",
    "#             loss = criterion(outputs, batch_targets)\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     return total_loss / len(dataloader.dataset)  # 평균 손실 반환\n",
    "\n",
    "# # 학습 루프\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # 모델을 학습 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     for batch_features, batch_targets in train_loader:\n",
    "#         # 배치를 GPU로 전송\n",
    "#         batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "#         # 모델에 대한 순전파 및 손실 계산\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "#         # 역전파 및 최적화\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     # 에폭마다 학습 손실 기록\n",
    "#     train_loss = total_loss / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "#     # 검증 데이터에 대한 손실 계산 및 기록\n",
    "#     valid_loss = evaluate(model, criterion, valid_loader)\n",
    "#     valid_losses.append(valid_loss)\n",
    "    \n",
    "#     # 에폭마다 손실 출력\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "\n",
    "# # 손실 함수 시각화\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(valid_losses, label='Valid Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델학습2: 모델학습1에서 구한 epochs를 기준으로 train 데이터만 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 485.84566205739975\n",
      "Epoch 2/100, Loss: 485.81628608703613\n",
      "Epoch 3/100, Loss: 485.836544752121\n",
      "Epoch 4/100, Loss: 485.8656451702118\n",
      "Epoch 5/100, Loss: 485.8829475045204\n",
      "Epoch 6/100, Loss: 485.8968893289566\n",
      "Epoch 7/100, Loss: 485.9001671075821\n",
      "Epoch 8/100, Loss: 485.91155701875687\n",
      "Epoch 9/100, Loss: 485.91633850336075\n",
      "Epoch 10/100, Loss: 485.92055094242096\n",
      "Epoch 11/100, Loss: 485.918395280838\n",
      "Epoch 12/100, Loss: 485.92063784599304\n",
      "Epoch 13/100, Loss: 485.9231938123703\n",
      "Epoch 14/100, Loss: 485.92320162057877\n",
      "Epoch 15/100, Loss: 485.9241887331009\n",
      "Epoch 16/100, Loss: 485.9248147010803\n",
      "Epoch 17/100, Loss: 485.92394441366196\n",
      "Epoch 18/100, Loss: 485.9230046272278\n",
      "Epoch 19/100, Loss: 485.92039889097214\n",
      "Epoch 20/100, Loss: 485.91593128442764\n",
      "Epoch 21/100, Loss: 485.91266989707947\n",
      "Epoch 22/100, Loss: 485.90787702798843\n",
      "Epoch 23/100, Loss: 485.90440875291824\n",
      "Epoch 24/100, Loss: 485.89382004737854\n",
      "Epoch 25/100, Loss: 485.884153008461\n",
      "Epoch 26/100, Loss: 485.8771513700485\n",
      "Epoch 27/100, Loss: 485.87162631750107\n",
      "Epoch 28/100, Loss: 485.861941576004\n",
      "Epoch 29/100, Loss: 485.85328567028046\n",
      "Epoch 30/100, Loss: 485.8447828888893\n",
      "Epoch 31/100, Loss: 485.8350767493248\n",
      "Epoch 32/100, Loss: 485.82673370838165\n",
      "Epoch 33/100, Loss: 485.8140895962715\n",
      "Epoch 34/100, Loss: 485.79518926143646\n",
      "Epoch 35/100, Loss: 485.7846802473068\n",
      "Epoch 36/100, Loss: 485.7558743953705\n",
      "Epoch 37/100, Loss: 485.7571515440941\n",
      "Epoch 38/100, Loss: 485.72251868247986\n",
      "Epoch 39/100, Loss: 485.7251062989235\n",
      "Epoch 40/100, Loss: 485.668836414814\n",
      "Epoch 41/100, Loss: 485.7125076055527\n",
      "Epoch 42/100, Loss: 485.66370636224747\n",
      "Epoch 43/100, Loss: 485.6741515994072\n",
      "Epoch 44/100, Loss: 485.5967266559601\n",
      "Epoch 45/100, Loss: 485.6376891732216\n",
      "Epoch 46/100, Loss: 485.59986132383347\n",
      "Epoch 47/100, Loss: 485.57671028375626\n",
      "Epoch 48/100, Loss: 485.5491527915001\n",
      "Epoch 49/100, Loss: 485.53153067827225\n",
      "Epoch 50/100, Loss: 485.49815636873245\n",
      "Epoch 51/100, Loss: 485.4834757447243\n",
      "Epoch 52/100, Loss: 485.4483474493027\n",
      "Epoch 53/100, Loss: 485.44024473428726\n",
      "Epoch 54/100, Loss: 485.4058583974838\n",
      "Epoch 55/100, Loss: 485.377101957798\n",
      "Epoch 56/100, Loss: 485.3602691888809\n",
      "Epoch 57/100, Loss: 485.3396766781807\n",
      "Epoch 58/100, Loss: 485.32262367010117\n",
      "Epoch 59/100, Loss: 485.3044615983963\n",
      "Epoch 60/100, Loss: 485.2839213013649\n",
      "Epoch 61/100, Loss: 485.26131159067154\n",
      "Epoch 62/100, Loss: 485.2394106388092\n",
      "Epoch 63/100, Loss: 485.218457698822\n",
      "Epoch 64/100, Loss: 485.1977812051773\n",
      "Epoch 65/100, Loss: 485.177662730217\n",
      "Epoch 66/100, Loss: 485.1582623720169\n",
      "Epoch 67/100, Loss: 485.139496922493\n",
      "Epoch 68/100, Loss: 485.1210989356041\n",
      "Epoch 69/100, Loss: 485.1019239425659\n",
      "Epoch 70/100, Loss: 485.08123445510864\n",
      "Epoch 71/100, Loss: 485.05904430150986\n",
      "Epoch 72/100, Loss: 485.03711622953415\n",
      "Epoch 73/100, Loss: 485.02093720436096\n",
      "Epoch 74/100, Loss: 485.01177394390106\n",
      "Epoch 75/100, Loss: 484.9987158179283\n",
      "Epoch 76/100, Loss: 484.958231151104\n",
      "Epoch 77/100, Loss: 484.93642896413803\n",
      "Epoch 78/100, Loss: 484.9191808104515\n",
      "Epoch 79/100, Loss: 484.9088734984398\n",
      "Epoch 80/100, Loss: 484.915574491024\n",
      "Epoch 81/100, Loss: 484.8779430985451\n",
      "Epoch 82/100, Loss: 484.8569951057434\n",
      "Epoch 83/100, Loss: 484.83944195508957\n",
      "Epoch 84/100, Loss: 484.8197829723358\n",
      "Epoch 85/100, Loss: 484.7818217277527\n",
      "Epoch 86/100, Loss: 484.7468341588974\n",
      "Epoch 87/100, Loss: 484.68481373786926\n",
      "Epoch 88/100, Loss: 484.6041759252548\n",
      "Epoch 89/100, Loss: 484.4794465303421\n",
      "Epoch 90/100, Loss: 484.3987990617752\n",
      "Epoch 91/100, Loss: 484.3677225112915\n",
      "Epoch 92/100, Loss: 484.33854228258133\n",
      "Epoch 93/100, Loss: 484.32308679819107\n",
      "Epoch 94/100, Loss: 484.1896358728409\n",
      "Epoch 95/100, Loss: 484.14433175325394\n",
      "Epoch 96/100, Loss: 484.1695885658264\n",
      "Epoch 97/100, Loss: 484.09889245033264\n",
      "Epoch 98/100, Loss: 484.05836164951324\n",
      "Epoch 99/100, Loss: 484.0323314666748\n",
      "Epoch 100/100, Loss: 483.9684965610504\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "학습2: train data만 가지고 학습\n",
    "이미 학습1 코드에서 모델이 학습을 수행하였으므로\n",
    "학습2 코드 실행 전 재시작 -> 학습1 코드 실행 X -> 학습2 코드 실행(정해진 epochs만 학습)\n",
    "'''\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100 # train, valid loss를 ㄴ기준으로 과적합되기 전 epochs\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_features, batch_targets in train_loader:\n",
    "        # 배치를 GPU로 전송\n",
    "        batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "        # 모델에 대한 순전파 및 손실 계산\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # 에폭마다 손실 출력\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Imbalance: Counter({0.0: 15192, 1.0: 14700})\n",
      "Accuracy: 0.4946\n",
      "Precision: 0.4918\n",
      "Recall: 0.8327\n",
      "F1 Score: 0.6184\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHHCAYAAACcHAM1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX4UlEQVR4nO3dd1hUR9sG8HuXsiDSFKRYEBuCvcVgNxJRsSAaG3lFRY2xxF5I7I2IHXtHDSa2iC0WYglGCSqKXWPBLlgQERREmO8PP05cFxTcPbLq/ct1ris7Z87MnHXRh2dmziqEEAJEREREekyZ3wMgIiIiehcGLERERKT3GLAQERGR3mPAQkRERHqPAQsRERHpPQYsREREpPcYsBAREZHeY8BCREREeo8BCxEREek9BiyfmcuXL6Np06awtLSEQqFAWFiYTtu/fv06FAoFQkJCdNrux6xRo0Zo1KhRfg+DPmEHDx6EQqHApk2bcn1NixYt0KtXLxlHBZw/fx6GhoY4e/asrP3Q54EBSz64evUqvvvuO5QqVQomJiawsLBA3bp1MXfuXDx//lzWvv38/HDmzBlMmTIFa9euRc2aNWXt70Pq1q0bFAoFLCwssn0fL1++DIVCAYVCgRkzZuS5/bt372L8+PGIiYnRwWjfX3JyMsaNG4eKFSvCzMwMhQsXRtWqVTFw4EDcvXs3X8f2sStZsiRatmyZ38PI0bp16zBnzhyt2zl8+DD27t2LkSNHSmUXL17EiBEjULVqVZibm8PBwQFeXl44fvx4tm3cuXMHHTp0gJWVFSwsLNCmTRtcu3ZNrY6bmxu8vLwwduxYrcdMZJjfA/jc7Ny5E9988w1UKhW6du2KihUr4sWLF/j7778xfPhwnDt3DkuXLpWl7+fPnyMyMhI//fQT+vfvL0sfTk5OeP78OYyMjGRp/10MDQ3x7NkzbN++HR06dFA7FxoaChMTE6Smpr5X23fv3sWECRNQsmRJVK1aNdfX7d279736y056ejoaNGiAixcvws/PDwMGDEBycjLOnTuHdevWoW3btnB0dNRZf6Rf1q1bh7Nnz2LQoEFatTN9+nQ0adIEZcqUkcqWL1+OFStWoF27dujbty+ePHmCJUuW4Msvv8Tu3bvh4eEh1U1OTkbjxo3x5MkT/PjjjzAyMsLs2bPRsGFDxMTEoHDhwlLdPn36oEWLFrh69SpKly6t1bjp88aA5QOKjY1Fp06d4OTkhP3798PBwUE6169fP1y5cgU7d+6Urf8HDx4AAKysrGTrQ6FQwMTERLb230WlUqFu3br49ddfNQKWdevWwcvLC5s3b/4gY3n27BkKFCgAY2NjnbUZFhaGkydPIjQ0FF26dFE7l5qaihcvXuisL/o03b9/Hzt37sTixYvVyjt37ozx48ejYMGCUlmPHj3g6uqK8ePHqwUsCxcuxOXLl3H06FHUqlULANC8eXNUrFgRM2fOxNSpU6W6Hh4esLa2xurVqzFx4kSZ744+aYI+mD59+ggA4vDhw7mqn56eLiZOnChKlSoljI2NhZOTkwgICBCpqalq9ZycnISXl5c4dOiQqFWrllCpVMLZ2VmsXr1aqjNu3DgBQO1wcnISQgjh5+cn/f/rsq553d69e0XdunWFpaWlMDMzE+XKlRMBAQHS+djYWAFArFq1Su26ffv2iXr16okCBQoIS0tL0bp1a3H+/Pls+7t8+bLw8/MTlpaWwsLCQnTr1k2kpKS88/3y8/MTZmZmIiQkRKhUKvH48WPp3NGjRwUAsXnzZgFATJ8+XTr36NEjMXToUFGxYkVhZmYmzM3NRbNmzURMTIxU58CBAxrv3+v32bBhQ1GhQgVx/PhxUb9+fWFqaioGDhwonWvYsKHUVteuXYVKpdK4/6ZNmworKytx586dHO8xMDBQABDXr19/5/shhBAXLlwQ7dq1E9bW1kKlUokaNWqIrVu3atQ7e/asaNy4sTAxMRFFixYVkyZNEitWrBAARGxsrFQPgBg3bpzG9U5OTsLPz0+t7PHjx2LgwIGiWLFiwtjYWJQuXVr8/PPPIiMjQ6qT9XmZPn26WLJkifRZr1mzpjh69Gi29/PNN98IGxsbYWJiIsqVKyd+/PFHtTq3b98W3bt3F0WKFBHGxsbCzc1NrFixIlfvV9bP0rusXbtWVK9eXZiYmAhra2vRsWNHcfPmTbU6WZ+Jc+fOiUaNGglTU1Ph6Ogopk2bptHe9evXRatWrUSBAgWEra2tGDRokNi9e7cAIA4cOCC1l9PPcNbnc/369WLy5MmiaNGiQqVSia+++kpcvnxZra+VK1fm6TPk4+MjChUqpFZWq1YtUatWLY26TZs2FaVLl9Yob9u2rahcuXKu+iPKCTMsH9D27dtRqlQp1KlTJ1f1e/bsidWrV6N9+/YYOnQooqKiEBgYiAsXLmDLli1qda9cuYL27dvD398ffn5+WLlyJbp164YaNWqgQoUK8PHxgZWVFQYPHozOnTujRYsWar9J5ca5c+fQsmVLVK5cGRMnToRKpcKVK1dw+PDht173559/onnz5ihVqhTGjx+P58+fY968eahbty5OnDiBkiVLqtXv0KEDnJ2dERgYiBMnTmD58uUoUqQIpk2blqtx+vj4oE+fPvj999/Ro0cPAK+yK+XLl0f16tU16l+7dg1hYWH45ptv4OzsjPj4eCxZsgQNGzbE+fPn4ejoCFdXV0ycOBFjx45F7969Ub9+fQBQ+7N89OgRmjdvjk6dOuHbb7+FnZ1dtuObO3cu9u/fDz8/P0RGRsLAwABLlizB3r17sXbt2rdO6Tg5OQEA1qxZg9GjR0OhUORY99y5c6hbty6KFi2KUaNGwczMDBs2bIC3tzc2b96Mtm3bAgDi4uLQuHFjvHz5Uqq3dOlSmJqavuOdztmzZ8/QsGFD3LlzB9999x1KlCiBI0eOICAgAPfu3dNYh7Fu3To8ffoU3333HRQKBYKCguDj44Nr165J04unT59G/fr1YWRkhN69e6NkyZK4evUqtm/fjilTpgAA4uPj8eWXX0KhUKB///6wtbXFrl274O/vj6SkJK2nUgBgypQpGDNmDDp06ICePXviwYMHmDdvHho0aICTJ0+qZTAfP36MZs2awcfHBx06dMCmTZswcuRIVKpUCc2bNwcApKSk4KuvvsK9e/cwcOBA2NvbY926dThw4IBavz/99BOePHmC27dvY/bs2QCg8TP8888/Q6lUYtiwYXjy5AmCgoLg6+uLqKgoqc6RI0dQuHBh6bP0LnFxcbCxsZFeZ2Zm4vTp09LP1uu++OIL7N27F0+fPoW5ublUXqNGDWzduhVJSUmwsLDIVb9EGvI7YvpcPHnyRAAQbdq0yVX9mJgYAUD07NlTrXzYsGECgNi/f79U5uTkJACIiIgIqez+/ftCpVKJoUOHSmWv/zb7utxmWGbPni0AiAcPHuQ47uwyLFWrVhVFihQRjx49kspOnTollEql6Nq1q0Z/PXr0UGuzbdu2onDhwjn2+fp9mJmZCSGEaN++vWjSpIkQQoiMjAxhb28vJkyYkO17kJqaqvZbf9Z9qFQqMXHiRKns2LFj2WaPhPjvt9/Fixdne+71DIsQQuzZs0cAEJMnTxbXrl0TBQsWFN7e3u+8x2fPngkXFxfpt+tu3bqJFStWiPj4eI26TZo0EZUqVVLLyGVmZoo6deqIsmXLSmWDBg0SAERUVJRUdv/+fWFpafneGZZJkyYJMzMz8e+//6rVGzVqlDAwMJCyEVl/HoULFxYJCQlSva1btwoAYvv27VJZgwYNhLm5ubhx44Zam5mZmdL/+/v7CwcHB/Hw4UO1Op06dRKWlpbi2bNnGmN/8z7elmG5fv26MDAwEFOmTFErP3PmjDA0NFQrz/pMrFmzRipLS0sT9vb2ol27dlLZzJkzBQARFhYmlT1//lyUL19eLcMihBBeXl7Z/qxmZVhcXV1FWlqaVD537lwBQJw5c0Yqq1evnqhRo8Zb34csERERQqFQiDFjxkhlDx48EADUfjayLFiwQAAQFy9eVCtft26dxmeMKK+4S+gDSUpKAgC13zre5o8//gAADBkyRK186NChAKCx1sXNzU36rR8AbG1t4eLiorFqXxtZvzlu3boVmZmZubrm3r17iImJQbdu3VCoUCGpvHLlyvj666+l+3xdnz591F7Xr18fjx49kt7D3OjSpQsOHjyIuLg47N+/H3FxcRprPrKoVCoola9+FDIyMvDo0SMULFgQLi4uOHHiRK77VKlU6N69e67qNm3aFN999x0mTpwIHx8fmJiYYMmSJe+8ztTUFFFRURg+fDgAICQkBP7+/nBwcMCAAQOQlpYGAEhISMD+/fvRoUMHPH36FA8fPsTDhw/x6NEjeHp64vLly7hz5w6AV5+1L7/8El988YXUj62tLXx9fXN972/auHEj6tevD2tra6nvhw8fwsPDAxkZGYiIiFCr37FjR1hbW0uvsz7LWZ/fBw8eICIiAj169ECJEiXUrs3KMgkhsHnzZrRq1QpCCLV+PT098eTJkzz9eWbn999/R2ZmJjp06KDWvr29PcqWLauRFSlYsCC+/fZb6bWxsTG++OILtZ/L3bt3o2jRomjdurVUZmJi8l5bjrt37662ZurN9xF4lQl8/b3Oyf3799GlSxc4OztjxIgRUnnWDjyVSqVxTdb6tTd36WX19/Dhw9zeCpEGBiwfSFYa9OnTp7mqf+PGDSiVSrVV/ABgb28PKysr3LhxQ638zb/EgVd/STx+/Pg9R6ypY8eOqFu3Lnr27Ak7Ozt06tQJGzZseGvwkjVOFxcXjXOurq54+PAhUlJS1MrfvJesv+zyci8tWrSAubk51q9fj9DQUNSqVUvjvcySmZmJ2bNno2zZslCpVLCxsYGtrS1Onz6NJ0+e5LrPokWL5mmB7YwZM1CoUCHExMQgODgYRYoUydV1lpaWCAoKwvXr13H9+nWsWLECLi4umD9/PiZNmgTg1RShEAJjxoyBra2t2jFu3DgAr/5BAl79GZUtW1ajn+z+zHLr8uXL2L17t0bfWQs3s/rO8q4/86x/cCtWrJhjnw8ePEBiYiKWLl2q0W9WIPlmv+9zX0IIlC1bVqOPCxcuaLRfrFgxjWm7N38ub9y4gdKlS2vUy+nz+ja5/dkRQry1nZSUFLRs2RJPnz7F1q1b1aaesqYKs4Lj12XtwHtzOjGrv7dNYRK9C9ewfCAWFhZwdHTM8wOUcvsDbmBgkG35u/5ielsfGRkZaq9NTU0RERGBAwcOYOfOndi9ezfWr1+Pr776Cnv37s1xDHmlzb1kUalU8PHxwerVq3Ht2jWMHz8+x7pTp07FmDFj0KNHD0yaNAmFChWCUqnEoEGDcp1JAjT/kn6XkydPSv/AnTlzBp07d87T9cCrNS09evRA27ZtUapUKYSGhmLy5MnSuIcNGwZPT89sr32ffxBz8uZnJTMzE19//bXab+avK1eunNprXfyZZ93zt99+Cz8/v2zrVK5cOdft5dSHQqHArl27sh3zm2tKdHFfeZGb/goXLvzW4P/Fixfw8fHB6dOnsWfPHo0gsVChQlCpVLh3757GtVllb67Dyurv9bUwRHnFgOUDatmyJZYuXYrIyEi4u7u/ta6TkxMyMzNx+fJluLq6SuXx8fFITEzM9YK53LC2tkZiYqJG+ZtZHABQKpVo0qQJmjRpglmzZmHq1Kn46aefcODAAbVtj6/fBwBcunRJ49zFixdhY2MDMzMz7W8iG126dMHKlSuhVCrRqVOnHOtt2rQJjRs3xooVK9TKExMT1f6C1eVvhykpKejevTvc3NxQp04dBAUFoW3bttIW0byytrZG6dKlpYC4VKlSAAAjI6Ns/1xe5+TkhMuXL2uUZ/dnlt1n5cWLFxr/eJUuXRrJycnv7Du3su7nbQG/ra0tzM3NkZGRobN+31S6dGkIIeDs7KwRdL0vJycnnD9/HkIItc/YlStXNOrq4jNYvnz5HLf2Z2ZmomvXrti3bx82bNiAhg0batRRKpWoVKlStg+Ui4qKQqlSpTSmvmNjY6FUKnX2ntHniVNCH9CIESNgZmaGnj17Ij4+XuP81atXMXfuXACvpjQAaOymmDVrFgDAy8tLZ+MqXbo0njx5gtOnT0tl9+7d09iJlJCQoHFt1gPUsksPA4CDgwOqVq2K1atXq/1Dd/bsWezdu1e6Tzk0btwYkyZNwvz582Fvb59jPQMDA43feDdu3Cit8ciSFVhlF9zl1ciRI3Hz5k2sXr0as2bNQsmSJeHn55fj+5jl1KlT2a4DuHHjBs6fPy9N4xQpUgSNGjXCkiVLsv1NOOuZPMCrz9o///yDo0ePqp0PDQ3VuK506dIa60+WLl2qkWHp0KEDIiMjsWfPHo02EhMT8fLly7fe55tsbW3RoEEDrFy5Ejdv3lQ7l/VnZ2BggHbt2mHz5s3ZBjav3/P78vHxgYGBASZMmKDxmRFC4NGjR3lu09PTE3fu3MG2bdukstTUVCxbtkyjrpmZWZ6mKbPj7u6Ox48fZ7u+bcCAAVi/fj0WLlwIHx+fHNto3749jh07pha0XLp0Cfv378c333yjUT86OhoVKlSApaWlVmOnzxszLB9Q6dKlsW7dOnTs2BGurq5qT7o9cuQINm7ciG7dugEAqlSpAj8/PyxduhSJiYlo2LAhjh49itWrV8Pb2xuNGzfW2bg6deqEkSNHom3btvjhhx/w7NkzLFq0COXKlVNbpDhx4kRERETAy8sLTk5OuH//PhYuXIhixYqhXr16ObY/ffp0NG/eHO7u7vD395e2NVtaWr51qkZbSqUSo0ePfme9li1bYuLEiejevTvq1KmDM2fOIDQ0VPqtPkvp0qVhZWWFxYsXw9zcHGZmZqhduzacnZ3zNK79+/dj4cKFGDdunLTNetWqVWjUqBHGjBmDoKCgHK8NDw/HuHHj0Lp1a3z55ZcoWLAgrl27hpUrVyItLU3t/VywYAHq1auHSpUqoVevXihVqhTi4+MRGRmJ27dv49SpUwBeBdJr165Fs2bNMHDgQGlbs5OTk1oQC7zaat+nTx+0a9cOX3/9NU6dOoU9e/ZopPqHDx+Obdu2oWXLltL2+pSUFJw5cwabNm3C9evX8zw9EBwcjHr16qF69ero3bs3nJ2dcf36dezcuVP6uoSff/4ZBw4cQO3atdGrVy+4ubkhISEBJ06cwJ9//plt0P2mK1euYPLkyRrl1apVg5eXFyZPnoyAgABcv34d3t7eMDc3R2xsLLZs2YLevXtj2LBhebqv7777DvPnz0fnzp0xcOBAODg4SE9lBtSzKjVq1MD69esxZMgQ1KpVCwULFkSrVq3y1J+XlxcMDQ3x559/onfv3lL5nDlzsHDhQri7u6NAgQL45Zdf1K5r27atFLT37dsXy5Ytg5eXF4YNGwYjIyPMmjULdnZ20saALOnp6fjrr7/Qt2/fPI2TSMMH35dE4t9//xW9evUSJUuWFMbGxsLc3FzUrVtXzJs3T20Lanp6upgwYYJwdnYWRkZGonjx4m99cNyb3txOm9O2ZiFePRCuYsWKwtjYWLi4uIhffvlFY1vzvn37RJs2bYSjo6MwNjYWjo6OonPnzmpbV3N6cNyff/4p6tatK0xNTYWFhYVo1apVjg+Oe3Pb9KpVqzS212bn9W3NOclpW/PQoUOFg4ODMDU1FXXr1hWRkZHZbkfeunWrcHNzE4aGhtk+OC47r7eTlJQknJycRPXq1UV6erpavcGDBwulUikiIyNzHP+1a9fE2LFjxZdffimKFCkiDA0Nha2trfDy8lLb6p7l6tWromvXrsLe3l4YGRmJokWLipYtW4pNmzap1Tt9+rRo2LDhOx8cl5GRIUaOHClsbGxEgQIFhKenp7hy5Uq2D457+vSpCAgIEGXKlBHGxsbCxsZG1KlTR8yYMUO8ePFCCPH2zySy2UJ99uxZ0bZtW2FlZSVMTEyEi4uL2pZbIYSIj48X/fr1E8WLFxdGRkbC3t5eNGnSRCxdujTH9zVL1iMCsjv8/f2leps3bxb16tUTZmZmwszMTJQvX17069dPXLp0SaqT02ciu8cIXLt2TXh5eQlTU1Nha2srhg4dKj3k8J9//pHqJScniy5duggrK6tsHxy3ceNGtXZz+nls3bq1tO3/9XHldO/Z/fzdunVLtG/fXlhYWIiCBQuKli1bajykTgghdu3aJT0QkkgbCiFkWv1FRB+1kJAQdO/eHbGxsRoP9yP5zZkzB4MHD8bt27dRtGhRnbZ96NAhNGrUCBcvXsx2h5gueXt7Q6FQaEwxE+UV17AQEeWzN59bkpqaiiVLlqBs2bI6D1aAV89nadq06VunH3XhwoUL2LFjh7TdnkgbXMNCRJTPfHx8UKJECVStWhVPnjzBL7/8gosXL2a78FlXdu3aJVvbWVxdXfO8wJooJwxYiIjymaenJ5YvX47Q0FBkZGTAzc0Nv/32Gzp27JjfQyPSG1zDQkRERHqPa1iIiIhI7zFgISIiIr3HgIWIiIj03ie56PZZOpflEGWn8BcD8nsIRHrn+cn5svdhWq2/Ttr5EGPVV8ywEBERkd77JDMsREREekXB/IC2GLAQERHJ7bUvsaT3w4CFiIhIbsywaI3vIBEREek9ZliIiIjkxikhrTFgISIikhunhLTGd5CIiIj0HjMsREREcuOUkNYYsBAREcmNU0Ja4ztIREREeo8ZFiIiIrlxSkhrDFiIiIjkxikhrfEdJCIiIr3HDAsREZHcOCWkNQYsREREcuOUkNYYsBAREcmNGRatMeQjIiIivceAhYiISG4KpW6OPIqIiECrVq3g6OgIhUKBsLAw6Vx6ejpGjhyJSpUqwczMDI6OjujatSvu3r2r1kZCQgJ8fX1hYWEBKysr+Pv7Izk5Wa3O6dOnUb9+fZiYmKB48eIICgrSGMvGjRtRvnx5mJiYoFKlSvjjjz/ydC8MWIiIiOSWTwFLSkoKqlSpggULFmice/bsGU6cOIExY8bgxIkT+P3333Hp0iW0bt1arZ6vry/OnTuH8PBw7NixAxEREejdu7d0PikpCU2bNoWTkxOio6Mxffp0jB8/HkuXLpXqHDlyBJ07d4a/vz9OnjwJb29veHt74+zZs7l/C4UQIs/vgJ57lv7J3RKRThT+YkB+D4FI7zw/OV/2PkwbTtRJO8//Gvve1yoUCmzZsgXe3t451jl27Bi++OIL3LhxAyVKlMCFCxfg5uaGY8eOoWbNmgCA3bt3o0WLFrh9+zYcHR2xaNEi/PTTT4iLi4OxsTEAYNSoUQgLC8PFixcBAB07dkRKSgp27Ngh9fXll1+iatWqWLx4ca7GzwwLERGR3JQK3Rwye/LkCRQKBaysrAAAkZGRsLKykoIVAPDw8IBSqURUVJRUp0GDBlKwAgCenp64dOkSHj9+LNXx8PBQ68vT0xORkZG5Hht3CREREclNR9ua09LSkJaWplamUqmgUqm0bjs1NRUjR45E586dYWFhAQCIi4tDkSJF1OoZGhqiUKFCiIuLk+o4Ozur1bGzs5POWVtbIy4uTip7vU5WG7nBDAsREdFHIjAwEJaWlmpHYGCg1u2mp6ejQ4cOEEJg0aJFOhip7jHDQkREJDcdPYclICAAQ4YMUSvTNruSFazcuHED+/fvl7IrAGBvb4/79++r1X/58iUSEhJgb28v1YmPj1erk/X6XXWyzucGMyxERERy09EuIZVKBQsLC7VDm4AlK1i5fPky/vzzTxQuXFjtvLu7OxITExEdHS2V7d+/H5mZmahdu7ZUJyIiAunp6VKd8PBwuLi4wNraWqqzb98+tbbDw8Ph7u6e67EyYCEiIvpEJScnIyYmBjExMQCA2NhYxMTE4ObNm0hPT0f79u1x/PhxhIaGIiMjA3FxcYiLi8OLFy8AAK6urmjWrBl69eqFo0eP4vDhw+jfvz86deoER0dHAECXLl1gbGwMf39/nDt3DuvXr8fcuXPVMkEDBw7E7t27MXPmTFy8eBHjx4/H8ePH0b9//1zfC7c1E31GuK2ZSNMH2db89TSdtPM8fGSe6h88eBCNGzfWKPfz88P48eM1FstmOXDgABo1agTg1YPj+vfvj+3bt0OpVKJdu3YIDg5GwYIFpfqnT59Gv379cOzYMdjY2GDAgAEYOVJ9rBs3bsTo0aNx/fp1lC1bFkFBQWjRokWu74UBC9FnhAELkaYPErA0na6Tdp7vHa6Tdj5GXHRLREQkN375oda4hoWIiIj0HjMsREREctPRg+M+ZwxYiIiI5MYpIa0x5CMiIiK9xwwLERGR3DglpDUGLERERHLjlJDWGPIRERGR3mOGhYiISG6cEtIaAxYiIiK5MWDRGt9BIiIi0nvMsBAREcmNi261xoCFiIhIbpwS0hoDFiIiIrkxw6I1hnxERESk95hhISIikhunhLTGgIWIiEhunBLSGkM+IiIi0nvMsBAREclMwQyL1hiwEBERyYwBi/Y4JURERER6jxkWIiIiuTHBojUGLERERDLjlJD2OCVEREREeo8ZFiIiIpkxw6I9BixEREQyY8CiPQYsREREMmPAoj2uYSEiIiK9xwwLERGR3Jhg0RoDFiIiIplxSkh7nBIiIiIivccMCxERkcyYYdEeAxYiIiKZMWDRHqeEiIiISO8xw0JERCQzZli0x4CFiIhIboxXtMYpISIiItJ7zLAQERHJjFNC2mPAQkREJDMGLNpjwEJERCQzBiza4xoWIiIi0nvMsBAREcmNCRatMWAhIiKSGaeEtMcpISIiItJ7zLAQERHJjBkW7TFgISIikhkDFu1xSoiIiIj0HjMsREREMmOGRXsMWIiIiOTGeEVrnBIiIiIivccMCxERkcw4JaQ9BixEREQyY8CiPQYsREREMmPAoj2uYSEiIiK9xwwLERGR3Jhg0RoDFiIiIplxSkh7nBIiIiIivccMC73VimVLsP/PcFyPvQaViQmqVK2GgYOHoqRzKalOz27/Q/TxY2rXtfumI0aPm6DRXmLiY3Rs54378fGIOHIU5hYWAIDjR6PQq4efRv3wg4dgY2Or47siypu61UtjcFcPVHcrAQdbS3QYvBTbD54GABgaKjG+byt41qsA52KFkZSciv1RFzEmeBvuPXii1k6zehXwY+/mqFjWEakvXuLv6MvoMGSZRn+FLM1wdP0oFLWzhn394XiS/BwAsHTCt/hf6y816p+/eg812k+R4c5JV5hh0R4DFnqrE8ePoWPnLqhQsRJevszA/Lmz8X3vnvh96w6YFigg1fNp/w2+7/+D9NrExDTb9iaMHY2y5VxwPz4+2/NhO3bBrGBB6XWhQoV1dCdE78/MVIUz/97Bmq2RWD+rt9q5AibGqOpaHD8v24XT/96BtUUBzBjeHhvnfId6vkFSPe8mVbFgTGeMm78dB4/+C0NDJSqUdsi2v8XjuuDM5bsoametVj5s+iaMCd4qvTY0MEDU+gD8Hn5Sh3dLcmDAoj0GLPRWC5YsV3s9YUogmjSog/Pnz6FGzVpSuYmJ6TszIRt++xVPk5LQ+/t+OHwoIts6hQoVlrIuRPpi7+Hz2Hv4fLbnkpJT0fL7+Wplg3/egL9DR6C4vTVuxT2GgYESM4a3w49zwrA6LFKqd/FanEZ7vb6pB0vzApi6dBea1aug0VdScqr0ulWjyrC2MMXabZFvNkP0ycnXgOXhw4dYuXIlIiMjERf36gfX3t4ederUQbdu3WBry6kAfZOc/BQAYGlpqVb+x87t+GPHNhS2sUWDho3Qq09fmJr+l2W5evUKli1eiDW/rsedW7dybL9je2+kv0hH6TJl0advf1StXl2eGyGSkYW5KTIzM5H49NVUTrXyxVHUzhqZmQKRv46EXWELnP73Nn6cHYbzV+9J15UvZY+AXs3RsOsMlCxq885+/LzdsT/qEm7eeyzbvZBuMMOivXxbdHvs2DGUK1cOwcHBsLS0RIMGDdCgQQNYWloiODgY5cuXx/Hjx/NreJSNzMxMzPh5KqpWq44yZctJ5c29WmLKz0FYunI1evTsjZ07tmH0qBHS+RcvXiBg+FAMGjocDg6O2bZtY2uLn8aOx4zZwZg+ey7s7e3Rq0dXXDh/Tvb7ItIllbEhJv/QBht2R+NpyqtsiHOxV8HH6D4tMG35HrQbuBiJSc+xZ9lAWFu8mlo1NjLE6sBu+HFOGG7FvTsAcbC1hGddN4RsOSLfzZDuKHR0fMbyLWAZMGAAvvnmG9y6dQshISGYNm0apk2bhpCQENy8eRPt27fHgAED3tlOWloakpKS1I60tLQPcAefn8DJE3HlymX8PH2WWnm7bzqiTt36KFvOBS1atsKkqdOwf184bt28CQAInjMTzqVKw6tV6xzbLulcCu07dIJbhYqoWq06xk+eispVqyJ0zWpZ74lIlwwNlfglyB8KhQI/TF0vlSv//7fracv3IGxfDE5euIXe436BgIDP19UAAJN+aI1LsfH47Y9j2bb9Jt9WtZH49Dm2HTit+xuhT0ZERARatWoFR0dHKBQKhIWFqZ0XQmDs2LFwcHCAqakpPDw8cPnyZbU6CQkJ8PX1hYWFBaysrODv74/k5GS1OqdPn0b9+vVhYmKC4sWLIygoCG/auHEjypcvDxMTE1SqVAl//PFHnu4l3wKWU6dOYfDgwdmmyRQKBQYPHoyYmJh3thMYGAhLS0u1Y8a0QBlG/Hn7ecpEHPrrIJatXAM7e/u31q1UqTIA4NatGwCAY1FR+HPvbtSsUgE1q1TAdz27AwAa13fHovnBObZTsWJl3Pz/Noj0naGhEqHT/FHCwRotv58vZVcA4N7DV7uFLl77b/rnRfpLXL/9CMXtCwEAGtYqBx+Panh6bC6eHpuLXUte/cJ2+8DPGN2nhUZ/fm2+xK87jyL9ZYact0U6olAodHLkVUpKCqpUqYIFCxZkez4oKAjBwcFYvHgxoqKiYGZmBk9PT6Sm/vf59fX1xblz5xAeHo4dO3YgIiICvXv/t/g8KSkJTZs2hZOTE6KjozF9+nSMHz8eS5culeocOXIEnTt3hr+/P06ePAlvb294e3vj7Nmzub6XfFvDYm9vj6NHj6J8+fLZnj969Cjs7Oze2U5AQACGDBmiVpahNNbJGOlV9D1t6iTs3/cnlq1ag6LFir3zmksXLwIAbGyKAABmzA5GWtp/H/5zZ89g/JifsGL1LyhevMRb27H9/zaI9FlWsFK6hC2a9Q5GwpMUtfMnL9xCalo6ypa0w5GYa9I1JRwL4ea9BABA52HLYaoykq6pUcEJSyd8Cw//Obh264Fae/VrlEWZEkUQEsbFth+L/FrD0rx5czRv3jzbc0IIzJkzB6NHj0abNm0AAGvWrIGdnR3CwsLQqVMnXLhwAbt378axY8dQs2ZNAMC8efPQokULzJgxA46OjggNDcWLFy+wcuVKGBsbo0KFCoiJicGsWbOkwGbu3Llo1qwZhg8fDgCYNGkSwsPDMX/+fCxevDhX95JvAcuwYcPQu3dvREdHo0mTJlJwEh8fj3379mHZsmWYMWPGO9tRqVRQqVRqZc/ShSxj/hwFTp6IXX/swOzgBTAzM8PDh6/+4ixY0BwmJia4dfMmdv2xA/XqN4CVlRX+/fdfzJwWiOo1a6KciwsAoHgJ9aAk8fGr+flSpUpLO4JC166GY9FiKF2mDF6kpWHL5k04dvQfLFy64gPeLVH2zEyNUbr4f5sAShYtjMrliuJx0jPce/gE66b3RLXyxeEzcDEMlArYFTYHACQ8eYb0lxl4mpKK5Zv+xpg+LXA77jFu3kvAYD8PAMDv4ScAALG3H6r1Wdjq1fb+i9fipOewZOnm7Y6jp2PVFuySftNVvJKWlqax7CG7fwdzIzY2FnFxcfDw8JDKLC0tUbt2bURGRqJTp06IjIyElZWVFKwAgIeHB5RKJaKiotC2bVtERkaiQYMGMDb+L1ng6emJadOm4fHjx7C2tkZkZKRGcsHT01Njiupt8i1g6devH2xsbDB79mwsXLgQGRmv0poGBgaoUaMGQkJC0KFDh/waHv2/jet/BQD06t5VrXzC5Klo7e0DIyMjRP1zBOvWrsbz589hZ++AJl83Rc/vvs9TP+np6Zg9fRru34+HiYkJypZzweLlK1HrC82HZBF9aNXdnLB3+UDpddCwdgCAtdv+weTFf6BVo1fToEfXB6hd17TnXByKfrUeIGDOFrzMyMSKyV1hqjLCsbM30Lx3sLSTKLcsCprAu0lVDJu+SZtboo9UYGAgJkxQfyjnuHHjMH78+Dy3lbU7983ZDDs7O+lcXFwcihRRz3QbGhqiUKFCanWcnZ012sg6Z21tjbi4uLf2kxv5uq25Y8eO6NixI9LT0/Hw4avfLmxsbGBkZPSOK+lDOXn24lvP2zs4YEXIL3lqs+YXtTXa7dajJ7r16Jnn8RF9CIeiL8O0Wv8cz7/tXJaXLzMRMHsLAmZv0arPpORUFK4zJJsrSJ/pakoou2UQ75Nd+RjpxYPjjIyM4OCQ/RMfiYiIPna6mhJ63+mf7Nj//waK+Ph4tX+D4+PjUbVqVanO/fv31a57+fIlEhISpOvt7e0R/8bTy7Nev6uO/Ts2cbyOX35IRET0GXJ2doa9vT327dsnlSUlJSEqKgru7u4AAHd3dyQmJiI6Olqqs3//fmRmZqJ27dpSnYiICKSnp0t1wsPD4eLiAmtra6nO6/1k1cnqJzcYsBAREcksv7Y1JycnIyYmRnpMSGxsLGJiYnDz5k0oFAoMGjQIkydPxrZt23DmzBl07doVjo6O8Pb2BgC4urqiWbNm6NWrF44ePYrDhw+jf//+6NSpExwdXz0ItEuXLjA2Noa/vz/OnTuH9evXY+7cuWpTVwMHDsTu3bsxc+ZMXLx4EePHj8fx48fRv/+7p1Oz6MWUEBER0acsv57Mf/z4cTRu3Fh6nRVE+Pn5ISQkBCNGjEBKSgp69+6NxMRE1KtXD7t374aJiYl0TWhoKPr3748mTZpAqVSiXbt2CA7+7xlalpaW2Lt3L/r164caNWrAxsYGY8eOVXtWS506dbBu3TqMHj0aP/74I8qWLYuwsDBUrFgx1/eiEEJ8cnuAua2ZKHuFv3j306OJPjfPT85/dyUtlR+1RyftXPzZUyftfIyYYSEiIpKZUvmZfxGQDjBgISIikhm/rFl7XHRLREREeo8ZFiIiIpnl13cJfUoYsBAREcmM8Yr2GLAQERHJjBkW7XENCxEREek9ZliIiIhkxgyL9hiwEBERyYzxivY4JURERER6jxkWIiIimXFKSHsMWIiIiGTGeEV7nBIiIiIivccMCxERkcw4JaQ9BixEREQyY7yiPU4JERERkd5jhoWIiEhmnBLSHgMWIiIimTFe0R4DFiIiIpkxw6I9rmEhIiIivccMCxERkcyYYNEeAxYiIiKZcUpIe5wSIiIiIr3HDAsREZHMmGDRHgMWIiIimXFKSHucEiIiIiK9xwwLERGRzJhg0R4DFiIiIplxSkh7nBIiIiIivccMCxERkcyYYdEeAxYiIiKZMV7RHgMWIiIimTHDoj2uYSEiIiK9xwwLERGRzJhg0R4DFiIiIplxSkh7nBIiIiIivccMCxERkcyYYNEeAxYiIiKZKRmxaI1TQkRERKT3mGEhIiKSGRMs2mPAQkREJDPuEtIeAxYiIiKZKRmvaI1rWIiIiEjvMcNCREQkM04JaY8BCxERkcwYr2iPU0JERESk93QSsCQmJuqiGSIiok+SQkf/fc7yHLBMmzYN69evl1536NABhQsXRtGiRXHq1CmdDo6IiOhToFTo5vic5TlgWbx4MYoXLw4ACA8PR3h4OHbt2oXmzZtj+PDhOh8gERERUZ4X3cbFxUkBy44dO9ChQwc0bdoUJUuWRO3atXU+QCIioo8ddwlpL88ZFmtra9y6dQsAsHv3bnh4eAAAhBDIyMjQ7eiIiIg+AQqFbo7PWZ4zLD4+PujSpQvKli2LR48eoXnz5gCAkydPokyZMjofIBEREVGeA5bZs2ejZMmSuHXrFoKCglCwYEEAwL1799C3b1+dD5CIiOhjp/zc0yM6kOeAxcjICMOGDdMoHzx4sE4GRERE9KlhvKK9XAUs27Zty3WDrVu3fu/BEBERfYq46FZ7uQpYvL29c9WYQqHgwlsiIiLSuVwFLJmZmXKPg4iI6JPFBIv2tPryw9TUVJiYmOhqLERERJ8kLrrVXp6fw5KRkYFJkyahaNGiKFiwIK5duwYAGDNmDFasWKHzARIRERHlOWCZMmUKQkJCEBQUBGNjY6m8YsWKWL58uU4HR0RE9ClQ6Oj4nOU5YFmzZg2WLl0KX19fGBgYSOVVqlTBxYsXdTo4IiKiT4FCodDJ8TnLc8By586dbJ9om5mZifT0dJ0MioiIiLSTkZGBMWPGwNnZGaampihdujQmTZoEIYRURwiBsWPHwsHBAaampvDw8MDly5fV2klISICvry8sLCxgZWUFf39/JCcnq9U5ffo06tevDxMTExQvXhxBQUE6v588Byxubm44dOiQRvmmTZtQrVo1nQyKiIjoU6JU6ObIi2nTpmHRokWYP38+Lly4gGnTpiEoKAjz5s2T6gQFBSE4OBiLFy9GVFQUzMzM4OnpidTUVKmOr68vzp07h/DwcOzYsQMRERHo3bu3dD4pKQlNmzaFk5MToqOjMX36dIwfPx5Lly7V+n17XZ53CY0dOxZ+fn64c+cOMjMz8fvvv+PSpUtYs2YNduzYodPBERERfQryYzrnyJEjaNOmDby8vAAAJUuWxK+//oqjR48CeJVdmTNnDkaPHo02bdoAeLXsw87ODmFhYejUqRMuXLiA3bt349ixY6hZsyYAYN68eWjRogVmzJgBR0dHhIaG4sWLF1i5ciWMjY1RoUIFxMTEYNasWWqBjbbynGFp06YNtm/fjj///BNmZmYYO3YsLly4gO3bt+Prr7/W2cCIiIjo/dWpUwf79u3Dv//+CwA4deoU/v77b+lLi2NjYxEXFwcPDw/pGktLS9SuXRuRkZEAgMjISFhZWUnBCgB4eHhAqVQiKipKqtOgQQO1jTienp64dOkSHj9+rLP7ea/nsNSvXx/h4eE6GwQREdGnTFcJlrS0NKSlpamVqVQqqFQqjbqjRo1CUlISypcvDwMDA2RkZGDKlCnw9fUFAMTFxQEA7Ozs1K6zs7OTzsXFxaFIkSJq5w0NDVGoUCG1Os7OzhptZJ2ztrZ+39tVk+cMS5bjx49j7dq1WLt2LaKjo3UyGCIiok+RrnYJBQYGwtLSUu0IDAzMts8NGzYgNDQU69atw4kTJ7B69WrMmDEDq1ev/sB3rxt5zrDcvn0bnTt3xuHDh2FlZQUASExMRJ06dfDbb7+hWLFiuh4jERHRRy2vC2ZzEhAQgCFDhqiVZZddAYDhw4dj1KhR6NSpEwCgUqVKuHHjBgIDA+Hn5wd7e3sAQHx8PBwcHKTr4uPjUbVqVQCAvb097t+/r9buy5cvkZCQIF1vb2+P+Ph4tTpZr7Pq6EKeMyw9e/ZEeno6Lly4gISEBCQkJODChQvIzMxEz549dTYwIiIiUqdSqWBhYaF25BSwPHv2DEql+j/zBgYG0vcDOjs7w97eHvv27ZPOJyUlISoqCu7u7gAAd3d3JCYmqs2k7N+/H5mZmahdu7ZUJyIiQu3RJuHh4XBxcdHZdBDwHgHLX3/9hUWLFsHFxUUqc3Fxwbx58xAREaGzgREREX0q8uPBca1atcKUKVOwc+dOXL9+HVu2bMGsWbPQtm1baUyDBg3C5MmTsW3bNpw5cwZdu3aFo6MjvL29AQCurq5o1qwZevXqhaNHj+Lw4cPo378/OnXqBEdHRwBAly5dYGxsDH9/f5w7dw7r16/H3LlzNTJB2srzlFDx4sWzfUBcRkaGNHgiIiL6T348o3bevHkYM2YM+vbti/v378PR0RHfffcdxo4dK9UZMWIEUlJS0Lt3byQmJqJevXrYvXu32hcbh4aGon///mjSpAmUSiXatWuH4OBg6bylpSX27t2Lfv36oUaNGrCxscHYsWN1uqUZABTi9Ufe5cLWrVsxdepULFiwQNrmdPz4cQwYMAAjR46UorL89Cw9T7dE9Nko/MWA/B4Ckd55fnK+7H30+O2MTtpZ2amSTtr5GOUqw2Jtba2WikpJSUHt2rVhaPjq8pcvX8LQ0BA9evTQi4CFiIhInyg/8+8B0oVcBSxz5syReRhERESfLsYr2stVwOLn5yf3OIiIiIhy9F5Pus2SmpqKFy9eqJVZWFhoNSAiIqJPTX58l9CnJs/bmlNSUtC/f38UKVIEZmZmsLa2VjuIiIhInUKhm+NzlueAZcSIEdi/fz8WLVoElUqF5cuXY8KECXB0dMSaNWvkGCMRERF95vI8JbR9+3asWbMGjRo1Qvfu3VG/fn2UKVMGTk5OCA0Nlb5UiYiIiF7hLiHt5TnDkpCQgFKlSgF4tV4lISEBAFCvXj0+6ZaIiCgbnBLSXp4DllKlSiE2NhYAUL58eWzYsAHAq8xL1pchEhER0X/y49H8n5o8Byzdu3fHqVOnAACjRo3CggULYGJigsGDB2P48OE6HyARERFRntewDB48WPp/Dw8PXLx4EdHR0ShTpgwqV66s08G9L84VEuWggGV+j4Dos5Tn7ABp0Oo5LADg5OQEJycnXYyFiIjok/S5T+foQq4Clte/lfFdfvjhh/ceDBEREVF2chWwzJ49O1eNKRQKBixERERvUDLBorVcBSxZu4KIiIgo7xiwaI/rgIiIiEjvab3oloiIiN6Oi261x4CFiIhIZpwS0h6nhIiIiEjvMcNCREQkM84Iae+9MiyHDh3Ct99+C3d3d9y5cwcAsHbtWvz99986HRwREdGnQKlQ6OT4nOU5YNm8eTM8PT1hamqKkydPIi0tDQDw5MkTTJ06VecDJCIi+tgpdXR8zvJ8/5MnT8bixYuxbNkyGBkZSeV169bFiRMndDo4IiIiIuA91rBcunQJDRo00Ci3tLREYmKiLsZERET0SfnMZ3N0Is8ZFnt7e1y5ckWj/O+//0apUqV0MigiIqJPCdewaC/PAUuvXr0wcOBAREVFQaFQ4O7duwgNDcWwYcPw/fffyzFGIiIi+szleUpo1KhRyMzMRJMmTfDs2TM0aNAAKpUKw4YNw4ABA+QYIxER0UftM0+O6ESeAxaFQoGffvoJw4cPx5UrV5CcnAw3NzcULFhQjvERERF99PikW+2994PjjI2N4ebmpsuxEBEREWUrzwFL48aN3/olTvv379dqQERERJ+az33BrC7kOWCpWrWq2uv09HTExMTg7Nmz8PPz09W4iIiIPhmMV7SX54Bl9uzZ2ZaPHz8eycnJWg+IiIiI6E06e9Lvt99+i5UrV+qqOSIiok+GUqGb43Oms29rjoyMhImJia6aIyIi+mQo8JlHGzqQ54DFx8dH7bUQAvfu3cPx48cxZswYnQ2MiIjoU/G5Z0d0Ic8Bi6WlpdprpVIJFxcXTJw4EU2bNtXZwIiIiIiy5ClgycjIQPfu3VGpUiVYW1vLNSYiIqJPCjMs2svTolsDAwM0bdqU38pMRESUBwqFQifH5yzPu4QqVqyIa9euyTEWIiIiomzlOWCZPHkyhg0bhh07duDevXtISkpSO4iIiEgdtzVrL9drWCZOnIihQ4eiRYsWAIDWrVurpaeEEFAoFMjIyND9KImIiD5in/lsjk7kOmCZMGEC+vTpgwMHDsg5HiIiIiINuQ5YhBAAgIYNG8o2GCIiok8Rv/xQe3na1vy5r1AmIiJ6H5/7+hNdyFPAUq5cuXcGLQkJCVoNiIiIiOhNeQpYJkyYoPGkWyIiIno7TlBoL08BS6dOnVCkSBG5xkJERPRJUvLLD7WW64CF61eIiIjeD/8J1V6uHxyXtUuIiIiI6EPLdYYlMzNTznEQERF9srhLSHt5WsNCREREecfnsGgvz98lRERERPShMcNCREQkMyZYtMeAhYiISGacEtIep4SIiIhI7zHDQkREJDMmWLTHgIWIiEhmnM7QHt9DIiIi0nvMsBAREcmMX2+jPQYsREREMmO4oj0GLERERDLjtmbtcQ0LERER6T0GLERERDJT6OjIqzt37uDbb79F4cKFYWpqikqVKuH48ePSeSEExo4dCwcHB5iamsLDwwOXL19WayMhIQG+vr6wsLCAlZUV/P39kZycrFbn9OnTqF+/PkxMTFC8eHEEBQW9x2jfjgELERGRzBQK3Rx58fjxY9StWxdGRkbYtWsXzp8/j5kzZ8La2lqqExQUhODgYCxevBhRUVEwMzODp6cnUlNTpTq+vr44d+4cwsPDsWPHDkRERKB3797S+aSkJDRt2hROTk6Ijo7G9OnTMX78eCxdulTr9+11CiGE0GmLeiD1ZX6PgEg/WTf8Kb+HQKR3nh+eInsf607c1kk7XaoXy3XdUaNG4fDhwzh06FC254UQcHR0xNChQzFs2DAAwJMnT2BnZ4eQkBB06tQJFy5cgJubG44dO4aaNWsCAHbv3o0WLVrg9u3bcHR0xKJFi/DTTz8hLi4OxsbGUt9hYWG4ePGilnf8H2ZYiIiIZKZQKHRypKWlISkpSe1IS0vLts9t27ahZs2a+Oabb1CkSBFUq1YNy5Ytk87HxsYiLi4OHh4eUpmlpSVq166NyMhIAEBkZCSsrKykYAUAPDw8oFQqERUVJdVp0KCBFKwAgKenJy5duoTHjx/r7D1kwEJERCQzpY6OwMBAWFpaqh2BgYHZ9nnt2jUsWrQIZcuWxZ49e/D999/jhx9+wOrVqwEAcXFxAAA7Ozu16+zs7KRzcXFxKFKkiNp5Q0NDFCpUSK1Odm283ocucFszERHRRyIgIABDhgxRK1OpVNnWzczMRM2aNTF16lQAQLVq1XD27FksXrwYfn5+so9V15hhISIikpmupoRUKhUsLCzUjpwCFgcHB7i5uamVubq64ubNmwAAe3t7AEB8fLxanfj4eOmcvb097t+/r3b+5cuXSEhIUKuTXRuv96ELDFiIiIhklh/bmuvWrYtLly6plf37779wcnICADg7O8Pe3h779u2TziclJSEqKgru7u4AAHd3dyQmJiI6Olqqs3//fmRmZqJ27dpSnYiICKSnp0t1wsPD4eLiorYjSVsMWIiIiD5BgwcPxj///IOpU6fiypUrWLduHZYuXYp+/foBeJX1GTRoECZPnoxt27bhzJkz6Nq1KxwdHeHt7Q3gVUamWbNm6NWrF44ePYrDhw+jf//+6NSpExwdHQEAXbp0gbGxMfz9/XHu3DmsX78ec+fO1Zi60hbXsBAREcksP778sFatWtiyZQsCAgIwceJEODs7Y86cOfD19ZXqjBgxAikpKejduzcSExNRr1497N69GyYmJlKd0NBQ9O/fH02aNIFSqUS7du0QHBwsnbe0tMTevXvRr18/1KhRAzY2Nhg7dqzas1p0gc9hIfqM8DksRJo+xHNYfj91Tyft+FRx0Ek7HyNmWIiIiGSWHxmWTw3XsBAREZHeY4aFiIhIZsyvaI8BCxERkcw4I6Q9TgkRERGR3mOGhYiISGZKTgppjQELERGRzDglpD1OCREREZHeY4aFiIhIZgpOCWmNAQsREZHMOCWkPU4JERERkd5jhoWIiEhm3CWkPQYsREREMuOUkPYYsBAREcmMAYv2uIaFiIiI9B4zLERERDLjtmbtMWAhIiKSmZLxitY4JURERER6jxkWIiIimXFKSHsMWIiIiGTGXULa45QQERER6T1mWIiIiGTGKSHtMWAhIiKSGXcJaY9TQkRERKT3mGGht1qxbAn2he9FbOw1qExMULVqNQwaMgwlnUtp1BVCoF+fXjj89yHMDl6Ar5p4SOeqVHDRqP/z9Flo3sJLev3bulD89usvuHvnDuwdHNCr9/do1cZblvsiyou6VUpicJf6qF7eEQ42Fugw6hdsP3QBAGBooMT43l/D070cnB0LISklFfuPXcWYxXtw7+FTAEAJeysEdGuMRjVKwa6wOe49TMKve05h2uqDSH+ZodFfqaKF8E9If2RkZMKh2WSp3NW5CMb2bIJqLkXh5GCN4XN3Yv6GIx/mTSCtcEpIewxY6K2OHzuKjp19UaFSJWS8zMC8ubPQp5c/ft+2EwUKFFCr+8ua1VC8ZSn8xMmBqFuvvvTa3MJC+v8Nv61D8JyZGDthMipWrIQzZ05j4rjRMLewQKPGX+n+xojywMzUGGeu3MOandFYH+irdq6AiRGqujji55ADOH0lDtbmppgx0Asbp/0P9fwXAgBcnGyhVCrQf/pWXL39CBVK2WHByLYwMzFCwILdau0ZGiixZkJHHD51HV9WLKHel8oIsXcf4/f9ZzHtBy/Qx4O7hLTHgIXeatHSFWqvJ075GY3ru+PC+XOoUbOWVH7xwgWsWb0Sv67fjCaN6mXblrmFBWxsbbM9t2P7NrTv0BHNmrcAABQrXhznzp7BqhXLGLBQvtv7z7/Y+8+/2Z5LSklDy0Gr1MoGz9qOv1f0RXE7S9yKf4LwqMsIj7osnb9+9zHKlTiEXt61NQKW8b2/xqUbD3Ag+qpGwBJ98Q6iL94BAEz63lMXt0YfCOMV7XENC+VJ8tNXKW4LS0up7Pnz5wgYMRQ/jh6bY0ACAFMnT0DDurXRpWN7bPl9E4QQ0rkXL17A2FilVt9EpcLZM2eQnp6u47sgkpdFQRNkZmYi8WlqznXMTJDw9LlaWcPqpeDTuCIGzdwu9xCJPjp6HbDcunULPXr0eGudtLQ0JCUlqR1paWkfaISfl8zMTARNm4qq1aqjbNlyUvn0aYGoUq0aGn/lkeO1ffv/gOkz52Dx8lXw+Loppk6agHWha6XzderWw5bNm3D+3FkIIXDu7Bn8vnkTXr5MR2LiY1nvi0iXVMaGmPy9Jzb8eRpPn2X/d1GpooXwfXt3rAg7KpUVsjDFsp/aodeUzTleRx8vpUKhk+NzptcBS0JCAlavXv3WOoGBgbC0tFQ7pk8L/EAj/LxMnTwBVy9fRtCM2VLZwf37cCzqH4wY+eNbr/3u+36oVr0GXF3d0KNnb3Tr0ROrV/033dS7T1/UrV8f/+vSETWqVMDAAX2lBbdKhV5/TIkkhgZK/DKpExQKBX6Yvi3bOo42Ftg2qxt+P3AWq7Yfl8oXjmqL9eGncPjU9Q80WvqQFDo6Pmf5uoZl27bsf6CzXLt27Z1tBAQEYMiQIWplwkCVQ216X1MnT0TEXwexcvUvsLO3l8qPRv2DW7duop57LbX6QwcNQPUaNbEiZO2bTQEAKlWugqWLF/7/VJAxTExMMHFyIMaMm4iER49gY2uLzRvXw8zMDNaFCsl6b0S6YGigROikzihhZ4XmP6zINkviYGOO3fP88c+Zm+g3LUztXMPqpeBVtzwGdX61BkyhUMDAQImnf01Ev6CtWLMz+kPcBpHeyteAxdvbGwqFQm0tw5vetusEAFQqFVQq9QAl9aVOhkd4tVU5cMok7N8XjhUha1GsWHG18z169kbb9t+olbX3boVhIwPQsFHjHNu9dPECLCwsYWxsrFZuZGQkBUS7d/2BBg0bQ6lkhoX0W1awUrp4YTQbsBwJSc816jjaWGD3PH+cvHQHvadu1vh7r9F3S2Dw2tPFWtZ3w9Bv66Pxd0tw92GS7PdAMvvc0yM6kK8Bi4ODAxYuXIg2bdpkez4mJgY1atT4wKOi102dNAG7/tiBOfMWwqyAGR4+eAAAKGhuDhMTE9jY2ma70NbBwVEKbg4e2I+ER49QqUoVqIxV+CfyMJYvWwK/bv+tT7p+PRZnz5xGpcpVkPQkCWvXrMKVy5cxaerPH+ZGid7CzNQYpYsVll6XdLRG5bIOeJz0DPcePsW6KV1QrZwDfEashYFSCbtCBQEACUnPkf4yA442Ftgz3x834xIRMH83bK3MpLbiE5IBAJduPFDrs7prUWRmCpyPvS+VGRkawNW5CADA2MgAjrYWqFzWAcnP0nDtToJs90/a43NYtJevAUuNGjUQHR2dY8DyruwLyW/D+l8BAP7d/qdWPnFyINq09clVG0aGhvjt11BMnzYVQgAlSpTAsBGj0K59B6lOZkYm1oSswo3rsTA0NEStL2pjTeivKFq0mO5uhug9VS9fFHvn95ReB/3/M1DW/nECk1fsQ6v6rgCAo6sHqF3XtP9yHDoZi6++KI0yxW1QprgNrm4dqVbHtO5PuR6Hg405okL6S68Hd6mPwV3qI+LENXgOWPGWK4k+fgqRjxHBoUOHkJKSgmbNmmV7PiUlBcePH0fDhg3z1C6nhIiyZ90w9/84En0unh+eInsfR6890Uk7X5SyfHelT1S+Zljq16//1vNmZmZ5DlaIiIj0DSeEtMfVjERERKT3+Gh+IiIiuTHFojUGLERERDLjLiHtMWAhIiKS2Wf+VH2d4BoWIiIi0nvMsBAREcmMCRbtMWAhIiKSGyMWrXFKiIiIiPQeMyxEREQy4y4h7TFgISIikhl3CWmPU0JERESk95hhISIikhkTLNpjwEJERCQ3Rixa45QQERER6T1mWIiIiGTGXULaY8BCREQkM+4S0h4DFiIiIpkxXtEe17AQERGR3mOGhYiISG5MsWiNAQsREZHMuOhWe5wSIiIiIr3HDAsREZHMuEtIewxYiIiIZMZ4RXucEiIiIiK9xwwLERGR3Jhi0RoDFiIiIplxl5D2OCVERET0Gfj555+hUCgwaNAgqSw1NRX9+vVD4cKFUbBgQbRr1w7x8fFq1928eRNeXl4oUKAAihQpguHDh+Ply5dqdQ4ePIjq1atDpVKhTJkyCAkJ0fn4GbAQERHJTKHQzfG+jh07hiVLlqBy5cpq5YMHD8b27duxceNG/PXXX7h79y58fHyk8xkZGfDy8sKLFy9w5MgRrF69GiEhIRg7dqxUJzY2Fl5eXmjcuDFiYmIwaNAg9OzZE3v27Hn/AWdDIYQQOm1RD6S+fHcdos+RdcOf8nsIRHrn+eEpsvfxb9wznbRTzr5Anq9JTk5G9erVsXDhQkyePBlVq1bFnDlz8OTJE9ja2mLdunVo3749AODixYtwdXVFZGQkvvzyS+zatQstW7bE3bt3YWdnBwBYvHgxRo4ciQcPHsDY2BgjR47Ezp07cfbsWanPTp06ITExEbt379bJfQPMsBAREclPoZsjLS0NSUlJakdaWtpbu+7Xrx+8vLzg4eGhVh4dHY309HS18vLly6NEiRKIjIwEAERGRqJSpUpSsAIAnp6eSEpKwrlz56Q6b7bt6ekptaErDFiIiIg+EoGBgbC0tFQ7AgMDc6z/22+/4cSJE9nWiYuLg7GxMaysrNTK7ezsEBcXJ9V5PVjJOp917m11kpKS8Pz58zzfY064S4iIiEhmutolFBAQgCFDhqiVqVSqbOveunULAwcORHh4OExMTHTSf35ihoWIiEhmulp0q1KpYGFhoXbkFLBER0fj/v37qF69OgwNDWFoaIi//voLwcHBMDQ0hJ2dHV68eIHExES16+Lj42Fvbw8AsLe319g1lPX6XXUsLCxgamqqi7cPAAMWIiKiT1KTJk1w5swZxMTESEfNmjXh6+sr/b+RkRH27dsnXXPp0iXcvHkT7u7uAAB3d3ecOXMG9+/fl+qEh4fDwsICbm5uUp3X28iqk9WGrnBKiIiISGb58dg4c3NzVKxYUa3MzMwMhQsXlsr9/f0xZMgQFCpUCBYWFhgwYADc3d3x5ZdfAgCaNm0KNzc3/O9//0NQUBDi4uIwevRo9OvXT8rs9OnTB/Pnz8eIESPQo0cP7N+/Hxs2bMDOnTt1ej8MWIiIiOSmpw+6nT17NpRKJdq1a4e0tDR4enpi4cKF0nkDAwPs2LED33//Pdzd3WFmZgY/Pz9MnDhRquPs7IydO3di8ODBmDt3LooVK4bly5fD09NTp2Plc1iIPiN8DguRpg/xHJarD3SzW6a0re7WhHxsmGEhIiKSGb9LSHsMWIiIiGSmzWP16RXuEiIiIiK9xwwLERGRzJhg0R4DFiIiIrkxYtEaAxYiIiKZcdGt9riGhYiIiPQeMyxEREQy4y4h7TFgISIikhnjFe1xSoiIiIj0HjMsREREMuOUkPYYsBAREcmOEYu2OCVEREREeo8ZFiIiIplxSkh7DFiIiIhkxnhFe5wSIiIiIr3HDAsREZHMOCWkPQYsREREMuN3CWmPAQsREZHcGK9ojWtYiIiISO8xw0JERCQzJli0x4CFiIhIZlx0qz1OCREREZHeY4aFiIhIZtwlpD0GLERERHJjvKI1TgkRERGR3mOGhYiISGZMsGiPAQsREZHMuEtIe5wSIiIiIr3HDAsREZHMuEtIewxYiIiIZMYpIe1xSoiIiIj0HgMWIiIi0nucEiIiIpIZp4S0x4CFiIhIZlx0qz1OCREREZHeY4aFiIhIZpwS0h4DFiIiIpkxXtEep4SIiIhI7zHDQkREJDemWLTGgIWIiEhm3CWkPU4JERERkd5jhoWIiEhm3CWkPQYsREREMmO8oj0GLERERHJjxKI1rmEhIiIivccMCxERkcy4S0h7DFiIiIhkxkW32uOUEBEREek9hRBC5Pcg6NOUlpaGwMBABAQEQKVS5fdwiPQGfzaI8o4BC8kmKSkJlpaWePLkCSwsLPJ7OER6gz8bRHnHKSEiIiLSewxYiIiISO8xYCEiIiK9x4CFZKNSqTBu3DguKiR6A382iPKOi26JiIhI7zHDQkRERHqPAQsRERHpPQYsREREpPcYsBAREZHeY8BCslmwYAFKliwJExMT1K5dG0ePHs3vIRHlq4iICLRq1QqOjo5QKBQICwvL7yERfTQYsJAs1q9fjyFDhmDcuHE4ceIEqlSpAk9PT9y/fz+/h0aUb1JSUlClShUsWLAgv4dC9NHhtmaSRe3atVGrVi3Mnz8fAJCZmYnixYtjwIABGDVqVD6Pjij/KRQKbNmyBd7e3vk9FKKPAjMspHMvXrxAdHQ0PDw8pDKlUgkPDw9ERkbm48iIiOhjxYCFdO7hw4fIyMiAnZ2dWrmdnR3i4uLyaVRERPQxY8BCREREeo8BC+mcjY0NDAwMEB8fr1YeHx8Pe3v7fBoVERF9zBiwkM4ZGxujRo0a2Ldvn1SWmZmJffv2wd3dPR9HRkREHyvD/B4AfZqGDBkCPz8/1KxZE1988QXmzJmDlJQUdO/ePb+HRpRvkpOTceXKFel1bGwsYmJiUKhQIZQoUSIfR0ak/7itmWQzf/58TJ8+HXFxcahatSqCg4NRu3bt/B4WUb45ePAgGjdurFHu5+eHkJCQDz8goo8IAxYiIiLSe1zDQkRERHqPAQsRERHpPQYsREREpPcYsBAREZHeY8BCREREeo8BCxEREek9BixERESk9xiwEOWjbt26wdvbW3rdqFEjDBo06IOP4+DBg1AoFEhMTMyxjkKhQFhYWK7bHD9+PKpWrarVuK5fvw6FQoGYmBit2iGijx8DFqI3dOvWDQqFAgqFAsbGxihTpgwmTpyIly9fyt7377//jkmTJuWqbm6CDCKiTwW/S4goG82aNcOqVauQlpaGP/74A/369YORkRECAgI06r548QLGxsY66bdQoUI6aYeI6FPDDAtRNlQqFezt7eHk5ITvv/8eHh4e2LZtG4D/pnGmTJkCR0dHuLi4AABu3bqFDh06wMrKCoUKFUKbNm1w/fp1qc2MjAwMGTIEVlZWKFy4MEaMGIE3vxnjzSmhtLQ0jBw5EsWLF4dKpUKZMmWwYsUKXL9+XfpOGmtraygUCnTr1g3Aq2/GDgwMhLOzM0xNTVGlShVs2rRJrZ8//vgD5cqVg6mpKRo3bqw2ztwaOXIkypUrhwIFCqBUqVIYM2YM0tPTNeotWbIExYsXR4ECBdChQwc8efJE7fzy5cvh6uoKExMTlC9fHgsXLsyxz8ePH8PX1xe2trYwNTVF2bJlsWrVqjyPnYg+PsywEOWCqakpHj16JL3et28fLCwsEB4eDgBIT0+Hp6cn3N3dcejQIRgaGmLy5Mlo1qwZTp8+DWNjY8ycORMhISFYuXIlXF1dMXPmTGzZsgVfffVVjv127doVkZGRCA4ORpUqVRAbG4uHDx+iePHi2Lx5M9q1a4dLly7BwsICpqamAIDAwED88ssvWLx4McqWLYuIiAh8++23sLW1RcOGDXHr1i34+PigX79+6N27N44fP46hQ4fm+T0xNzdHSEgIHB0dcebMGfTq1Qvm5uYYMWKEVOfKlSvYsGEDtm/fjqSkJPj7+6Nv374IDQ0FAISGhmLs2LGYP38+qlWrhpMnT6JXr14wMzODn5+fRp9jxozB+fPnsWvXLtjY2ODKlSt4/vx5nsdORB8hQURq/Pz8RJs2bYQQQmRmZorw8HChUqnEsGHDpPN2dnYiLS1Numbt2rXCxcVFZGZmSmVpaWnC1NRU7NmzRwghhIODgwgKCpLOp6eni2LFikl9CSFEw4YNxcCBA4UQQly6dEkAEOHh4dmO88CBAwKAePz4sVSWmpoqChQoII4cOaJW19/fX3Tu3FkIIURAQIBwc3NTOz9y5EiNtt4EQGzZsiXH89OnTxc1atSQXo8bN04YGBiI27dvS2W7du0SSqVS3Lt3TwghROnSpcW6devU2pk0aZJwd3cXQggRGxsrAIiTJ08KIYRo1aqV6N69e45jIKJPFzMsRNnYsWMHChYsiPT0dGRmZqJLly4YP368dL5SpUpq61ZOnTqFK1euwNzcXK2d1NRUXL16FU+ePMG9e/dQu3Zt6ZyhoSFq1qypMS2UJSYmBgYGBmjYsGGux33lyhU8e/YMX3/9tVr5ixcvUK1aNQDAhQsX1MYBAO7u7rnuI8v69esRHByMq1evIjk5GS9fvoSFhYVanRIlSqBo0aJq/WRmZuLSpUswNzfH1atX4e/vj169ekl1Xr58CUtLy2z7/P7779GuXTucOHECTZs2hbe3N+rUqZPnsRPRx4cBC1E2GjdujEWLFsHY2BiOjo4wNFT/UTEzM1N7nZycjBo1akhTHa+ztbV9rzFkTfHkRXJyMgBg586daoEC8Gpdjq5ERkbC19cXEyZMgKenJywtLfHbb79h5syZeR7rsmXLNAIoAwODbK9p3rw5bty4gT/++APh4eFo0qQJ+vXrhxkzZrz/zRDRR4EBC1E2zMzMUKZMmVzXr169OtavX48iRYpoZBmyODg4ICoqCg0aNADwKpMQHR2N6tWrZ1u/UqVKyMzMxF9//QUPDw+N81kZnoyMDKnMzc0NKpUKN2/ezDEz4+rqKi0gzvLPP/+8+yZfc+TIETg5OeGnn36Sym7cuKFR7+bNm7h79y4cHR2lfpRKJVxcXGBnZwdHR0dcu3YNvr6+ue7b1tYWfn5+8PPzQ/369TF8+HAGLESfAe4SItIBX19f2NjYoE2bNjh06BBiY2Nx8OBB/PDDD7h9+zYAYODAgfj5558RFhaGixcvom/fvm99hkrJkiXh5+eHHj16ICwsTGpzw4YNAAAnJycoFArs2LEDDx48QHJyMszNzTFs2DAMHjwYq1evxtWrV3HixAnMmzcPq1evBgD06dMHly9fxvDhw3Hp0iWsW7cOISEhebrfsmXL4ubNm/jtt99w9epVBAcHY8uWLRr1TExM4Ofnh1OnTuHQoUP44Ycf0KFDB9jb2wMAJkyYgMDAQAQHB+Pff//FmTNnsGrVKsyaNSvbfseOHYutW7fiypUrOHfuHHbs2AFXV9c8jZ2IPk4MWIh0oECBAoiIiECJEiXg4+MDV1dX+Pv7IzU1Vcq4DB06FP/73//g5+cHd3d3mJubo23btm9td9GiRWjfvj369u2L8uXLo1evXkhJSQEAFC1aFBMmTMCoUaNgZ2eH/v37AwAmTZqEMWPGIDAwEK6urmjWrBl27twJZ2dnAK/WlWzevBlhYWGoUqUKFi9ejKlTp+bpflu3bo3Bgwejf//+qFq1Ko4cOYIxY8Zo1CtTpgx8fHzQokULNG3aFJUrV1bbttyzZ08sX74cq1atQqVKldCwYUOEhIRIY32TsbExAgICULlyZTRo0AAGBgb47bff8jR2Ivo4KUROK/6IiIiI9AQzLERERKT3GLAQERGR3mPAQkRERHqPAQsRERHpPQYsREREpPcYsBAREZHeY8BCREREeo8BCxEREek9BixERESk9xiwEBERkd5jwEJERER6jwELERER6b3/A6YMNoZjuW+EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        # 로그 오즈를 확률로 변환\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "        # 확률을 기준으로 0.5 이상이면 1, 미만이면 0으로 예측\n",
    "        preds = torch.round(probs).cpu().numpy()\n",
    "        y_true.extend(labels.squeeze().cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data Imbalance: {Counter(y_true)}')\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "seq_len = 20\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title(f'Confusion Matrix Sequence Length({seq_len})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4226661135.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    @@@\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@@@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. 백테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(y_test_bt)\n",
    "true_df.columns=['return', 'true']\n",
    "pred_df = pd.DataFrame({'pred': y_pred})\n",
    "bt_df = pd.concat([true_df, pred_df], axis=1)\n",
    "bt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백테스팅\n",
    "transaction_fee = 0.005 / 100\n",
    "returns = target_var[['returns_next10m', 'returns_next10m_binary']][split:] # test 실제 수익률\n",
    "returns['pred'] = pred1 # 모델의 binary 예측값\n",
    "\n",
    "# 거래 시뮬레이션: 예측이 1이면 구매하고, 아니면 거래하지 않음\n",
    "simulated_returns = returns[returns['pred'] == 1]['returns_next10m'] - transaction_fee\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "#final_portfolio_value = initial_investment + total_return # 최종 포트폴리오 가치\n",
    "\n",
    "print(f\"초기 투자 횟수: {initial_investment}\")\n",
    "print(f\"총 수익: {total_return.round(4)}\")\n",
    "print(f\"수익률: {(total_return / initial_investment * 100).round(4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 투자 횟수: 8025\n",
      "총 수익: 8.084\n",
      "수익률: 0.1007%\n",
      "수익률 with transaction cost: -0.3993%\n"
     ]
    }
   ],
   "source": [
    "simulated_returns = bt_df[bt_df['pred'] == 1]['return']\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "\n",
    "print(f\"초기 투자 횟수: {initial_investment}\")\n",
    "print(f\"총 수익: {total_return.round(4)}\")\n",
    "print(f\"수익률: {(total_return / initial_investment * 100).round(4)}%\")\n",
    "\n",
    "transaction_fee = 0.005 #/ 100\n",
    "simulated_returns = bt_df[bt_df['pred'] == 1]['return'] - transaction_fee\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "print(f\"수익률 with transaction cost: {(total_return / initial_investment * 100).round(4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델학습3: Optuna(with. Pruner) + CV 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([7669, 20, 77]) torch.Size([7669, 1])\n",
      "Train Size: torch.Size([5368, 20, 77]) torch.Size([5368, 1])\n",
      "Test Size: torch.Size([2301, 20, 77]) torch.Size([2301, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 / Optuna 용 -> valid 제거\n",
    "file_path = '../../data/' # 경로 설정\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "#df = df.iloc[:20000]\n",
    "#df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df['returns_next10m_binary'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "#X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "X, y, y_for_backtest = sq.createSeqForBacktest(df, seq_len=seq_len)\n",
    "\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (70% / 30%)\n",
    "split = int((X.size(0)) * 0.7)\n",
    "\n",
    "X_train_seq = X[:split]\n",
    "X_test_seq = X[split:]\n",
    "y_train_seq = y[:split]\n",
    "y_test_seq = y[split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 21:20:34,197] A new study created in memory with name: no-name-8852c764-fbe6-48e5-bb20-b0cdeaf9c5cd\n",
      "c:\\Users\\com\\anaconda3\\Lib\\site-packages\\optuna\\trial\\_trial.py:499: UserWarning: The reported value is ignored because this `step` 99 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2024-02-28 21:22:12,960] Trial 0 finished with value: 0.6910429483652114 and parameters: {'hidden_size': 96, 'num_layers': 3, 'lr': 0.01}. Best is trial 0 with value: 0.6910429483652114.\n",
      "[I 2024-02-28 21:23:53,114] Trial 1 finished with value: 2.064844066500664 and parameters: {'hidden_size': 64, 'num_layers': 3, 'lr': 0.001}. Best is trial 0 with value: 0.6910429483652114.\n",
      "[I 2024-02-28 21:25:38,778] Trial 2 finished with value: 1.4596738010644912 and parameters: {'hidden_size': 96, 'num_layers': 5, 'lr': 0.001}. Best is trial 0 with value: 0.6910429483652114.\n"
     ]
    }
   ],
   "source": [
    "# 학습 3: Optuna(with. Pruner) + CV 추가\n",
    "\n",
    "def objective(trial):\n",
    "    tscv = TimeSeriesSplit(n_splits=5, gap=0)\n",
    "\n",
    "    input_size = X.size(-1)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    lr = trial.suggest_categorical('lr', [0.01, 0.001, 0.0001])\n",
    "    num_epochs = 100\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        model = CNNLSTMModel(input_size, hidden_size, num_layers, num_classes=1).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        total_loss += val_loss\n",
    "\n",
    "        # Pruner를 위한 조기 중단 로직\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    avg_loss = total_loss / 5\n",
    "    return avg_loss\n",
    "\n",
    "# MedianPruner 초기화 및 Optuna 최적화 실행\n",
    "pruner = MedianPruner()\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(\"Best trial's value:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1180583119.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    best_model = CNNLSTMModel(input_size=input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 평가\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "input_size = X_test_seq.size(-1)\n",
    "\n",
    "# 모델을 최적의 하이퍼파라미터로 초기화\n",
    "best_model = CNNLSTMModel(input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "best_model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# 검증 데이터로 평가\n",
    "with torch.no_grad(): # 기울기 계산X -> 메모리 사용량, 속도 줄어듬\n",
    "    val_loss = 0.0\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "        # 로그 오즈를 확률로 변환\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "        # 확률을 기준으로 0.5 이상이면 1, 미만이면 0으로 예측\n",
    "        preds = torch.round(probs).cpu().numpy()\n",
    "        y_true.extend(labels.squeeze().cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data Imbalance: {Counter(y_true)}')\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title(f'Confusion Matrix Sequence Length: {seq_len}(with. Optuna)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

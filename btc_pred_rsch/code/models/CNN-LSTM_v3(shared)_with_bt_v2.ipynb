{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM_v3\n",
    "\n",
    "- 파이썬 버전: 3.8.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library 불러오기, SEED 설정, CUDA 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 PC는 윈도우 운영 체제입니다: cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 import\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 관련\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sequence as sq # 사용자 정의 함수 불러오기\n",
    "\n",
    "# 성능 평가 관련\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# 운영체제 관련\n",
    "import platform\n",
    "\n",
    "'''\n",
    "딥러닝 학습을 진행할 때, 가중치를 임의의 값으로 초기화하여 학습을 수행하는 데, \n",
    "실험을 동일하게 진행하기 위해서는 난수를 동일하게 생성해야 한다.\n",
    "Pytorch에서 random seed를 고정하기 위해 manual_seed를 사용한다.\n",
    "'''\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# 운영체제별 device 설정\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"이 PC는 윈도우 운영 체제입니다: {device} is available\")\n",
    "elif os_name == 'Darwin':\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")\n",
    "    print(f\"이 PC는 맥(OS X) 운영 체제입니다: {device} is available\")\n",
    "else:\n",
    "    print(f\"이 PC는 다른 운영 체제입니다: {os_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 전처리 (Binary, Scale, Tensor, train&valid&test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([111077, 20, 77]) torch.Size([111077, 1])\n",
      "Train Size: torch.Size([66646, 20, 77]) torch.Size([66646, 1])\n",
      "Valid Size: torch.Size([22215, 20, 77]) torch.Size([22215, 1])\n",
      "Test Size: torch.Size([22216, 20, 77]) torch.Size([22216, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "file_path = '../../data/' # 경로 설정\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "#df = df.iloc[:10000]\n",
    "#df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df['returns_next10m_binary'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "#X, y = sq.create_sequence(df, seq_len=seq_len) # 사용자 정의 함수\n",
    "X, y, y_for_backtest = sq.createSeqForBacktest(df, seq_len=seq_len)\n",
    "\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (60% / 20% / 20%)\n",
    "train_split = int((X.size(0)) * 0.6)\n",
    "valid_split = int((X.size(0)) * 0.8)\n",
    "\n",
    "X_train_seq = X[:train_split]\n",
    "X_val_seq = X[train_split:valid_split]\n",
    "X_test_seq = X[valid_split:]\n",
    "y_train_seq = y[:train_split]\n",
    "y_val_seq = y[train_split:valid_split]\n",
    "y_test_seq = y[valid_split:]\n",
    "y_test_bt = y_for_backtest[valid_split:] # for backtest\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Valid Size:', X_val_seq.size(), y_val_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset과 DataLoader를 이용해 배치 데이터로 만든다.\n",
    "train = torch.utils.data.TensorDataset(X_train_seq, y_train_seq)\n",
    "valid = torch.utils.data.TensorDataset(X_val_seq, y_val_seq)\n",
    "test = torch.utils.data.TensorDataset(X_test_seq, y_test_seq)\n",
    "batch_size = 128 # 32, 64, 128\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False, drop_last=True) # 시계열 데이터기에 shuffle X, 마지막 batch 버림\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(77, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN 레이어\n",
    "        '''\n",
    "        in_channels = 일반적인 이미지와 같은 2D 데이터를 다룰 때는 특성 맵(channel)을 채널로 인식함.\n",
    "        그러나 주식 시계열 데이터와 같은 1D 데이터의 경우 시퀀스 길이에 해당하는 차원이 채널로 간주됨.\n",
    "        이에 따라 'in_channels'에는 시퀀스 길이를 입력해야 함.\n",
    "        즉, 주식 시게열 데이터에서는 'in_channels'에는 시퀀스의 길이가 들어가야 올바르게 수행됨.\n",
    "        '''\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Fully Connected 레이어\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 레이어 적용 (cnn takes input of shape (batch_size, channels, seq_len))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn(x)\n",
    "        \n",
    "        # LSTM 레이어 적용\n",
    "        '''\n",
    "        LSTM 레이어에 입력을 전달하고, LSTM의 출력과 은닉 상태를 받는 부분\n",
    "        x.permute(0, 2, 1): 입력텐서 x의 차원을 변경. 일반적으로 LSTM 레이어는 시간 단계(seq_len)를 두 번쨰 차원으로 받지만,\n",
    "        Conv1d 레이어의 출력은 시간 단계가 세번째 차원에 위치함. 따라서 permute를 통해 차원을 변경하여 LSTM 레이어에 올바른 형태의 입력을 제공\n",
    "        여기서 0번째 차원은 배치 크기(batch_size)를 나타내며, 1번째 차원은 특성 수(num_features)를 나타냄. 마지막(2번째) 차원은 시간 단계(seq_len)를 나타냄\n",
    "        self.lstm(x.permute(0, 2, 1)): 변경된 입력을 LSTM 레이어에 전달함. LSTM 입력으로 3D 텐서를 받으며,\n",
    "        이 텐서는 배치 크기(batch_size), 시간 단계(seq_len),. 특성 수(num_features)의 형태를 가짐\n",
    "        lstm_out, _: LSTM 레이어의 출력과 은닉 상태를 받음. 여기서 은닉 상태는 사용하지 않기 때문에 '_'로 무시. lstm_out은 LSTM 레이어의 출력으로, 각 시간 단계에\n",
    "        해당하는 출력을 포함하는 3D 텐서임.\n",
    "        '''\n",
    "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(out)\n",
    "        \n",
    "        # Fully Connected 레이어에 입력\n",
    "        '''\n",
    "        lstm_out[:, -1, :]: LSTM 레이어의 출력에서 마지막 시간 단계의 출력만 선택. 이는 시퀀스 예측을 위해 마지막 시간 단계의 정보만을 사용하고자 하는 것\n",
    "        따라서 [:, -1, :]는 모든 배치와 모든 특성을 유지하면서 마지막 시간 단계의 출력을 선택함\n",
    "        self.fc(lstm_out[:, -1, :]): 선택된 마지막 시간 단계의 출력을 Fully Connected(FC) 레이어에 입력함. FC 레이어는 입력된 LSTM 출력을 받아서 최종\n",
    "        예측을 수행하는 역할을 함. 출력 크기는 1이며, 이는 주어진 입력에 대한 예측된 결과를 나타냄.\n",
    "        '''\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "#model = CNNLSTMModel(input_size=77, hidden_size=64, num_layers=2, num_classes=1)\n",
    "model = CNNLSTMModel(input_size=77, hidden_size=128, num_layers=2, num_classes=1)\n",
    "model.to(device) # GPU 사용 시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델학습1: train, valid를 이용한 과적합 방지되는 epochs 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습1: valid를 이용한 과적합 방지 epochs 찾기\n",
    "\n",
    "# # 학습과 검증 손실을 저장할 리스트 초기화\n",
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "\n",
    "# # # 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "# #criterion = nn.BCELoss() # 모델 출력이 시그모이드 활성화 함수를 거쳐 확률로 변환된 후의 값을 입력으로 받음. 입력 값은 0과 1사이의 확률 값.\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# num_epochs = 30\n",
    "\n",
    "# # 검증 데이터에 대한 모델 성능 평가 함수 정의\n",
    "# def evaluate(model, criterion, dataloader):\n",
    "#     model.eval()  # 모델을 평가 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_features, batch_targets in dataloader:\n",
    "#             # 배치를 GPU로 전송\n",
    "#             batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            \n",
    "#             # 모델에 대한 순전파 및 손실 계산\n",
    "#             outputs = model(batch_features)\n",
    "#             loss = criterion(outputs, batch_targets)\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     return total_loss / len(dataloader.dataset)  # 평균 손실 반환\n",
    "\n",
    "# # 학습 루프\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # 모델을 학습 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     for batch_features, batch_targets in train_loader:\n",
    "#         # 배치를 GPU로 전송\n",
    "#         batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "#         # 모델에 대한 순전파 및 손실 계산\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "#         # 역전파 및 최적화\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     # 에폭마다 학습 손실 기록\n",
    "#     train_loss = total_loss / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "#     # 검증 데이터에 대한 손실 계산 및 기록\n",
    "#     valid_loss = evaluate(model, criterion, valid_loader)\n",
    "#     valid_losses.append(valid_loss)\n",
    "    \n",
    "#     # 에폭마다 손실 출력\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "\n",
    "# # 손실 함수 시각화\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(valid_losses, label='Valid Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델학습2: 모델학습1에서 구한 epochs를 기준으로 train 데이터만 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 312.8719656765461\n",
      "Epoch 2/7, Loss: 265.10607969760895\n",
      "Epoch 3/7, Loss: 256.6614151597023\n",
      "Epoch 4/7, Loss: 251.91457638144493\n",
      "Epoch 5/7, Loss: 248.59114323556423\n",
      "Epoch 6/7, Loss: 245.33998516201973\n",
      "Epoch 7/7, Loss: 242.0009521842003\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "학습2: train data만 가지고 학습\n",
    "이미 학습1 코드에서 모델이 학습을 수행하였으므로\n",
    "학습2 코드 실행 전 재시작 -> 학습1 코드 실행 X -> 학습2 코드 실행(정해진 epochs만 학습)\n",
    "'''\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 7 # train, valid loss를 ㄴ기준으로 과적합되기 전 epochs\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_features, batch_targets in train_loader:\n",
    "        # 배치를 GPU로 전송\n",
    "        batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "        # 모델에 대한 순전파 및 손실 계산\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # 에폭마다 손실 출력\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Imbalance: Counter({0.0: 11343, 1.0: 10873})\n",
      "Accuracy: 0.7783\n",
      "Precision: 0.7758\n",
      "Recall: 0.7693\n",
      "F1 Score: 0.7725\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        # 로그 오즈를 확률로 변환\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "        # 확률을 기준으로 0.5 이상이면 1, 미만이면 0으로 예측\n",
    "        preds = torch.round(probs).cpu().numpy()\n",
    "        y_true.extend(labels.squeeze().cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data Imbalance: {Counter(y_true)}')\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title(f'Confusion Matrix Sequence Length({seq_len})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. 백테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -0.053187\n",
       "1        -0.031017\n",
       "2        -0.013299\n",
       "3        -0.053193\n",
       "4         0.039891\n",
       "            ...   \n",
       "149554    0.029500\n",
       "149555    0.036054\n",
       "149556    0.042596\n",
       "149557    0.029488\n",
       "149558    0.042584\n",
       "Name: returns_next10m, Length: 149559, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['returns_next10m'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>return_times_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.104333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.059139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.184444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.125254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22211</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22212</th>\n",
       "      <td>0.000853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22213</th>\n",
       "      <td>0.000951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22214</th>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22215</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22216 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         return  true  pred  return_times_10\n",
       "0     -0.001043   0.0   0.0        -0.104333\n",
       "1     -0.000591   0.0   0.0        -0.059139\n",
       "2     -0.000974   0.0   0.0        -0.097400\n",
       "3     -0.001844   0.0   0.0        -0.184444\n",
       "4     -0.001253   0.0   0.0        -0.125254\n",
       "...         ...   ...   ...              ...\n",
       "22211 -0.000066   0.0   1.0        -0.006557\n",
       "22212  0.000853   1.0   1.0         0.085282\n",
       "22213  0.000951   1.0   1.0         0.095108\n",
       "22214 -0.000098   0.0   1.0        -0.009835\n",
       "22215  0.000459   1.0   0.0         0.045897\n",
       "\n",
       "[22216 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df = pd.DataFrame(y_test_bt)\n",
    "true_df.columns=['return', 'true']\n",
    "pred_df = pd.DataFrame({'pred': y_pred})\n",
    "bt_df = pd.concat([true_df, pred_df], axis=1)\n",
    "bt_df['return_times_10'] = bt_df['return'] * 100\n",
    "bt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 투자 횟수: 10783\n",
      "총 수익: 10.8194\n",
      "수익률: 0.1003%\n",
      "수익률 with transaction cost: 0.0003%\n"
     ]
    }
   ],
   "source": [
    "simulated_returns = bt_df[bt_df['pred'] == 1]['return']\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "# 방법1:\n",
    "# sum 보다는 그냥 return 값에 1을 더하고, 그 값을 모두 곱하면 수익률\n",
    "# 곱한 항의 개수대로 루트를 씌운다(투자 횟수)\n",
    "# 방법2:\n",
    "# 투자한 10분동안의 거래에는 또 다른 거래가 일어날 수 없다.\n",
    "# 투자한 10분 이내의 1값은 제거해야 한다.\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "\n",
    "print(f\"초기 투자 횟수: {initial_investment}\")\n",
    "print(f\"총 수익: {total_return.round(4)}\")\n",
    "print(f\"수익률: {(total_return / initial_investment * 100).round(4)}%\")\n",
    "\n",
    "# transaction_fee를 먼저 고려해서 데이터를 생성해야 한다.\n",
    "# 종속변수를 다시 만들어야 한다. 기존에 1로 만들어놓은 것들에서 transaction_fee를 고려해서\n",
    "# 종속변수를 새롭게 정의하고 학습을 시켜야 한다.\n",
    "transaction_fee = 0.0005 * 2 # 0.001\n",
    "simulated_returns = bt_df[bt_df['pred'] == 1]['return'] - transaction_fee\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "print(f\"수익률 with transaction cost: {(total_return / initial_investment * 100).round(4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 투자 횟수: 10873\n",
      "총 수익: 14.4217\n",
      "수익률: 0.1326%\n",
      "수익률 with transaction cost: -0.3674%\n"
     ]
    }
   ],
   "source": [
    "simulated_returns = bt_df[bt_df['true'] == 1]['return']\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "\n",
    "print(f\"초기 투자 횟수: {initial_investment}\")\n",
    "print(f\"총 수익: {total_return.round(4)}\")\n",
    "print(f\"수익률: {(total_return / initial_investment * 100).round(4)}%\")\n",
    "\n",
    "transaction_fee = 0.005 #/ 100\n",
    "simulated_returns = bt_df[bt_df['true'] == 1]['return'] - transaction_fee\n",
    "total_return = simulated_returns.sum() # 총 수익\n",
    "initial_investment = len(simulated_returns) # 투자 횟수\n",
    "print(f\"수익률 with transaction cost: {(total_return / initial_investment * 100).round(4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델학습3: Optuna(with. Pruner) + CV 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([7669, 20, 77]) torch.Size([7669, 1])\n",
      "Train Size: torch.Size([5368, 20, 77]) torch.Size([5368, 1])\n",
      "Test Size: torch.Size([2301, 20, 77]) torch.Size([2301, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 / Optuna 용 -> valid 제거\n",
    "file_path = '../../data/' # 경로 설정\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "#df = df.iloc[:20000]\n",
    "#df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df['returns_next10m_binary'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "#X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "X, y, y_for_backtest = sq.createSeqForBacktest(df, seq_len=seq_len)\n",
    "\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (70% / 30%)\n",
    "split = int((X.size(0)) * 0.7)\n",
    "\n",
    "X_train_seq = X[:split]\n",
    "X_test_seq = X[split:]\n",
    "y_train_seq = y[:split]\n",
    "y_test_seq = y[split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 21:20:34,197] A new study created in memory with name: no-name-8852c764-fbe6-48e5-bb20-b0cdeaf9c5cd\n",
      "c:\\Users\\com\\anaconda3\\Lib\\site-packages\\optuna\\trial\\_trial.py:499: UserWarning: The reported value is ignored because this `step` 99 is already reported.\n",
      "  warnings.warn(\n",
      "[I 2024-02-28 21:22:12,960] Trial 0 finished with value: 0.6910429483652114 and parameters: {'hidden_size': 96, 'num_layers': 3, 'lr': 0.01}. Best is trial 0 with value: 0.6910429483652114.\n",
      "[I 2024-02-28 21:23:53,114] Trial 1 finished with value: 2.064844066500664 and parameters: {'hidden_size': 64, 'num_layers': 3, 'lr': 0.001}. Best is trial 0 with value: 0.6910429483652114.\n",
      "[I 2024-02-28 21:25:38,778] Trial 2 finished with value: 1.4596738010644912 and parameters: {'hidden_size': 96, 'num_layers': 5, 'lr': 0.001}. Best is trial 0 with value: 0.6910429483652114.\n"
     ]
    }
   ],
   "source": [
    "# 학습 3: Optuna(with. Pruner) + CV 추가\n",
    "\n",
    "def objective(trial):\n",
    "    tscv = TimeSeriesSplit(n_splits=5, gap=0)\n",
    "\n",
    "    input_size = X.size(-1)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    lr = trial.suggest_categorical('lr', [0.01, 0.001, 0.0001])\n",
    "    num_epochs = 100\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        model = CNNLSTMModel(input_size, hidden_size, num_layers, num_classes=1).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        total_loss += val_loss\n",
    "\n",
    "        # Pruner를 위한 조기 중단 로직\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    avg_loss = total_loss / 5\n",
    "    return avg_loss\n",
    "\n",
    "# MedianPruner 초기화 및 Optuna 최적화 실행\n",
    "pruner = MedianPruner()\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(\"Best trial's value:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1180583119.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    best_model = CNNLSTMModel(input_size=input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 평가\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "input_size = X_test_seq.size(-1)\n",
    "\n",
    "# 모델을 최적의 하이퍼파라미터로 초기화\n",
    "best_model = CNNLSTMModel(input_size, best_params['hidden_size'], best_params['num_layers'], num_classes=1).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "best_model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# 검증 데이터로 평가\n",
    "with torch.no_grad(): # 기울기 계산X -> 메모리 사용량, 속도 줄어듬\n",
    "    val_loss = 0.0\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch, labels = x_batch.to(device), labels.to(device)\n",
    "        # 로그 오즈를 확률로 변환\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "        # 확률을 기준으로 0.5 이상이면 1, 미만이면 0으로 예측\n",
    "        preds = torch.round(probs).cpu().numpy()\n",
    "        y_true.extend(labels.squeeze().cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data Imbalance: {Counter(y_true)}')\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title(f'Confusion Matrix Sequence Length: {seq_len}(with. Optuna)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

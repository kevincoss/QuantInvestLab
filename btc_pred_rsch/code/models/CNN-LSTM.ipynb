{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library 불러오기, SEED 설정, CUDA 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps 사용 가능 여부: True\n",
      "mps 지원 환경 여부: True\n",
      "mps is available\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 import\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 관련\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sequence as sq\n",
    "\n",
    "# 성능 평가 관련\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Visualization 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "'''\n",
    "딥러닝 학습을 진행할 때, 가중치를 임의의 값으로 초기화하여 학습을 수행하는 데, \n",
    "실험을 동일하게 진행하기 위해서는 난수를 동일하게 생성해야 한다.\n",
    "Pytorch에서 random seed를 고정하기 위해 manual_seed를 사용한다.\n",
    "'''\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# 맥북 용\n",
    "# GPU 사용 가능 환경인지 확인 -> mac의 경우 GPU가 아는 MPS를 사용\n",
    "print(f\"mps 사용 가능 여부: {torch.backends.mps.is_available()}\")\n",
    "print(f\"mps 지원 환경 여부: {torch.backends.mps.is_built()}\")\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# 윈도우 용(Colab)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 전처리 (Binary, Scale, Tensor, train&valid&test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([707, 20, 77]) torch.Size([707, 1])\n",
      "Train Size: torch.Size([424, 20, 77]) torch.Size([424, 1])\n",
      "Valid Size: torch.Size([141, 20, 77]) torch.Size([141, 1])\n",
      "Test Size: torch.Size([142, 20, 77]) torch.Size([142, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "file_path = '../../data/' # for mac\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "df = df.iloc[:1000]\n",
    "df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (60% / 20% / 20%)\n",
    "train_split = int((X.size(0)) * 0.6)\n",
    "valid_split = int((X.size(0)) * 0.8)\n",
    "\n",
    "X_train_seq = X[:train_split]\n",
    "X_val_seq = X[train_split:valid_split]\n",
    "X_test_seq = X[valid_split:]\n",
    "y_train_seq = y[:train_split]\n",
    "y_val_seq = y[train_split:valid_split]\n",
    "y_test_seq = y[valid_split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Valid Size:', X_val_seq.size(), y_val_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset과 DataLoader를 이용해 배치 데이터로 만든다.\n",
    "train = torch.utils.data.TensorDataset(X_train_seq, y_train_seq)\n",
    "valid = torch.utils.data.TensorDataset(X_val_seq, y_val_seq)\n",
    "test = torch.utils.data.TensorDataset(X_test_seq, y_test_seq)\n",
    "batch_size = 32 # 64, 128\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False, drop_last=True) # 시계열 데이터기에 shuffle X, 마지막 batch 버림\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 주식 시계열 데이터의 형태: [배치 크기, 시퀀스 길이, 특성 수]\n",
    "# # 여기서 특성 수는 주가, 거래량, 기술적 지표 등 다양한 특성을 포함합니다.\n",
    "\n",
    "# class CNNLSTMModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers):\n",
    "#         super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "#         # CNN 레이어\n",
    "#         self.cnn = nn.Conv1d(in_channels=input_size[-1], out_channels=64, kernel_size=3)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "#         # LSTM 레이어\n",
    "#         self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "#         # Fully Connected 레이어\n",
    "#         self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # CNN 레이어 적용\n",
    "#         x = self.cnn(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "        \n",
    "#         # LSTM 레이어 적용\n",
    "#         lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "#         # Fully Connected 레이어에 입력\n",
    "#         out = self.fc(lstm_out[:, -1, :])\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# num_features = X.size(2)\n",
    "\n",
    "# # 모델 인스턴스화\n",
    "# input_size = [batch_size, seq_len, num_features]  # 예: [32, 20, 5]\n",
    "# hidden_size = 64\n",
    "# num_layers = 2\n",
    "\n",
    "# model = CNNLSTMModel(input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN 레이어\n",
    "        # in_channels=input_size[-1]이면 안됨. 즉 feature_dims면 안되고 sequence_length(=20, 40, 80...) 여야 함.\n",
    "        '''\n",
    "        in_channels = 일반적인 이미지와 같은 2D 데이터를 다룰 때는 특성 맵(channel)을 채널로 인식함.\n",
    "        그러나 주식 시계열 데이터와 같은 1D 데이터의 경우 시퀀스 길이에 해당하는 차원이 채널로 간주됨.\n",
    "        이에 따라 'in_channels'에는 시퀀스 길이를 입력해야 함.\n",
    "        즉, 주식 시게열 데이터에서는 'in_channels'에는 시퀀스의 길이가 들어가야 올바르게 수행됨.\n",
    "        '''\n",
    "        self.cnn = nn.Conv1d(in_channels=input_size[1], out_channels=64, kernel_size=3) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully Connected 레이어\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 레이어 적용\n",
    "        x = self.cnn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # LSTM 레이어 적용\n",
    "        '''\n",
    "        LSTM 레이어에 입력을 전달하고, LSTM의 출력과 은닉 상태를 받는 부분\n",
    "        x.permute(0, 2, 1): 입력텐서 x의 차원을 변경. 일반적으로 LSTM 레이어는 시간 단계(seq_len)를 두 번쨰 차원으로 받지만,\n",
    "        Conv1d 레이어의 출력은 시간 단계가 세번째 차원에 위치함. 따라서 permute를 통해 차원을 변경하여 LSTM 레이어에 올바른 형태의 입력을 제공\n",
    "        여기서 0번째 차원은 배치 크기(batch_size)를 나타내며, 1번째 차원은 특성 수(num_features)를 나타냄. 마지막(2번째) 차원은 시간 단계(seq_len)를 나타냄\n",
    "        self.lstm(x.permute(0, 2, 1)): 변경된 입력을 LSTM 레이어에 전달함. LSTM 입력으로 3D 텐서를 받으며,\n",
    "        이 텐서는 배치 크기(batch_size), 시간 단계(seq_len),. 특성 수(num_features)의 형태를 가짐\n",
    "        lstm_out, _: LSTM 레이어의 출력과 은닉 상태를 받음. 여기서 은닉 상태는 사용하지 않기 때문에 '_'로 무시. lstm_out은 LSTM 레이어의 출력으로, 각 시간 단계에\n",
    "        해당하는 출력을 포함하는 3D 텐서임.\n",
    "        '''\n",
    "        lstm_out, _ = self.lstm(x.permute(0, 2, 1))\n",
    "        \n",
    "        # Fully Connected 레이어에 입력\n",
    "        '''\n",
    "        lstm_out[:, -1, :]: LSTM 레이어의 출력에서 마지막 시간 단계의 출력만 선택. 이는 시퀀스 예측을 위해 마지막 시간 단계의 정보만을 사용하고자 하는 것\n",
    "        따라서 [:, -1, :]는 모든 배치와 모든 특성을 유지하면서 마지막 시간 단계의 출력을 선택함\n",
    "        self.fc(lstm_out[:, -1, :]): 선택된 마지막 시간 단계의 출력을 Fully Connected(FC) 레이어에 입력함. FC 레이어는 입력된 LSTM 출력을 받아서 최종\n",
    "        예측을 수행하는 역할을 함. 출력 크기는 1이며, 이는 주어진 입력에 대한 예측된 결과를 나타냄.\n",
    "        '''\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = CNNLSTMModel(input_size=X.size(), hidden_size=32, num_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델학습1: train 데이터만 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습1: train data만 가지고 학습 -> 과적합 이빠이~\n",
    "\n",
    "# # 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# #criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # GPU 사용 가능 여부 확인\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# num_epochs = 100\n",
    "\n",
    "# # 학습 루프\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch_features, batch_targets in train_loader:\n",
    "#         # 배치를 GPU로 전송\n",
    "#         batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "#         # 모델에 대한 순전파 및 손실 계산\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "#         # 역전파 및 최적화\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     # 에폭마다 손실 출력\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델학습2: train, valid를 이용한 과적합 방지되는 epoch 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.02293544923359493, Valid Loss: 0.024438940041454124\n",
      "Epoch 2/100, Train Loss: 0.021384847332846443, Valid Loss: 0.02451746345411801\n",
      "Epoch 3/100, Train Loss: 0.02132009616437948, Valid Loss: 0.02451127048925305\n",
      "Epoch 4/100, Train Loss: 0.021304904571119346, Valid Loss: 0.024495448626525012\n",
      "Epoch 5/100, Train Loss: 0.021297076963028818, Valid Loss: 0.024483293083542627\n",
      "Epoch 6/100, Train Loss: 0.02129076561837826, Valid Loss: 0.024476811818197265\n",
      "Epoch 7/100, Train Loss: 0.02128815524420648, Valid Loss: 0.024469592047075852\n",
      "Epoch 8/100, Train Loss: 0.021283795108210365, Valid Loss: 0.02446920356006487\n",
      "Epoch 9/100, Train Loss: 0.02128088980350854, Valid Loss: 0.024468173371984602\n",
      "Epoch 10/100, Train Loss: 0.021278363634955208, Valid Loss: 0.024467038770093985\n",
      "Epoch 11/100, Train Loss: 0.0212761049844184, Valid Loss: 0.024466010695653604\n",
      "Epoch 12/100, Train Loss: 0.02127408545534566, Valid Loss: 0.024465118739621858\n",
      "Epoch 13/100, Train Loss: 0.021272258095021517, Valid Loss: 0.024464352333799323\n",
      "Epoch 14/100, Train Loss: 0.021270584807081043, Valid Loss: 0.02446368526905141\n",
      "Epoch 15/100, Train Loss: 0.021269038600741693, Valid Loss: 0.024463092604427472\n",
      "Epoch 16/100, Train Loss: 0.021267598389454606, Valid Loss: 0.024462550244432814\n",
      "Epoch 17/100, Train Loss: 0.021266248569173633, Valid Loss: 0.024462049311779914\n",
      "Epoch 18/100, Train Loss: 0.021264975644507498, Valid Loss: 0.024461572051893733\n",
      "Epoch 19/100, Train Loss: 0.021263772586606583, Valid Loss: 0.024461114237494502\n",
      "Epoch 20/100, Train Loss: 0.0212626299768124, Valid Loss: 0.024460670373118516\n",
      "Epoch 21/100, Train Loss: 0.021261542051468255, Valid Loss: 0.024460237499669933\n",
      "Epoch 22/100, Train Loss: 0.02126050445268739, Valid Loss: 0.024459810544413034\n",
      "Epoch 23/100, Train Loss: 0.021259512682006043, Valid Loss: 0.02445939077553174\n",
      "Epoch 24/100, Train Loss: 0.021258564490192342, Valid Loss: 0.024458974811202246\n",
      "Epoch 25/100, Train Loss: 0.02125765636282147, Valid Loss: 0.02445856772416027\n",
      "Epoch 26/100, Train Loss: 0.02125678576950757, Valid Loss: 0.02445816697803795\n",
      "Epoch 27/100, Train Loss: 0.021255951304480714, Valid Loss: 0.024457768345555516\n",
      "Epoch 28/100, Train Loss: 0.02125515043735504, Valid Loss: 0.024457379858544532\n",
      "Epoch 29/100, Train Loss: 0.021254380918898672, Valid Loss: 0.02445699855790916\n",
      "Epoch 30/100, Train Loss: 0.021253642749111606, Valid Loss: 0.024456621061825584\n",
      "Epoch 31/100, Train Loss: 0.02125293438164693, Valid Loss: 0.024456245256653915\n",
      "Epoch 32/100, Train Loss: 0.021252250896309905, Valid Loss: 0.024455884669689423\n",
      "Epoch 33/100, Train Loss: 0.021251596369833318, Valid Loss: 0.024455526619092793\n",
      "Epoch 34/100, Train Loss: 0.021250965882022427, Valid Loss: 0.024455174486687842\n",
      "Epoch 35/100, Train Loss: 0.02125035858941528, Valid Loss: 0.024454830808842434\n",
      "Epoch 36/100, Train Loss: 0.021249775897781802, Valid Loss: 0.024454492203732754\n",
      "Epoch 37/100, Train Loss: 0.021249213589812226, Valid Loss: 0.02445415993954273\n",
      "Epoch 38/100, Train Loss: 0.021248673211853458, Valid Loss: 0.02445383739809618\n",
      "Epoch 39/100, Train Loss: 0.021248152795827615, Valid Loss: 0.024453519929385353\n",
      "Epoch 40/100, Train Loss: 0.02124765121711875, Valid Loss: 0.024453204151586437\n",
      "Epoch 41/100, Train Loss: 0.021247169038034835, Valid Loss: 0.024452901478354813\n",
      "Epoch 42/100, Train Loss: 0.021246703868767, Valid Loss: 0.024452603455130936\n",
      "Epoch 43/100, Train Loss: 0.021246256271623215, Valid Loss: 0.024452310504642784\n",
      "Epoch 44/100, Train Loss: 0.02124582512198754, Valid Loss: 0.02445202262689036\n",
      "Epoch 45/100, Train Loss: 0.021245409716975014, Valid Loss: 0.0244517427809695\n",
      "Epoch 46/100, Train Loss: 0.02124500794793075, Valid Loss: 0.02445146673960043\n",
      "Epoch 47/100, Train Loss: 0.021244623048125574, Valid Loss: 0.024451199998246863\n",
      "Epoch 48/100, Train Loss: 0.021244250800249713, Valid Loss: 0.024450937906901043\n",
      "Epoch 49/100, Train Loss: 0.021243892891227075, Valid Loss: 0.024450678774651062\n",
      "Epoch 50/100, Train Loss: 0.021243547212402774, Valid Loss: 0.024450423446952873\n",
      "Epoch 51/100, Train Loss: 0.02124321460723877, Valid Loss: 0.02445017615108625\n",
      "Epoch 52/100, Train Loss: 0.02124289352938814, Valid Loss: 0.02444993392795536\n",
      "Epoch 53/100, Train Loss: 0.021242585665774794, Valid Loss: 0.024449697200288164\n",
      "Epoch 54/100, Train Loss: 0.021242287783127912, Valid Loss: 0.024449465545356697\n",
      "Epoch 55/100, Train Loss: 0.021242000724909442, Valid Loss: 0.024449240231344885\n",
      "Epoch 56/100, Train Loss: 0.0212417242099654, Valid Loss: 0.024449018299156893\n",
      "Epoch 57/100, Train Loss: 0.02124145837887278, Valid Loss: 0.02444880101697665\n",
      "Epoch 58/100, Train Loss: 0.021241201966438653, Valid Loss: 0.024448588807532128\n",
      "Epoch 59/100, Train Loss: 0.021240955113240007, Valid Loss: 0.024448380402639403\n",
      "Epoch 60/100, Train Loss: 0.021240716694660905, Valid Loss: 0.02444818045230622\n",
      "Epoch 61/100, Train Loss: 0.021240488257048266, Valid Loss: 0.024447982192884944\n",
      "Epoch 62/100, Train Loss: 0.02124026656713126, Valid Loss: 0.024447789006199396\n",
      "Epoch 63/100, Train Loss: 0.02124005401471876, Valid Loss: 0.024447601737705528\n",
      "Epoch 64/100, Train Loss: 0.021239849756348808, Valid Loss: 0.024447416160123567\n",
      "Epoch 65/100, Train Loss: 0.02123965140221254, Valid Loss: 0.024447238614373173\n",
      "Epoch 66/100, Train Loss: 0.021239461482695815, Valid Loss: 0.02444706233680671\n",
      "Epoch 67/100, Train Loss: 0.021239278873182693, Valid Loss: 0.024446889018336086\n",
      "Epoch 68/100, Train Loss: 0.021239101886749268, Valid Loss: 0.024446722463513097\n",
      "Epoch 69/100, Train Loss: 0.021238931929165462, Valid Loss: 0.024446559290513925\n",
      "Epoch 70/100, Train Loss: 0.021238769422162254, Valid Loss: 0.02444640372661834\n",
      "Epoch 71/100, Train Loss: 0.02123861197593077, Valid Loss: 0.024446250699090618\n",
      "Epoch 72/100, Train Loss: 0.02123846099624094, Valid Loss: 0.02444610020793076\n",
      "Epoch 73/100, Train Loss: 0.021238326885790196, Valid Loss: 0.02444595013949888\n",
      "Epoch 74/100, Train Loss: 0.021238268686915345, Valid Loss: 0.024445795843787227\n",
      "Epoch 75/100, Train Loss: 0.021238771249663155, Valid Loss: 0.02444554981610454\n",
      "Epoch 76/100, Train Loss: 0.021241271973780868, Valid Loss: 0.02444486753314945\n",
      "Epoch 77/100, Train Loss: 0.021243577717610124, Valid Loss: 0.0244440939409513\n",
      "Epoch 78/100, Train Loss: 0.02124350995949979, Valid Loss: 0.024443590894658515\n",
      "Epoch 79/100, Train Loss: 0.02123824422651867, Valid Loss: 0.024445255174704476\n",
      "Epoch 80/100, Train Loss: 0.021237622032750328, Valid Loss: 0.024445239956497302\n",
      "Epoch 81/100, Train Loss: 0.02123750872769446, Valid Loss: 0.024445128356311338\n",
      "Epoch 82/100, Train Loss: 0.021237474005177337, Valid Loss: 0.02444498970153484\n",
      "Epoch 83/100, Train Loss: 0.021237490312108455, Valid Loss: 0.024444837096735096\n",
      "Epoch 84/100, Train Loss: 0.021237357185696654, Valid Loss: 0.024444716196533635\n",
      "Epoch 85/100, Train Loss: 0.021237050024968274, Valid Loss: 0.024444655746432908\n",
      "Epoch 86/100, Train Loss: 0.021236882738347323, Valid Loss: 0.024444557250814236\n",
      "Epoch 87/100, Train Loss: 0.021236792909649183, Valid Loss: 0.024444438886980637\n",
      "Epoch 88/100, Train Loss: 0.021236703783836006, Valid Loss: 0.024444328977706584\n",
      "Epoch 89/100, Train Loss: 0.02123662028110252, Valid Loss: 0.024444221604800392\n",
      "Epoch 90/100, Train Loss: 0.021236540011639864, Valid Loss: 0.02444412184099779\n",
      "Epoch 91/100, Train Loss: 0.021236464943525928, Valid Loss: 0.024444022922651142\n",
      "Epoch 92/100, Train Loss: 0.021236389734834996, Valid Loss: 0.024443928231584266\n",
      "Epoch 93/100, Train Loss: 0.021236319305761805, Valid Loss: 0.02444383903598109\n",
      "Epoch 94/100, Train Loss: 0.021236250563612523, Valid Loss: 0.02444375237674578\n",
      "Epoch 95/100, Train Loss: 0.02123618575761903, Valid Loss: 0.02444366825387833\n",
      "Epoch 96/100, Train Loss: 0.02123612235739546, Valid Loss: 0.024443587512834698\n",
      "Epoch 97/100, Train Loss: 0.021236061628134746, Valid Loss: 0.024443511421798816\n",
      "Epoch 98/100, Train Loss: 0.02123600258579794, Valid Loss: 0.024443436176218886\n",
      "Epoch 99/100, Train Loss: 0.021235946495577973, Valid Loss: 0.02444336515791873\n",
      "Epoch 100/100, Train Loss: 0.02123589223285891, Valid Loss: 0.024443294985074523\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # 학습2: valid를 이용한 과적합 방지 epoch 찾기\n",
    "\n",
    "# # 학습과 검증 손실을 저장할 리스트 초기화\n",
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "\n",
    "# # # 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "# #criterion = nn.BCELoss() # 모델 출력이 시그모이드 활성화 함수를 거쳐 확률로 변환된 후의 값을 입력으로 받음. 입력 값은 0과 1사이의 확률 값.\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# num_epochs = 100\n",
    "\n",
    "# # 검증 데이터에 대한 모델 성능 평가 함수 정의\n",
    "# def evaluate(model, criterion, dataloader):\n",
    "#     model.eval()  # 모델을 평가 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_features, batch_targets in dataloader:\n",
    "#             # 배치를 GPU로 전송\n",
    "#             batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            \n",
    "#             # 모델에 대한 순전파 및 손실 계산\n",
    "#             outputs = model(batch_features)\n",
    "#             loss = criterion(outputs, batch_targets)\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     return total_loss / len(dataloader.dataset)  # 평균 손실 반환\n",
    "\n",
    "# # 학습 루프\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # 모델을 학습 모드로 설정\n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     for batch_features, batch_targets in train_loader:\n",
    "#         # 배치를 GPU로 전송\n",
    "#         batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        \n",
    "#         # 모델에 대한 순전파 및 손실 계산\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = criterion(outputs, batch_targets)\n",
    "        \n",
    "#         # 역전파 및 최적화\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     # 에폭마다 학습 손실 기록\n",
    "#     train_loss = total_loss / len(train_loader.dataset)\n",
    "#     train_losses.append(train_loss)\n",
    "    \n",
    "#     # 검증 데이터에 대한 손실 계산 및 기록\n",
    "#     valid_loss = evaluate(model, criterion, valid_loader)\n",
    "#     valid_losses.append(valid_loss)\n",
    "    \n",
    "#     # 에폭마다 손실 출력\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n",
    "\n",
    "# # 손실 함수 시각화\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(valid_losses, label='Valid Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델학습3: Optuna + CV 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Size: torch.Size([707, 20, 77]) torch.Size([707, 1])\n",
      "Train Size: torch.Size([494, 20, 77]) torch.Size([494, 1])\n",
      "Test Size: torch.Size([213, 20, 77]) torch.Size([213, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 / Optuna 용 -> valid 제거\n",
    "file_path = '../../data/' # for mac\n",
    "df = pd.read_csv(file_path + 'bitcoin_data_num_rows_gt_5.csv')\n",
    "df = df.iloc[:1000]\n",
    "df['returns_next10m'] = df['returns_next10m'].apply(lambda x: 0 if x <= 0 else 1) # 종속변수 이진분류화\n",
    "df = df.sort_values(by='window_start', ascending=True) # 시간순 정렬\n",
    "\n",
    "# sequence length를 기준으로 sequence 데이터 생성\n",
    "seq_len = 20 # 20, 40, 80, 160, 320\n",
    "X, y = sq.create_sequence(df, seq_len=seq_len)\n",
    "# Tensor화\n",
    "X = torch.FloatTensor(X).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "print('Full Data Size:', X.size(), y.size())\n",
    "\n",
    "# split (70% / 30%)\n",
    "split = int((X.size(0)) * 0.7)\n",
    "\n",
    "X_train_seq = X[:split]\n",
    "X_test_seq = X[split:]\n",
    "y_train_seq = y[:split]\n",
    "y_test_seq = y[split:]\n",
    "\n",
    "print('Train Size:', X_train_seq.size(), y_train_seq.size())\n",
    "print('Test Size:', X_test_seq.size(), y_test_seq.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 13:52:28,422] A new study created in memory with name: no-name-23273313-f894-451b-a8a8-9980a358554c\n",
      "[W 2024-02-28 13:52:59,387] Trial 0 failed with parameters: {'hidden_size': 100, 'num_layers': 2, 'lr': 0.01} because of the following error: RuntimeError('MPS backend out of memory (MPS allocated: 46.69 MB, other allocations: 9.02 GB, max allowed: 9.07 GB). Tried to allocate 156.25 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/yd/1_xwcyjj6z58p2vptxk1dwvm0000gn/T/ipykernel_4747/3352314322.py\", line 46, in objective\n",
      "    loss.backward()\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/homebrew/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 46.69 MB, other allocations: 9.02 GB, max allowed: 9.07 GB). Tried to allocate 156.25 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
      "[W 2024-02-28 13:52:59,443] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 46.69 MB, other allocations: 9.02 GB, max allowed: 9.07 GB). Tried to allocate 156.25 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Optuna 최적화 실행\u001b[39;00m\n\u001b[1;32m     67\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 시도 횟수는 10으로 설정\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[17], line 46\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m     45\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m---> 46\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 검증 손실 계산\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 46.69 MB, other allocations: 9.02 GB, max allowed: 9.07 GB). Tried to allocate 156.25 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# 학습 3: Optuna + CV 추가\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def objective(trial):\n",
    "    # K-Fold 교차 검증 설정\n",
    "    # k = 5  # 분할 수\n",
    "    # kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    # TimeSeriesSplit 설정\n",
    "    tscv = TimeSeriesSplit(n_splits=5, gap=0) # gap: valid 전 train 데이터의 마지막 몇개 데이터 포인트를 제거하느냐\n",
    "\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    input_size = X.size() # LSTM: X.shape[2](n_features), CNN-LSTM: X.size() -> CNN내에서 X.size(1)(seq_len)으로 input 실행\n",
    "    hidden_size = trial.suggest_int('hidden_size', 5, 100, step=5)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    lr = trial.suggest_categorical('lr', [0.1, 0.01, 0.001, 0.0001])\n",
    "    num_epochs = 100  # 에폭 수는 고정값으로 설정\n",
    "\n",
    "    # 교차 검증을 위한 전체 손실 초기화\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        # 훈련 데이터와 검증 데이터로 분할\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        # DataLoader 설정\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        # 모델, 손실 함수, 옵티마이저 정의\n",
    "        model = CNNLSTMModel(input_size, hidden_size, num_layers).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss() # 시그모이드 활성화 함수가 내장되어 있음. 모델의 마지막 레이어에서 시그모이드 함수 별도 적용할 필요X\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # 모델 훈련\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # 검증 손실 계산\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "        total_loss += val_loss\n",
    "\n",
    "    # 평균 검증 손실을 반환\n",
    "    avg_loss = total_loss / 5\n",
    "    return avg_loss\n",
    "\n",
    "# Optuna 최적화 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)  # 시도 횟수는 10으로 설정\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(\"Best trial's value:\", study.best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6408\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        preds = torch.round(outputs).cpu().numpy()  # 이진 분류를 가정\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Accuracy: {accuracy.round(4)}')\n",
    "print(f'Precision: {precision.round(4)}')\n",
    "print(f'Recall: {recall.round(4)}')\n",
    "print(f'F1 Score: {f1.round(4)}')\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
